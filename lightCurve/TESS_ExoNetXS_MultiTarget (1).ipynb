{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ad1d8425",
      "metadata": {
        "id": "ad1d8425"
      },
      "source": [
        "# TESS → ExoNet-XS (Multi-target): build a dataset with Global/Local views\n",
        "\n",
        "This notebook creates a **multi-target pipeline**:\n",
        "\n",
        "* Downloads **TESScut TPFs** for a list of targets\n",
        "* Extracts a **light curve** using a **threshold** or **circular** aperture mask\n",
        "* Applies **detrending** with **CBVs** (if available) or **PLD** as a fallback\n",
        "* Runs **BLS** to obtain **period/epoch/duration**\n",
        "* Builds **Global/Local views** + **centroids**\n",
        "* **Saves** a standardized dataset (`index.csv` + per-*sample* folders with `global.npy`, `local.npy`, `params.npy`, `meta.json`)\n",
        "* Includes a **PyTorch Dataset** and a **training skeleton** (uses labels if you provide them)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68b15064",
      "metadata": {
        "id": "68b15064"
      },
      "source": [
        "## 0) Install dependencies (if needed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8b1c411",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8b1c411",
        "outputId": "9ea6324b-e593-4de2-f444-f7f020aa8241"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "Downloading pip-25.2-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-25.2\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.2)\n",
            "Collecting astropy\n",
            "  Downloading astropy-7.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting photutils\n",
            "  Downloading photutils-2.3.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n",
            "Collecting lightkurve\n",
            "  Downloading lightkurve-2.5.1-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting astroquery\n",
            "  Downloading astroquery-0.4.11-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cpu)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cpu)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (0.25.2)\n",
            "Collecting pyerfa>=2.0.1.1 (from astropy)\n",
            "  Downloading pyerfa-2.0.1.5-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\n",
            "Collecting astropy-iers-data>=0.2025.4.28.0.37.27 (from astropy)\n",
            "  Downloading astropy_iers_data-0.2025.9.29.0.35.48-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from astropy) (6.0.3)\n",
            "Requirement already satisfied: packaging>=22.0.0 in /usr/local/lib/python3.12/dist-packages (from astropy) (25.0)\n",
            "Requirement already satisfied: beautifulsoup4>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from lightkurve) (4.13.5)\n",
            "Collecting bokeh>=2.3.2 (from lightkurve)\n",
            "  Downloading bokeh-3.8.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting fbpca>=1.0 (from lightkurve)\n",
            "  Downloading fbpca-1.0.tar.gz (11 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting memoization>=0.3.1 (from lightkurve)\n",
            "  Downloading memoization-0.4.0.tar.gz (41 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting patsy>=0.5.0 (from lightkurve)\n",
            "  Downloading patsy-1.0.1-py2.py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.12/dist-packages (from lightkurve) (2.32.4)\n",
            "Collecting s3fs>=2024.6.1 (from lightkurve)\n",
            "  Downloading s3fs-2025.9.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from lightkurve) (1.6.1)\n",
            "Collecting uncertainties>=3.1.4 (from lightkurve)\n",
            "  Downloading uncertainties-3.2.3-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: urllib3>=1.23 in /usr/local/lib/python3.12/dist-packages (from lightkurve) (2.5.0)\n",
            "Collecting html5lib>=0.999 (from astroquery)\n",
            "  Downloading html5lib-1.1-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: keyring>=15.0 in /usr/lib/python3/dist-packages (from astroquery) (23.5.0)\n",
            "Collecting pyvo>=1.5 (from astroquery)\n",
            "  Downloading pyvo-1.7-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.9.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (2025.9.30)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (0.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.6.0->lightkurve) (2.8)\n",
            "Requirement already satisfied: narwhals>=1.13 in /usr/local/lib/python3.12/dist-packages (from bokeh>=2.3.2->lightkurve) (2.6.0)\n",
            "Requirement already satisfied: tornado>=6.2 in /usr/local/lib/python3.12/dist-packages (from bokeh>=2.3.2->lightkurve) (6.4.2)\n",
            "Collecting xyzservices>=2021.09.1 (from bokeh>=2.3.2->lightkurve)\n",
            "  Downloading xyzservices-2025.4.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.12/dist-packages (from html5lib>=0.999->astroquery) (1.17.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from html5lib>=0.999->astroquery) (0.5.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.22.0->lightkurve) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.22.0->lightkurve) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.22.0->lightkurve) (2025.8.3)\n",
            "Collecting aiobotocore<3.0.0,>=2.5.4 (from s3fs>=2024.6.1->lightkurve)\n",
            "  Downloading aiobotocore-2.24.2-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from s3fs>=2024.6.1->lightkurve)\n",
            "  Downloading aiohttp-3.12.15-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting aioitertools<1.0.0,>=0.5.1 (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2024.6.1->lightkurve)\n",
            "  Downloading aioitertools-0.12.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting botocore<1.40.19,>=1.40.15 (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2024.6.1->lightkurve)\n",
            "  Downloading botocore-1.40.18-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2024.6.1->lightkurve)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: multidict<7.0.0,>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2024.6.1->lightkurve) (6.6.4)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.10.10 in /usr/local/lib/python3.12/dist-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2024.6.1->lightkurve) (1.17.3)\n",
            "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs>=2024.6.1->lightkurve)\n",
            "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs>=2024.6.1->lightkurve)\n",
            "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs>=2024.6.1->lightkurve) (25.3.0)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs>=2024.6.1->lightkurve)\n",
            "  Downloading frozenlist-1.7.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs>=2024.6.1->lightkurve)\n",
            "  Downloading propcache-0.4.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs>=2024.6.1->lightkurve)\n",
            "  Downloading yarl-1.21.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (74 kB)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.24.0->lightkurve) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.24.0->lightkurve) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Downloading astropy-7.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m141.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading photutils-2.3.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightkurve-2.5.1-py3-none-any.whl (256 kB)\n",
            "Downloading astroquery-0.4.11-py3-none-any.whl (11.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astropy_iers_data-0.2025.9.29.0.35.48-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bokeh-3.8.0-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m145.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
            "Downloading patsy-1.0.1-py2.py3-none-any.whl (232 kB)\n",
            "Downloading pyerfa-2.0.1.5-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (738 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m738.7/738.7 kB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyvo-1.7-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading s3fs-2025.9.0-py3-none-any.whl (30 kB)\n",
            "Downloading aiobotocore-2.24.2-py3-none-any.whl (85 kB)\n",
            "Downloading aiohttp-3.12.15-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aioitertools-0.12.0-py3-none-any.whl (24 kB)\n",
            "Downloading botocore-1.40.18-py3-none-any.whl (14.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m166.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading yarl-1.21.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (377 kB)\n",
            "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
            "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
            "Downloading frozenlist-1.7.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n",
            "Downloading propcache-0.4.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (221 kB)\n",
            "Downloading uncertainties-3.2.3-py3-none-any.whl (60 kB)\n",
            "Downloading xyzservices-2025.4.0-py3-none-any.whl (90 kB)\n",
            "Building wheels for collected packages: fbpca, memoization\n",
            "  Building wheel for fbpca (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fbpca: filename=fbpca-1.0-py3-none-any.whl size=11428 sha256=4e26a6a230f1a5e87bc54ee8d64eb3b79cf2c77c03f52f31132e6906539ffd6f\n",
            "  Stored in directory: /root/.cache/pip/wheels/04/15/cd/2f622795b09e83471a3be5d2581cd9cf96a6ec7aa78e8deffe\n",
            "  Building wheel for memoization (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for memoization: filename=memoization-0.4.0-py3-none-any.whl size=50538 sha256=7fee421009e9321b8667f0b27a86ec074900b32dc7b4f36926ef502ef92fbb60\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/35/02/90618fc7cbf03a335f3cacd59d32b35930bf5a57f3c0d0814c\n",
            "Successfully built fbpca memoization\n",
            "Installing collected packages: fbpca, xyzservices, uncertainties, pyerfa, propcache, patsy, memoization, jmespath, html5lib, frozenlist, astropy-iers-data, aioitertools, aiohappyeyeballs, yarl, botocore, astropy, aiosignal, pyvo, photutils, bokeh, aiohttp, astroquery, aiobotocore, s3fs, lightkurve\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25/25\u001b[0m [lightkurve]\n",
            "\u001b[1A\u001b[2KSuccessfully installed aiobotocore-2.24.2 aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aioitertools-0.12.0 aiosignal-1.4.0 astropy-7.1.0 astropy-iers-data-0.2025.9.29.0.35.48 astroquery-0.4.11 bokeh-3.8.0 botocore-1.40.18 fbpca-1.0 frozenlist-1.7.0 html5lib-1.1 jmespath-1.0.1 lightkurve-2.5.1 memoization-0.4.0 patsy-1.0.1 photutils-2.3.0 propcache-0.4.0 pyerfa-2.0.1.5 pyvo-1.7 s3fs-2025.9.0 uncertainties-3.2.3 xyzservices-2025.4.0 yarl-1.21.0\n"
          ]
        }
      ],
      "source": [
        "# Se precisar:\n",
        "!pip install --upgrade pip\n",
        "!pip install numpy scipy astropy photutils lightkurve astroquery pandas torch torchvision matplotlib tqdm scikit-image\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "577c2cc1",
      "metadata": {
        "id": "577c2cc1"
      },
      "source": [
        "## 1) Configurações gerais"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "630e7e86",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "630e7e86",
        "outputId": "e02e5d13-dfed-41d2-d4bf-4b6a7a333734"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Config OK.\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# List of targets (names or TIC/TOI). You can edit/expand:\n",
        "TARGETS = [\n",
        "    \"TOI 700\",\n",
        "    \"pi Mensae\",\n",
        "    \"Kepler-10\",\n",
        "    # \"TIC 150428135\",\n",
        "]\n",
        "\n",
        "# (Optional) Force a single sector per target (None => all available)\n",
        "FORCED_SECTOR = None  # e.g., 13\n",
        "\n",
        "# TESScut cutout (in pixels, square side length)\n",
        "CUTOUT_SIZE = 15\n",
        "\n",
        "# Aperture mask: \"threshold\" OR \"circular\"\n",
        "APERTURE_MODE = \"threshold\"\n",
        "THRESHOLD = 3       # sigma for threshold mode\n",
        "CIRC_RADIUS = 3     # px for circular mode\n",
        "\n",
        "# Detrending: prefer CBVs; if unavailable, use PLD\n",
        "USE_CBVS = True\n",
        "USE_PLD  = True\n",
        "\n",
        "# BLS\n",
        "P_MIN, P_MAX = 0.5, 30.0  # days\n",
        "N_PERIODS    = 20000\n",
        "DUR_FRAC     = 0.02\n",
        "\n",
        "# Output directories\n",
        "DATA_DIR    = Path(\"dataset_tess_exonetxs\")\n",
        "CUTS_DIR    = DATA_DIR / \"tpf\"\n",
        "SAMPLES_DIR = DATA_DIR / \"samples\"\n",
        "for d in [DATA_DIR, CUTS_DIR, SAMPLES_DIR]:\n",
        "    d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# (Optional) Path to CSV with labels (columns: target,label [,sector])\n",
        "# label: 1=planet/positive; 0=false/negative; -1=unknown\n",
        "LABELS_CSV = None  # e.g., \"labels.csv\"\n",
        "\n",
        "print(\"Config OK.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "984da02b",
      "metadata": {
        "id": "984da02b"
      },
      "source": [
        "## 2) Helper functions (download, aperture mask, detrending, BLS, views)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9cb1043",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9cb1043",
        "outputId": "6c513264-78c8-4696-c5c4-235c289f15f7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/lightkurve/prf/__init__.py:7: UserWarning: Warning: the tpfmodel submodule is not available without oktopus installed, which requires a current version of autograd. See #1452 for details.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from astropy.coordinates import SkyCoord\n",
        "import astropy.units as u\n",
        "from astroquery.mast import Tesscut\n",
        "from lightkurve import open as lk_open\n",
        "from lightkurve import search_tesscut\n",
        "from lightkurve.correctors import CBVCorrector, PLDCorrector\n",
        "from astropy.timeseries import BoxLeastSquares\n",
        "\n",
        "def download_tesscut(target_name: str, sector=None, size=15, out_dir=Path(\".\")):\n",
        "    \"\"\"Download TESScut cutouts and save .fits; return a list of file paths.\"\"\"\n",
        "    out_dir = Path(out_dir); out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    # Resolve coordinates\n",
        "    try:\n",
        "        coord = SkyCoord.from_name(target_name)\n",
        "    except Exception:\n",
        "        sr = search_tesscut(target_name, sector=sector)\n",
        "        if len(sr) == 0:\n",
        "            raise RuntimeError(f\"Nothing found in TESScut for '{target_name}'.\")\n",
        "        coord = SkyCoord(sr.table[0][\"target_ra\"], sr.table[0][\"target_dec\"], unit=(u.deg, u.deg))\n",
        "    # Download cutouts\n",
        "    hduls = Tesscut.get_cutouts(coordinates=coord, size=size, sector=sector)\n",
        "    if hduls is None or len(hduls) == 0:\n",
        "        raise RuntimeError(f\"TESScut returned no cutouts for '{target_name}' (sector={sector}).\")\n",
        "    paths = []\n",
        "    for i, hdu in enumerate(hduls):\n",
        "        p = out_dir / f\"{target_name.replace(' ', '_')}_sector{sector if sector is not None else 'ALL'}_{i:02d}.fits\"\n",
        "        hdu.writeto(p, overwrite=True); paths.append(str(p))\n",
        "    return paths\n",
        "\n",
        "def build_aperture_mask(tpf, mode=\"threshold\", threshold=3, circ_radius=3):\n",
        "    if mode.lower() == \"threshold\":\n",
        "        return tpf.create_threshold_mask(threshold=threshold)\n",
        "    # circular\n",
        "    img = np.nanmean(tpf.flux.value, axis=0)\n",
        "    yy, xx = np.indices(img.shape)\n",
        "    den = np.nansum(img) + 1e-8\n",
        "    cx = np.nansum(img * xx) / den\n",
        "    cy = np.nansum(img * yy) / den\n",
        "    rr2 = (xx - cx)**2 + (yy - cy)**2\n",
        "    return (rr2 <= (circ_radius**2))\n",
        "\n",
        "def detrend_lightcurve(tpf, mask, use_cbvs=True, use_pld=True):\n",
        "    raw_lc = tpf.to_lightcurve(aperture_mask=mask).remove_nans()\n",
        "    corrected_lc = None\n",
        "    if use_cbvs:\n",
        "        try:\n",
        "            cbv = CBVCorrector(raw_lc)\n",
        "            corrected_lc = cbv.correct()\n",
        "            print(\"CBVCorrector OK.\")\n",
        "        except Exception as e:\n",
        "            print(\"CBVCorrector unavailable:\", e)\n",
        "    if corrected_lc is None and use_pld:\n",
        "        try:\n",
        "            pld = PLDCorrector(tpf)\n",
        "            corrected_lc = pld.correct(aperture_mask=mask)\n",
        "            print(\"PLDCorrector OK (fallback).\")\n",
        "        except Exception as e:\n",
        "            print(\"PLDCorrector failed:\", e)\n",
        "    if corrected_lc is None:\n",
        "        corrected_lc = raw_lc\n",
        "    lc = corrected_lc.normalize(unit=\"ppm\").remove_outliers(sigma=5)\n",
        "    return raw_lc, lc\n",
        "\n",
        "def run_bls(time_mjd, flux_norm, p_min, p_max, n_periods, dur_frac):\n",
        "    y = flux_norm / np.nanmedian(flux_norm)\n",
        "    bls = BoxLeastSquares(time_mjd, y)\n",
        "    periods = np.linspace(p_min, p_max, n_periods)\n",
        "    power = bls.power(periods, dur_frac)\n",
        "    i = np.nanargmax(power.power)\n",
        "    P = float(power.period[i]); t0 = float(power.transit_time[i]); dur = float(power.duration[i]); depth = float(power.depth[i])\n",
        "    return P, t0, dur, depth, power\n",
        "\n",
        "def phase_fold(t, y, P, t0):\n",
        "    phi = ((t - t0 + 0.5 * P) % P) / P - 0.5\n",
        "    order = np.argsort(phi)\n",
        "    return phi[order], y[order]\n",
        "\n",
        "def resample_uniform(x, y, n, xmin, xmax):\n",
        "    grid = np.linspace(xmin, xmax, n)\n",
        "    y_res = np.interp(grid, x, y, left=y[0], right=y[-1])\n",
        "    return grid, y_res\n",
        "\n",
        "def build_views(times_mjd, rel_flux, P, t0, dur, centroids=None, n_points=2001, local_k=2.0):\n",
        "    phi, yv = phase_fold(times_mjd, rel_flux, P, t0)\n",
        "    gx, gy = resample_uniform(phi, yv, n_points, -0.5, 0.5)\n",
        "    w = local_k * (dur / P)\n",
        "    lx, ly = resample_uniform(phi, yv, n_points, -w, +w)\n",
        "    def norm_robust(v):\n",
        "        med = np.nanmedian(v)\n",
        "        q25, q75 = np.nanpercentile(v, [25, 75])\n",
        "        iqr = max(q75 - q25, 1e-6)\n",
        "        return (v - med) / iqr\n",
        "    gy = norm_robust(gy); ly = norm_robust(ly)\n",
        "    if centroids is not None:\n",
        "        cx, cy = centroids\n",
        "        _, cxg = resample_uniform(*phase_fold(times_mjd, cx, P, t0), n_points, -0.5, 0.5)\n",
        "        _, cyg = resample_uniform(*phase_fold(times_mjd, cy, P, t0), n_points, -0.5, 0.5)\n",
        "        _, cxl = resample_uniform(*phase_fold(times_mjd, cx, P, t0), n_points, -w, +w)\n",
        "        _, cyl = resample_uniform(*phase_fold(times_mjd, cy, P, t0), n_points, -w, +w)\n",
        "        def z(v):\n",
        "            mu = np.nanmean(v); sd = np.nanstd(v) + 1e-6\n",
        "            return (v - mu)/sd\n",
        "        cxg, cyg, cxl, cyl = z(cxg), z(cyg), z(cxl), z(cyl)\n",
        "        global_view = np.stack([gy, cxg, cyg], axis=0).astype(\"float32\")\n",
        "        local_view  = np.stack([ly, cxl, cyl], axis=0).astype(\"float32\")\n",
        "    else:\n",
        "        global_view = gy[None, :].astype(\"float32\")\n",
        "        local_view  = ly[None, :].astype(\"float32\")\n",
        "    return global_view, local_view\n",
        "\n",
        "def compute_centroids_from_tpf(tpf):\n",
        "    flux_cube = tpf.flux.value\n",
        "    yy, xx = np.indices(flux_cube.shape[1:])\n",
        "    den = np.nansum(flux_cube, axis=(1,2)) + 1e-8\n",
        "    cx = np.nansum(flux_cube * xx, axis=(1,2)) / den\n",
        "    cy = np.nansum(flux_cube * yy, axis=(1,2)) / den\n",
        "    return cx, cy\n",
        "\n",
        "def save_sample(sample_dir, global_view, local_view, params, meta):\n",
        "    sample_dir = Path(sample_dir); sample_dir.mkdir(parents=True, exist_ok=True)\n",
        "    np.save(sample_dir / \"global.npy\", global_view)\n",
        "    np.save(sample_dir / \"local.npy\",  local_view)\n",
        "    np.save(sample_dir / \"params.npy\", params)\n",
        "    with (sample_dir / \"meta.json\").open(\"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(meta, f, ensure_ascii=False, indent=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86e8dbd0",
      "metadata": {
        "id": "86e8dbd0"
      },
      "source": [
        "## 3) (Optional) Load labels from a CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5dcc1caa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dcc1caa",
        "outputId": "283d0d3c-6e40-4512-fbe9-494c0f1db1e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nenhum CSV de rótulos definido; os samples serão salvos com label=-1 (desconhecido). Use o index.csv para rotular depois.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "labels_map = {}\n",
        "if LABELS_CSV:\n",
        "    df_labels = pd.read_csv(LABELS_CSV)\n",
        "    # Expects columns: target,label[,sector]\n",
        "    for _, r in df_labels.iterrows():\n",
        "        key = (str(r['target']).strip(), int(r['sector'])) if 'sector' in r and pd.notna(r['sector']) else (str(r['target']).strip(), None)\n",
        "        labels_map[key] = int(r['label'])\n",
        "    print(f\"Loaded labels: {len(labels_map)} entries\")\n",
        "else:\n",
        "    print(\"No labels CSV defined; samples will be saved with label=-1 (unknown). Use index.csv to label them later.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4847b158",
      "metadata": {
        "id": "4847b158"
      },
      "source": [
        "## 4) Main loop: build the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45487acb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45487acb",
        "outputId": "63704314-68c7-47f3-8bf1-57cf2df49542"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-4128344727.py:13: LightkurveDeprecationWarning: The open function is deprecated and may be removed in a future version.\n",
            "        Use read() instead.\n",
            "  tpf = lk_open(files[0])\n",
            "The SingleScale CBVs do not appear to be well aligned to the light curve. Consider using \"interpolate_cbvs=True\"\n",
            "WARNING:lightkurve.correctors.cbvcorrector:The SingleScale CBVs do not appear to be well aligned to the light curve. Consider using \"interpolate_cbvs=True\"\n",
            "The MultiScale CBVs do not appear to be well aligned to the light curve. Consider using \"interpolate_cbvs=True\"\n",
            "WARNING:lightkurve.correctors.cbvcorrector:The MultiScale CBVs do not appear to be well aligned to the light curve. Consider using \"interpolate_cbvs=True\"\n",
            "The MultiScale CBVs do not appear to be well aligned to the light curve. Consider using \"interpolate_cbvs=True\"\n",
            "WARNING:lightkurve.correctors.cbvcorrector:The MultiScale CBVs do not appear to be well aligned to the light curve. Consider using \"interpolate_cbvs=True\"\n",
            "The MultiScale CBVs do not appear to be well aligned to the light curve. Consider using \"interpolate_cbvs=True\"\n",
            "WARNING:lightkurve.correctors.cbvcorrector:The MultiScale CBVs do not appear to be well aligned to the light curve. Consider using \"interpolate_cbvs=True\"\n",
            "The Spike CBVs do not appear to be well aligned to the light curve. Consider using \"interpolate_cbvs=True\"\n",
            "WARNING:lightkurve.correctors.cbvcorrector:The Spike CBVs do not appear to be well aligned to the light curve. Consider using \"interpolate_cbvs=True\"\n",
            "/usr/local/lib/python3.12/dist-packages/astropy/utils/decorators.py:620: LightkurveDeprecationWarning: \"aperture_mask\" was deprecated in version 2.0 and will be removed in a future version. \n",
            "  return function(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CBVCorrector indisponível: SVD did not converge\n",
            "PLDCorrector OK (fallback).\n",
            "OK: TOI 700 (sector=None) → sample_id=TOI_700_ALL_4c09077b\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-4128344727.py:13: LightkurveDeprecationWarning: The open function is deprecated and may be removed in a future version.\n",
            "        Use read() instead.\n",
            "  tpf = lk_open(files[0])\n",
            "The SingleScale CBVs do not appear to be well aligned to the light curve. Consider using \"interpolate_cbvs=True\"\n",
            "WARNING:lightkurve.correctors.cbvcorrector:The SingleScale CBVs do not appear to be well aligned to the light curve. Consider using \"interpolate_cbvs=True\"\n",
            "The MultiScale CBVs do not appear to be well aligned to the light curve. Consider using \"interpolate_cbvs=True\"\n",
            "WARNING:lightkurve.correctors.cbvcorrector:The MultiScale CBVs do not appear to be well aligned to the light curve. Consider using \"interpolate_cbvs=True\"\n",
            "The MultiScale CBVs do not appear to be well aligned to the light curve. Consider using \"interpolate_cbvs=True\"\n",
            "WARNING:lightkurve.correctors.cbvcorrector:The MultiScale CBVs do not appear to be well aligned to the light curve. Consider using \"interpolate_cbvs=True\"\n",
            "The MultiScale CBVs do not appear to be well aligned to the light curve. Consider using \"interpolate_cbvs=True\"\n",
            "WARNING:lightkurve.correctors.cbvcorrector:The MultiScale CBVs do not appear to be well aligned to the light curve. Consider using \"interpolate_cbvs=True\"\n",
            "The Spike CBVs do not appear to be well aligned to the light curve. Consider using \"interpolate_cbvs=True\"\n",
            "WARNING:lightkurve.correctors.cbvcorrector:The Spike CBVs do not appear to be well aligned to the light curve. Consider using \"interpolate_cbvs=True\"\n",
            "/usr/local/lib/python3.12/dist-packages/astropy/utils/decorators.py:620: LightkurveDeprecationWarning: \"aperture_mask\" was deprecated in version 2.0 and will be removed in a future version. \n",
            "  return function(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CBVCorrector indisponível: SVD did not converge\n",
            "PLDCorrector OK (fallback).\n",
            "OK: pi Mensae (sector=None) → sample_id=pi_Mensae_ALL_953947c2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-4128344727.py:13: LightkurveDeprecationWarning: The open function is deprecated and may be removed in a future version.\n",
            "        Use read() instead.\n",
            "  tpf = lk_open(files[0])\n",
            "The SingleScale CBVs do not appear to be well aligned to the light curve. Consider using \"interpolate_cbvs=True\"\n",
            "WARNING:lightkurve.correctors.cbvcorrector:The SingleScale CBVs do not appear to be well aligned to the light curve. Consider using \"interpolate_cbvs=True\"\n",
            "The MultiScale CBVs do not appear to be well aligned to the light curve. Consider using \"interpolate_cbvs=True\"\n",
            "WARNING:lightkurve.correctors.cbvcorrector:The MultiScale CBVs do not appear to be well aligned to the light curve. Consider using \"interpolate_cbvs=True\"\n",
            "The MultiScale CBVs do not appear to be well aligned to the light curve. Consider using \"interpolate_cbvs=True\"\n",
            "WARNING:lightkurve.correctors.cbvcorrector:The MultiScale CBVs do not appear to be well aligned to the light curve. Consider using \"interpolate_cbvs=True\"\n",
            "The MultiScale CBVs do not appear to be well aligned to the light curve. Consider using \"interpolate_cbvs=True\"\n",
            "WARNING:lightkurve.correctors.cbvcorrector:The MultiScale CBVs do not appear to be well aligned to the light curve. Consider using \"interpolate_cbvs=True\"\n",
            "The Spike CBVs do not appear to be well aligned to the light curve. Consider using \"interpolate_cbvs=True\"\n",
            "WARNING:lightkurve.correctors.cbvcorrector:The Spike CBVs do not appear to be well aligned to the light curve. Consider using \"interpolate_cbvs=True\"\n",
            "/usr/local/lib/python3.12/dist-packages/astropy/utils/decorators.py:620: LightkurveDeprecationWarning: \"aperture_mask\" was deprecated in version 2.0 and will be removed in a future version. \n",
            "  return function(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CBVCorrector indisponível: SVD did not converge\n",
            "PLDCorrector OK (fallback).\n",
            "OK: Kepler-10 (sector=None) → sample_id=Kepler-10_ALL_58822b3f\n",
            "Dataset pronto: 3 samples. Index salvo em dataset_tess_exonetxs/index.csv\n"
          ]
        }
      ],
      "source": [
        "import uuid\n",
        "import pandas as pd\n",
        "\n",
        "index_rows = []\n",
        "for target in TARGETS:\n",
        "    try:\n",
        "        # 1) Download TESScut (um ou vários arquivos por setor)\n",
        "        files = download_tesscut(target, sector=FORCED_SECTOR, size=CUTOUT_SIZE, out_dir=CUTS_DIR)\n",
        "        if len(files) == 0:\n",
        "            print(f\"[WARN] Sem TPFs para {target}\"); continue\n",
        "\n",
        "        # 2) Abre o 1º TPF (você pode iterar sobre todos se quiser aumentar amostra)\n",
        "        tpf = lk_open(files[0])\n",
        "        # Extrai setor do header, se existir\n",
        "        sector_hdr = None\n",
        "        try:\n",
        "            sector_hdr = int(getattr(tpf.hdu[0].header, 'SECTOR', None) or getattr(tpf.hdu[1].header, 'SECTOR', None) or getattr(tpf.hdu[2].header, 'SECTOR', None))\n",
        "        except Exception:\n",
        "            sector_hdr = None\n",
        "\n",
        "        # 3) Máscara\n",
        "        mask = build_aperture_mask(tpf, mode=APERTURE_MODE, threshold=THRESHOLD, circ_radius=CIRC_RADIUS)\n",
        "\n",
        "        # 4) Detrending\n",
        "        raw_lc, lc = detrend_lightcurve(tpf, mask, use_cbvs=USE_CBVS, use_pld=USE_PLD)\n",
        "        time_mjd = lc.time.to_value(\"mjd\")\n",
        "        flux     = lc.flux.value\n",
        "\n",
        "        # 5) BLS\n",
        "        P, t0, dur, depth, power = run_bls(time_mjd, flux, P_MIN, P_MAX, N_PERIODS, DUR_FRAC)\n",
        "\n",
        "        # 6) Vistas + centróides\n",
        "        cx, cy = compute_centroids_from_tpf(tpf)\n",
        "        ynorm = flux / np.nanmedian(flux)\n",
        "        gview, lview = build_views(time_mjd, ynorm, P, t0, dur, centroids=(cx, cy))\n",
        "\n",
        "        # 7) Params/Meta\n",
        "        params = np.zeros(4, dtype=np.float32)  # placeholder p/ T_eff, log g, R*, Fe/H\n",
        "        meta = {\n",
        "            \"target\": target,\n",
        "            \"sector\": sector_hdr if sector_hdr is not None else FORCED_SECTOR,\n",
        "            \"period\": float(P), \"t0\": float(t0), \"duration\": float(dur), \"depth\": float(depth),\n",
        "            \"n_points\": int(gview.shape[-1]), \"local_k\": 2.0\n",
        "        }\n",
        "\n",
        "        # 8) Label\n",
        "        key1 = (target, sector_hdr if sector_hdr is not None else FORCED_SECTOR)\n",
        "        key2 = (target, None)\n",
        "        label = labels_map.get(key1, labels_map.get(key2, -1))\n",
        "        meta[\"label\"] = int(label)\n",
        "\n",
        "        # 9) Salvar sample\n",
        "        sample_id = f\"{target.replace(' ','_')}_{(sector_hdr if sector_hdr is not None else 'ALL')}_{uuid.uuid4().hex[:8]}\"\n",
        "        sample_dir = SAMPLES_DIR / sample_id\n",
        "        save_sample(sample_dir, gview, lview, params, meta)\n",
        "\n",
        "        # 10) Index\n",
        "        index_rows.append({\n",
        "            \"sample_id\": sample_id,\n",
        "            \"target\": target,\n",
        "            \"sector\": meta[\"sector\"],\n",
        "            \"label\": meta[\"label\"],\n",
        "            \"period\": meta[\"period\"],\n",
        "            \"t0\": meta[\"t0\"],\n",
        "            \"duration\": meta[\"duration\"],\n",
        "            \"depth\": meta[\"depth\"],\n",
        "            \"global_path\": str(sample_dir / \"global.npy\"),\n",
        "            \"local_path\": str(sample_dir / \"local.npy\"),\n",
        "            \"params_path\": str(sample_dir / \"params.npy\"),\n",
        "            \"meta_path\": str(sample_dir / \"meta.json\"),\n",
        "            \"tpf_path\": files[0],\n",
        "        })\n",
        "\n",
        "        print(f\"OK: {target} (sector={meta['sector']}) → sample_id={sample_id}\")\n",
        "    except Exception as e:\n",
        "        print(f\"[ERRO] {target}: {e}\")\n",
        "\n",
        "# Salva index.csv\n",
        "df_index = pd.DataFrame(index_rows)\n",
        "df_index.to_csv(DATA_DIR / \"index.csv\", index=False)\n",
        "print(f\"Dataset pronto: {len(df_index)} samples. Index salvo em {DATA_DIR/'index.csv'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cfe06e4",
      "metadata": {
        "id": "0cfe06e4"
      },
      "source": [
        "## 5) View dataset summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e9f2c78",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "2e9f2c78",
        "outputId": "7322a766-e543-41e9-8e70-0d8015a6b83b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"    print(\\\"index\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"sample_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"TOI_700_ALL_4c09077b\",\n          \"pi_Mensae_ALL_953947c2\",\n          \"Kepler-10_ALL_58822b3f\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"TOI 700\",\n          \"pi Mensae\",\n          \"Kepler-10\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sector\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": -1,\n        \"max\": -1,\n        \"num_unique_values\": 1,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"period\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.266510611111852,\n        \"min\": 4.633156657832892,\n        \"max\": 13.085329266463324,\n        \"num_unique_values\": 3,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"t0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 206.4904850483885,\n        \"min\": 58325.22026118344,\n        \"max\": 58687.421370605465,\n        \"num_unique_values\": 3,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"duration\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.02,\n        \"max\": 0.02,\n        \"num_unique_values\": 1,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"depth\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.003496951642058978,\n        \"min\": 0.0021619193240531,\n        \"max\": 0.0082769006647443,\n        \"num_unique_values\": 3,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"global_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"local_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"params_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"meta_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tpf_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-dc8fd544-77d0-4f97-aed9-fb57c3994d78\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sample_id</th>\n",
              "      <th>target</th>\n",
              "      <th>sector</th>\n",
              "      <th>label</th>\n",
              "      <th>period</th>\n",
              "      <th>t0</th>\n",
              "      <th>duration</th>\n",
              "      <th>depth</th>\n",
              "      <th>global_path</th>\n",
              "      <th>local_path</th>\n",
              "      <th>params_path</th>\n",
              "      <th>meta_path</th>\n",
              "      <th>tpf_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TOI_700_ALL_4c09077b</td>\n",
              "      <td>TOI 700</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1</td>\n",
              "      <td>13.085329</td>\n",
              "      <td>58334.499023</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.008277</td>\n",
              "      <td>dataset_tess_exonetxs/samples/TOI_700_ALL_4c09...</td>\n",
              "      <td>dataset_tess_exonetxs/samples/TOI_700_ALL_4c09...</td>\n",
              "      <td>dataset_tess_exonetxs/samples/TOI_700_ALL_4c09...</td>\n",
              "      <td>dataset_tess_exonetxs/samples/TOI_700_ALL_4c09...</td>\n",
              "      <td>dataset_tess_exonetxs/tpf/TOI_700_sectorALL_00...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>pi_Mensae_ALL_953947c2</td>\n",
              "      <td>pi Mensae</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1</td>\n",
              "      <td>4.633157</td>\n",
              "      <td>58325.220261</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.002162</td>\n",
              "      <td>dataset_tess_exonetxs/samples/pi_Mensae_ALL_95...</td>\n",
              "      <td>dataset_tess_exonetxs/samples/pi_Mensae_ALL_95...</td>\n",
              "      <td>dataset_tess_exonetxs/samples/pi_Mensae_ALL_95...</td>\n",
              "      <td>dataset_tess_exonetxs/samples/pi_Mensae_ALL_95...</td>\n",
              "      <td>dataset_tess_exonetxs/tpf/pi_Mensae_sectorALL_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Kepler-10_ALL_58822b3f</td>\n",
              "      <td>Kepler-10</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1</td>\n",
              "      <td>9.874094</td>\n",
              "      <td>58687.421371</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.002280</td>\n",
              "      <td>dataset_tess_exonetxs/samples/Kepler-10_ALL_58...</td>\n",
              "      <td>dataset_tess_exonetxs/samples/Kepler-10_ALL_58...</td>\n",
              "      <td>dataset_tess_exonetxs/samples/Kepler-10_ALL_58...</td>\n",
              "      <td>dataset_tess_exonetxs/samples/Kepler-10_ALL_58...</td>\n",
              "      <td>dataset_tess_exonetxs/tpf/Kepler-10_sectorALL_...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc8fd544-77d0-4f97-aed9-fb57c3994d78')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dc8fd544-77d0-4f97-aed9-fb57c3994d78 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dc8fd544-77d0-4f97-aed9-fb57c3994d78');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-56ec065c-e68e-4bfe-85e2-180040898d02\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-56ec065c-e68e-4bfe-85e2-180040898d02')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-56ec065c-e68e-4bfe-85e2-180040898d02 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                sample_id     target  sector  label     period            t0  \\\n",
              "0    TOI_700_ALL_4c09077b    TOI 700     NaN     -1  13.085329  58334.499023   \n",
              "1  pi_Mensae_ALL_953947c2  pi Mensae     NaN     -1   4.633157  58325.220261   \n",
              "2  Kepler-10_ALL_58822b3f  Kepler-10     NaN     -1   9.874094  58687.421371   \n",
              "\n",
              "   duration     depth                                        global_path  \\\n",
              "0      0.02  0.008277  dataset_tess_exonetxs/samples/TOI_700_ALL_4c09...   \n",
              "1      0.02  0.002162  dataset_tess_exonetxs/samples/pi_Mensae_ALL_95...   \n",
              "2      0.02  0.002280  dataset_tess_exonetxs/samples/Kepler-10_ALL_58...   \n",
              "\n",
              "                                          local_path  \\\n",
              "0  dataset_tess_exonetxs/samples/TOI_700_ALL_4c09...   \n",
              "1  dataset_tess_exonetxs/samples/pi_Mensae_ALL_95...   \n",
              "2  dataset_tess_exonetxs/samples/Kepler-10_ALL_58...   \n",
              "\n",
              "                                         params_path  \\\n",
              "0  dataset_tess_exonetxs/samples/TOI_700_ALL_4c09...   \n",
              "1  dataset_tess_exonetxs/samples/pi_Mensae_ALL_95...   \n",
              "2  dataset_tess_exonetxs/samples/Kepler-10_ALL_58...   \n",
              "\n",
              "                                           meta_path  \\\n",
              "0  dataset_tess_exonetxs/samples/TOI_700_ALL_4c09...   \n",
              "1  dataset_tess_exonetxs/samples/pi_Mensae_ALL_95...   \n",
              "2  dataset_tess_exonetxs/samples/Kepler-10_ALL_58...   \n",
              "\n",
              "                                            tpf_path  \n",
              "0  dataset_tess_exonetxs/tpf/TOI_700_sectorALL_00...  \n",
              "1  dataset_tess_exonetxs/tpf/pi_Mensae_sectorALL_...  \n",
              "2  dataset_tess_exonetxs/tpf/Kepler-10_sectorALL_...  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total: 3\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "idx_path = Path(\"dataset_tess_exonetxs/index.csv\")\n",
        "if idx_path.exists():\n",
        "    df = pd.read_csv(idx_path)\n",
        "    display(df.head(10))\n",
        "    print(\"Total:\", len(df))\n",
        "else:\n",
        "    print(\"index.csv não encontrado.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06552fc5",
      "metadata": {
        "id": "06552fc5"
      },
      "source": [
        "## 6) PyTorch Dataset + training (uses only samples with label ∈ {0,1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10cbc793",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "10cbc793",
        "outputId": "be24d6a4-b264-4aaf-cd47-c11ef4e20e15"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'dataset_tess_exonetxs/index.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2111862483.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m# Carrega dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0mindex_csv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"dataset_tess_exonetxs/index.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExoNetXSDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_csv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msupervised_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sem rótulos 0/1 no index.csv — adicione rótulos e reexecute.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2111862483.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, index_csv, supervised_only)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_csv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msupervised_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_csv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msupervised_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset_tess_exonetxs/index.csv'"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class ExoNetXSDataset(Dataset):\n",
        "    def __init__(self, index_csv, supervised_only=True):\n",
        "        import pandas as pd\n",
        "        self.df = pd.read_csv(index_csv)\n",
        "        if supervised_only:\n",
        "            self.df = self.df[self.df['label'].isin([0,1])].reset_index(drop=True)\n",
        "        self.supervised_only = supervised_only\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self, i):\n",
        "        r = self.df.iloc[i]\n",
        "        g = np.load(r['global_path']).astype('float32')  # (C,N)\n",
        "        l = np.load(r['local_path']).astype('float32')\n",
        "        p = np.load(r['params_path']).astype('float32')  # (D,)\n",
        "        y = int(r['label']) if r['label'] in [0,1] else -1\n",
        "        return torch.from_numpy(g), torch.from_numpy(l), torch.from_numpy(p), torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "class ConvBlock1D(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, k=5, s=1, p=2):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv1d(in_ch, out_ch, kernel_size=k, stride=s, padding=p),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv1d(out_ch, out_ch, kernel_size=k, stride=1, padding=p),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "    def forward(self, x): return self.net(x)\n",
        "\n",
        "class ExoNetXS(nn.Module):\n",
        "    def __init__(self, in_ch_global=1, in_ch_local=1, params_dim=4, n_classes=2):\n",
        "        super().__init__()\n",
        "        self.g1 = ConvBlock1D(in_ch_global, 16)\n",
        "        self.g2 = ConvBlock1D(16, 32)\n",
        "        self.g3 = ConvBlock1D(32, 64)\n",
        "        self.gpool = nn.AdaptiveMaxPool1d(1)\n",
        "        self.l1 = ConvBlock1D(in_ch_local, 16)\n",
        "        self.l2 = ConvBlock1D(16, 32)\n",
        "        self.lpool = nn.AdaptiveMaxPool1d(1)\n",
        "        fused = 64 + 32 + params_dim\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Linear(fused, 64), nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(64, n_classes)\n",
        "        )\n",
        "    def forward(self, g, l, p):\n",
        "        g = self.g3(self.g2(self.g1(g))); g = self.gpool(g).squeeze(-1)\n",
        "        l = self.l2(self.l1(l));          l = self.lpool(l).squeeze(-1)\n",
        "        x = torch.cat([g, l, p], dim=1)\n",
        "        return self.head(x)\n",
        "\n",
        "# Carrega dataset\n",
        "index_csv = \"dataset_tess_exonetxs/index.csv\"\n",
        "ds = ExoNetXSDataset(index_csv, supervised_only=True)\n",
        "if len(ds) == 0:\n",
        "    print(\"Sem rótulos 0/1 no index.csv — adicione rótulos e reexecute.\")\n",
        "else:\n",
        "    # split\n",
        "    n = len(ds); n_val = max(1, int(0.2*n))\n",
        "    tr, va = torch.utils.data.random_split(ds, [n-n_val, n_val])\n",
        "    tr_loader = DataLoader(tr, batch_size=8, shuffle=True)\n",
        "    va_loader = DataLoader(va, batch_size=8)\n",
        "\n",
        "    # infer channels/dims\n",
        "    g0,l0,p0,y0 = ds[0]\n",
        "    model = ExoNetXS(in_ch_global=g0.shape[0], in_ch_local=l0.shape[0], params_dim=p0.shape[0], n_classes=2)\n",
        "\n",
        "    # class weights (balanceamento)\n",
        "    import pandas as pd\n",
        "    df = pd.read_csv(index_csv)\n",
        "    df = df[df['label'].isin([0,1])]\n",
        "    n_pos = (df['label']==1).sum(); n_neg = (df['label']==0).sum()\n",
        "    total  = n_pos + n_neg\n",
        "    w_pos = total / (2*max(1,n_pos)); w_neg = total / (2*max(1,n_neg))\n",
        "    crit = nn.CrossEntropyLoss(weight=torch.tensor([w_neg, w_pos], dtype=torch.float32))\n",
        "\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "    for ep in range(5):\n",
        "        model.train(); run=0.0\n",
        "        for g,l,p,y in tr_loader:\n",
        "            opt.zero_grad(); logits = model(g,l,p); loss = crit(logits,y); loss.backward(); opt.step()\n",
        "            run += loss.item()*y.size(0)\n",
        "        tl = run/len(tr)\n",
        "\n",
        "        model.eval(); corr=tot=0\n",
        "        with torch.no_grad():\n",
        "            for g,l,p,y in va_loader:\n",
        "                logits = model(g,l,p)\n",
        "                pred = logits.argmax(1)\n",
        "                corr += (pred==y).sum().item(); tot += y.size(0)\n",
        "        acc = corr/max(1,tot)\n",
        "        print(f\"Epoch {ep+1} | train_loss={tl:.4f} | val_acc={acc:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "724f6f1b",
      "metadata": {
        "id": "724f6f1b"
      },
      "source": [
        "## 7) How to label (examples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90ba21e3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90ba21e3",
        "outputId": "803cd251-a0d0-44b9-b8a5-efa94fd91d5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Veja o exemplo no comentário acima. Você também pode abrir dataset_tess_exonetxs/index.csv e adicionar a coluna 'label'.\n"
          ]
        }
      ],
      "source": [
        "# Crie um CSV simples com colunas: target,label[,sector]\n",
        "# Exemplo:\n",
        "# target,label,sector\n",
        "# TOI 700,1,\n",
        "# Kepler-10,1,\n",
        "# pi Mensae,1,\n",
        "# TIC 150428135,0,13\n",
        "#\n",
        "# Salve como labels.csv e aponte LABELS_CSV para esse caminho na seção de Configurações.\n",
        "\n",
        "\n",
        "print(\"See the example in the comment above. You can also open dataset_tess_exonetxs/index.csv and add the 'label' column.\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V5E1",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
