{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a9bd865c",
      "metadata": {
        "id": "a9bd865c"
      },
      "source": [
        "# 🚀 NASA Exoplanet — AutoML ×3 (AutoGluon, FLAML, PyCaret) with Balancing and Clear Metrics\n",
        "\n",
        "Notebook inspired by your reference file (**Hanseniase_v2.ipynb**), now applied to **NASA data (Kepler/TESS/KOI/TOI/Exoplanet Archive)** with the following improvements:\n",
        "\n",
        "* Column merging/normalization to the project’s standard schema\n",
        "* Cleaning (essential NaNs + outliers via IQR)\n",
        "* Stratified split\n",
        "* **AutoML ×3**: **AutoGluon**, **FLAML**, and **PyCaret** (binary classification)\n",
        "* **Class imbalance handling** (class weights **or** **SMOTE**)\n",
        "* **Threshold sweep** with a table (FN/FP/Recall/Precision/F1/Specificity/Accuracy)\n",
        "* **ROC** and **Precision–Recall** curves\n",
        "* **Listing and export of FNs** (missed positives)\n",
        "\n",
        "> Edit the **Config** section with your NASA CSVs and the `COLUMN_MAP`.\n",
        "> Generated on: 2025-10-04 18:49:27"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2b7444e",
      "metadata": {
        "id": "a2b7444e"
      },
      "source": [
        "## 0) Instalação (Colab-friendly)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4269f6ea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4269f6ea",
        "outputId": "970054a6-084a-419b-910b-5b2d37dcd322"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: autogluon in /usr/local/lib/python3.12/dist-packages (1.4.0)\n",
            "Requirement already satisfied: autogluon.core==1.4.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.core[all]==1.4.0->autogluon) (1.4.0)\n",
            "Requirement already satisfied: autogluon.features==1.4.0 in /usr/local/lib/python3.12/dist-packages (from autogluon) (1.4.0)\n",
            "Requirement already satisfied: autogluon.tabular==1.4.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.tabular[all]==1.4.0->autogluon) (1.4.0)\n",
            "Requirement already satisfied: autogluon.multimodal==1.4.0 in /usr/local/lib/python3.12/dist-packages (from autogluon) (1.4.0)\n",
            "Requirement already satisfied: autogluon.timeseries==1.4.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.timeseries[all]==1.4.0->autogluon) (1.4.0)\n",
            "Requirement already satisfied: numpy<2.4.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.17,>=1.5.4 in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn<1.8.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (1.4.2)\n",
            "Requirement already satisfied: networkx<4,>=3.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (3.5)\n",
            "Requirement already satisfied: pandas<2.4.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (2.1.4)\n",
            "Requirement already satisfied: tqdm<5,>=4.38 in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (2.32.4)\n",
            "Requirement already satisfied: matplotlib<3.11,>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (3.7.5)\n",
            "Requirement already satisfied: boto3<2,>=1.10 in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (1.40.45)\n",
            "Requirement already satisfied: autogluon.common==1.4.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (1.4.0)\n",
            "Requirement already satisfied: hyperopt<0.2.8,>=0.2.7 in /usr/local/lib/python3.12/dist-packages (from autogluon.core[all]==1.4.0->autogluon) (0.2.7)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.core[all]==1.4.0->autogluon) (18.1.0)\n",
            "Requirement already satisfied: ray<2.45,>=2.10.0 in /usr/local/lib/python3.12/dist-packages (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (2.44.1)\n",
            "Requirement already satisfied: Pillow<12,>=10.0.1 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (11.3.0)\n",
            "Requirement already satisfied: torch<2.8,>=2.2 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (2.7.1)\n",
            "Requirement already satisfied: lightning<2.8,>=2.2 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (2.5.5)\n",
            "Requirement already satisfied: transformers<4.50,>=4.38.0 in /usr/local/lib/python3.12/dist-packages (from transformers[sentencepiece]<4.50,>=4.38.0->autogluon.multimodal==1.4.0->autogluon) (4.49.0)\n",
            "Requirement already satisfied: accelerate<2.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (1.10.1)\n",
            "Requirement already satisfied: fsspec<=2025.3 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3->autogluon.multimodal==1.4.0->autogluon) (2025.3.0)\n",
            "Requirement already satisfied: jsonschema<4.24,>=4.18 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (4.23.0)\n",
            "Requirement already satisfied: seqeval<1.3.0,>=1.2.2 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (1.2.2)\n",
            "Requirement already satisfied: evaluate<0.5.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (0.4.6)\n",
            "Requirement already satisfied: timm<1.0.7,>=0.9.5 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (1.0.3)\n",
            "Requirement already satisfied: torchvision<0.23.0,>=0.16.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (0.22.1)\n",
            "Requirement already satisfied: scikit-image<0.26.0,>=0.19.1 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (0.25.2)\n",
            "Requirement already satisfied: text-unidecode<1.4,>=1.3 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (1.3)\n",
            "Requirement already satisfied: torchmetrics<1.8,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (1.7.4)\n",
            "Requirement already satisfied: omegaconf<2.4.0,>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (2.3.0)\n",
            "Requirement already satisfied: pytorch-metric-learning<2.9,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (2.8.1)\n",
            "Requirement already satisfied: nlpaug<1.2.0,>=1.1.10 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (1.1.11)\n",
            "Requirement already satisfied: nltk<3.10,>=3.4.5 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (3.9.1)\n",
            "Requirement already satisfied: openmim<0.4.0,>=0.3.7 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (0.3.9)\n",
            "Requirement already satisfied: defusedxml<0.7.2,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (0.7.1)\n",
            "Requirement already satisfied: jinja2<3.2,>=3.0.3 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (3.1.6)\n",
            "Requirement already satisfied: tensorboard<3,>=2.9 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (2.19.0)\n",
            "Requirement already satisfied: pytesseract<0.4,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (0.3.13)\n",
            "Requirement already satisfied: nvidia-ml-py3<8.0,>=7.352.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (7.352.0)\n",
            "Requirement already satisfied: pdf2image<1.19,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (1.17.0)\n",
            "Requirement already satisfied: catboost<1.3,>=1.2 in /usr/local/lib/python3.12/dist-packages (from autogluon.tabular[all]==1.4.0->autogluon) (1.2.8)\n",
            "Requirement already satisfied: fastai<2.9,>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from autogluon.tabular[all]==1.4.0->autogluon) (2.8.4)\n",
            "Requirement already satisfied: loguru in /usr/local/lib/python3.12/dist-packages (from autogluon.tabular[all]==1.4.0->autogluon) (0.7.3)\n",
            "Requirement already satisfied: lightgbm<4.7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.tabular[all]==1.4.0->autogluon) (4.6.0)\n",
            "Requirement already satisfied: einx in /usr/local/lib/python3.12/dist-packages (from autogluon.tabular[all]==1.4.0->autogluon) (0.3.0)\n",
            "Requirement already satisfied: xgboost<3.1,>=2.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.tabular[all]==1.4.0->autogluon) (3.0.5)\n",
            "Requirement already satisfied: spacy<3.9 in /usr/local/lib/python3.12/dist-packages (from autogluon.tabular[all]==1.4.0->autogluon) (3.8.7)\n",
            "Requirement already satisfied: huggingface-hub[torch] in /usr/local/lib/python3.12/dist-packages (from autogluon.tabular[all]==1.4.0->autogluon) (0.35.3)\n",
            "Requirement already satisfied: joblib<1.7,>=1.2 in /usr/local/lib/python3.12/dist-packages (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (1.3.2)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.12/dist-packages (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (2.5.5)\n",
            "Requirement already satisfied: gluonts<0.17,>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (0.16.2)\n",
            "Collecting statsforecast<2.0.2,>=1.7.0 (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Using cached statsforecast-2.0.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (29 kB)\n",
            "Requirement already satisfied: mlforecast<0.15.0,>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (0.14.0)\n",
            "Requirement already satisfied: utilsforecast<0.2.12,>=0.2.3 in /usr/local/lib/python3.12/dist-packages (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (0.2.11)\n",
            "Requirement already satisfied: coreforecast<0.0.17,>=0.0.12 in /usr/local/lib/python3.12/dist-packages (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (0.0.16)\n",
            "Collecting fugue>=0.9.0 (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Using cached fugue-0.9.1-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: orjson~=3.9 in /usr/local/lib/python3.12/dist-packages (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (3.11.3)\n",
            "Requirement already satisfied: psutil<7.1.0,>=5.7.3 in /usr/local/lib/python3.12/dist-packages (from autogluon.common==1.4.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (5.9.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate<2.0,>=0.34.0->autogluon.multimodal==1.4.0->autogluon) (25.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate<2.0,>=0.34.0->autogluon.multimodal==1.4.0->autogluon) (6.0.3)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate<2.0,>=0.34.0->autogluon.multimodal==1.4.0->autogluon) (0.6.2)\n",
            "Requirement already satisfied: botocore<1.41.0,>=1.40.45 in /usr/local/lib/python3.12/dist-packages (from boto3<2,>=1.10->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (1.40.45)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from boto3<2,>=1.10->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.15.0,>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from boto3<2,>=1.10->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (0.14.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.4.0->autogluon) (0.21)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.4.0->autogluon) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.4.0->autogluon) (1.17.0)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.4.0->autogluon) (4.0.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.4.0->autogluon) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.4.0->autogluon) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.4.0->autogluon) (0.70.16)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.4.0->autogluon) (24.1.2)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.12/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.4.0->autogluon) (0.0.7)\n",
            "Requirement already satisfied: fastcore<1.9,>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.4.0->autogluon) (1.8.12)\n",
            "Requirement already satisfied: fasttransform>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.4.0->autogluon) (0.0.2)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.12/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.4.0->autogluon) (1.0.3)\n",
            "Requirement already satisfied: plum-dispatch in /usr/local/lib/python3.12/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.4.0->autogluon) (2.5.7)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.4.0->autogluon) (3.1.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3->autogluon.multimodal==1.4.0->autogluon) (3.12.15)\n",
            "Requirement already satisfied: triad>=0.9.7 in /usr/local/lib/python3.12/dist-packages (from fugue>=0.9.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (0.9.8)\n",
            "Requirement already satisfied: adagio>=0.2.4 in /usr/local/lib/python3.12/dist-packages (from fugue>=0.9.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (0.2.6)\n",
            "Requirement already satisfied: pydantic<3,>=1.7 in /usr/local/lib/python3.12/dist-packages (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (2.11.9)\n",
            "Requirement already satisfied: toolz~=0.10 in /usr/local/lib/python3.12/dist-packages (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (0.12.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (4.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.12/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.4.0->autogluon) (1.0.0)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.12/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.4.0->autogluon) (0.10.9.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2<3.2,>=3.0.3->autogluon.multimodal==1.4.0->autogluon) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema<4.24,>=4.18->autogluon.multimodal==1.4.0->autogluon) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema<4.24,>=4.18->autogluon.multimodal==1.4.0->autogluon) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema<4.24,>=4.18->autogluon.multimodal==1.4.0->autogluon) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema<4.24,>=4.18->autogluon.multimodal==1.4.0->autogluon) (0.27.1)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from lightning<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (0.15.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (2.9.0.post0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (0.60.0)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.12/dist-packages (from mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (4.5.0)\n",
            "Requirement already satisfied: window-ops in /usr/local/lib/python3.12/dist-packages (from mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (0.0.15)\n",
            "Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.4.0->autogluon) (5.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk<3.10,>=3.4.5->autogluon.multimodal==1.4.0->autogluon) (8.3.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk<3.10,>=3.4.5->autogluon.multimodal==1.4.0->autogluon) (2024.11.6)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf<2.4.0,>=2.1.1->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.12/dist-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon) (0.4.6)\n",
            "Requirement already satisfied: model-index in /usr/local/lib/python3.12/dist-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon) (0.1.11)\n",
            "Requirement already satisfied: opendatalab in /usr/local/lib/python3.12/dist-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon) (0.0.10)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon) (13.9.4)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon) (0.9.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<2.4.0,>=2.0.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.12/dist-packages (from pandas<2.4.0,>=2.0.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (2025.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (3.19.1)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (1.1.1)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.12/dist-packages (from ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (5.29.5)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.12/dist-packages (from ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (1.4.0)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.12/dist-packages (from ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (1.7.0)\n",
            "Requirement already satisfied: aiohttp_cors in /usr/local/lib/python3.12/dist-packages (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (0.8.1)\n",
            "Requirement already satisfied: colorful in /usr/local/lib/python3.12/dist-packages (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (0.5.7)\n",
            "Requirement already satisfied: py-spy>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (0.4.1)\n",
            "Requirement already satisfied: grpcio>=1.42.0 in /usr/local/lib/python3.12/dist-packages (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (1.75.1)\n",
            "Requirement already satisfied: opencensus in /usr/local/lib/python3.12/dist-packages (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (0.11.4)\n",
            "Requirement already satisfied: prometheus_client>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (0.23.1)\n",
            "Requirement already satisfied: smart_open in /usr/local/lib/python3.12/dist-packages (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (7.3.1)\n",
            "Requirement already satisfied: virtualenv!=20.21.1,>=20.0.24 in /usr/local/lib/python3.12/dist-packages (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (20.34.0)\n",
            "Requirement already satisfied: tensorboardX>=1.9 in /usr/local/lib/python3.12/dist-packages (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (2.6.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (2025.8.3)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image<0.26.0,>=0.19.1->autogluon.multimodal==1.4.0->autogluon) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image<0.26.0,>=0.19.1->autogluon.multimodal==1.4.0->autogluon) (2025.9.30)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image<0.26.0,>=0.19.1->autogluon.multimodal==1.4.0->autogluon) (0.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<1.8.0,>=1.4.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (3.6.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (0.19.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (80.9.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (3.5.0)\n",
            "Requirement already satisfied: statsmodels>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from statsforecast<2.0.2,>=1.7.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (0.14.5)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.4.0->autogluon) (1.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.4.0->autogluon) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.4.0->autogluon) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.4.0->autogluon) (2.3.8)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (1.13.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (9.5.1.17)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (0.6.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (2.26.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.3.1 in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (3.3.1)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers<4.50,>=4.38.0->transformers[sentencepiece]<4.50,>=4.38.0->autogluon.multimodal==1.4.0->autogluon) (0.21.4)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.12/dist-packages (from transformers[sentencepiece]<4.50,>=4.38.0->autogluon.multimodal==1.4.0->autogluon) (0.2.1)\n",
            "Requirement already satisfied: frozendict in /usr/local/lib/python3.12/dist-packages (from einx->autogluon.tabular[all]==1.4.0->autogluon) (2.4.6)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub[torch]; extra == \"all\"->autogluon.tabular[all]==1.4.0->autogluon) (1.1.10)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3->autogluon.multimodal==1.4.0->autogluon) (2.6.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3->autogluon.multimodal==1.4.0->autogluon) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3->autogluon.multimodal==1.4.0->autogluon) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3->autogluon.multimodal==1.4.0->autogluon) (1.20.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.4.0->autogluon) (4.13.5)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.12/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (1.3.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (0.43.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (0.4.2)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.13.2->statsforecast<2.0.2,>=1.7.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (1.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (1.3.0)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (0.1.5)\n",
            "INFO: pip is looking at multiple versions of thinc to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting thinc<8.4.0,>=8.3.4 (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon)\n",
            "  Downloading thinc-8.3.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
            "Collecting blis<1.3.0,>=1.2.0 (from thinc<8.4.0,>=8.3.4->spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon)\n",
            "  Downloading blis-1.2.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: fs in /usr/local/lib/python3.12/dist-packages (from triad>=0.9.7->fugue>=0.9.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (2.4.16)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (1.5.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon) (2.19.2)\n",
            "Requirement already satisfied: distlib<1,>=0.3.7 in /usr/local/lib/python3.12/dist-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (0.4.0)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.12/dist-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (4.4.0)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (0.22.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (1.17.3)\n",
            "Requirement already satisfied: ordered-set in /usr/local/lib/python3.12/dist-packages (from model-index->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon) (4.1.0)\n",
            "Requirement already satisfied: opencensus-context>=0.1.3 in /usr/local/lib/python3.12/dist-packages (from opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (0.1.3)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (2.25.1)\n",
            "Requirement already satisfied: pycryptodome in /usr/local/lib/python3.12/dist-packages (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon) (3.23.0)\n",
            "Requirement already satisfied: openxlab in /usr/local/lib/python3.12/dist-packages (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon) (0.0.11)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna->mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (1.16.5)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.12/dist-packages (from optuna->mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (6.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna->mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (2.0.43)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost<1.3,>=1.2->autogluon.tabular[all]==1.4.0->autogluon) (8.5.0)\n",
            "Requirement already satisfied: beartype>=0.16.2 in /usr/local/lib/python3.12/dist-packages (from plum-dispatch->fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.4.0->autogluon) (0.21.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna->mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (1.3.10)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (1.70.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (1.26.1)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (2.38.0)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (1.3.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon) (0.1.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna->mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (3.2.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.4.0->autogluon) (2.8)\n",
            "Requirement already satisfied: appdirs~=1.4.3 in /usr/local/lib/python3.12/dist-packages (from fs->triad>=0.9.7->fugue>=0.9.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (1.4.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.4.0->autogluon) (1.7.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (4.9.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (0.6.1)\n",
            "Using cached fugue-0.9.1-py3-none-any.whl (278 kB)\n",
            "Using cached statsforecast-2.0.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (353 kB)\n",
            "Downloading thinc-8.3.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading blis-1.2.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144591 sha256=bbf5918f31aad606888b42f034794b5229554d6b058b3ae9679847d02610291a\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/be/48/13754633f1d08d1fbfc60d5e80ae1e5d7329500477685286cd\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, blis, thinc, fugue, statsforecast\n",
            "  Attempting uninstall: antlr4-python3-runtime\n",
            "    Found existing installation: antlr4-python3-runtime 4.11.1\n",
            "    Uninstalling antlr4-python3-runtime-4.11.1:\n",
            "      Successfully uninstalled antlr4-python3-runtime-4.11.1\n",
            "  Attempting uninstall: blis\n",
            "    Found existing installation: blis 1.3.0\n",
            "    Uninstalling blis-1.3.0:\n",
            "      Successfully uninstalled blis-1.3.0\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.3.6\n",
            "    Uninstalling thinc-8.3.6:\n",
            "      Successfully uninstalled thinc-8.3.6\n",
            "  Attempting uninstall: fugue\n",
            "    Found existing installation: fugue 0.8.7\n",
            "    Uninstalling fugue-0.8.7:\n",
            "      Successfully uninstalled fugue-0.8.7\n",
            "  Attempting uninstall: statsforecast\n",
            "    Found existing installation: statsforecast 1.5.0\n",
            "    Uninstalling statsforecast-1.5.0:\n",
            "      Successfully uninstalled statsforecast-1.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "qpd 0.4.4 requires antlr4-python3-runtime<4.12,>=4.11.1, but you have antlr4-python3-runtime 4.9.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed antlr4-python3-runtime-4.9.3 blis-1.2.1 fugue-0.9.1 statsforecast-2.0.1 thinc-8.3.4\n",
            "Requirement already satisfied: flaml in /usr/local/lib/python3.12/dist-packages (2.3.6)\n",
            "Requirement already satisfied: NumPy>=1.17 in /usr/local/lib/python3.12/dist-packages (from flaml) (1.26.4)\n",
            "Requirement already satisfied: pycaret[full] in /usr/local/lib/python3.12/dist-packages (3.3.2)\n",
            "Requirement already satisfied: ipython>=5.5.0 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (7.34.0)\n",
            "Requirement already satisfied: ipywidgets>=7.6.5 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (7.7.1)\n",
            "Requirement already satisfied: tqdm>=4.62.0 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (4.67.1)\n",
            "Requirement already satisfied: numpy<1.27,>=1.21 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (1.26.4)\n",
            "Requirement already satisfied: pandas<2.2.0 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (2.1.4)\n",
            "Requirement already satisfied: jinja2>=3 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (3.1.6)\n",
            "Requirement already satisfied: scipy<=1.11.4,>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (1.11.4)\n",
            "Requirement already satisfied: joblib<1.4,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (1.3.2)\n",
            "Requirement already satisfied: scikit-learn>1.4.0 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (1.4.2)\n",
            "Requirement already satisfied: pyod>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (2.0.5)\n",
            "Requirement already satisfied: imbalanced-learn>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (0.14.0)\n",
            "Requirement already satisfied: category-encoders>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (2.7.0)\n",
            "Requirement already satisfied: lightgbm>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (4.6.0)\n",
            "Requirement already satisfied: numba>=0.55.0 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (0.60.0)\n",
            "Requirement already satisfied: requests>=2.27.1 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (2.32.4)\n",
            "Requirement already satisfied: psutil>=5.9.0 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (5.9.5)\n",
            "Requirement already satisfied: markupsafe>=2.0.1 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (3.0.3)\n",
            "Requirement already satisfied: importlib-metadata>=4.12.0 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (8.7.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (5.10.4)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (3.1.1)\n",
            "Requirement already satisfied: deprecation>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (2.1.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (3.5.0)\n",
            "Requirement already satisfied: matplotlib<3.8.0 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (3.7.5)\n",
            "Requirement already satisfied: scikit-plot>=0.3.7 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (0.3.7)\n",
            "Requirement already satisfied: yellowbrick>=1.4 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (1.5)\n",
            "Requirement already satisfied: plotly>=5.14.0 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (5.24.1)\n",
            "Requirement already satisfied: kaleido>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (1.1.0)\n",
            "Requirement already satisfied: schemdraw==0.15 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (0.15)\n",
            "Requirement already satisfied: plotly-resampler>=0.8.3.1 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (0.11.0)\n",
            "Requirement already satisfied: statsmodels>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (0.14.5)\n",
            "Requirement already satisfied: sktime==0.26.0 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (0.26.0)\n",
            "Requirement already satisfied: tbats>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (1.1.3)\n",
            "Requirement already satisfied: pmdarima>=2.0.4 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (2.0.4)\n",
            "Requirement already satisfied: wurlitzer in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (3.1.1)\n",
            "Requirement already satisfied: shap~=0.44.0 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (0.44.1)\n",
            "Requirement already satisfied: interpret>=0.2.7 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (0.7.2)\n",
            "Requirement already satisfied: umap-learn>=0.5.2 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (0.5.7)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (6.0.3)\n",
            "Requirement already satisfied: ydata-profiling>=4.3.1 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (4.17.0)\n",
            "Requirement already satisfied: explainerdashboard>=0.3.8 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (0.5.1)\n",
            "Requirement already satisfied: fairlearn==0.7.0 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (0.7.0)\n",
            "Requirement already satisfied: kmodes>=0.11.1 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (0.12.2)\n",
            "Requirement already satisfied: mlxtend>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (0.23.4)\n",
            "Collecting statsforecast<1.6.0,>=0.5.5 (from pycaret[full])\n",
            "  Using cached statsforecast-1.5.0-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: hyperopt>=0.2.7 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (0.2.7)\n",
            "Requirement already satisfied: optuna>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (4.5.0)\n",
            "Requirement already satisfied: optuna-integration in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (4.5.0)\n",
            "Requirement already satisfied: scikit-optimize>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (0.10.2)\n",
            "Requirement already satisfied: mlflow>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (3.4.0)\n",
            "Requirement already satisfied: gradio>=3.50.2 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (5.47.2)\n",
            "Requirement already satisfied: boto3>=1.24.56 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (1.40.45)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (0.118.0)\n",
            "Requirement already satisfied: uvicorn>=0.17.6 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (0.37.0)\n",
            "Requirement already satisfied: m2cgen>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (0.10.0)\n",
            "Requirement already satisfied: evidently~=0.4.16 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (0.4.40)\n",
            "Requirement already satisfied: dask>=2024.4.1 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (2025.5.0)\n",
            "Requirement already satisfied: distributed>=2024.4.1 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (2025.5.0)\n",
            "Collecting fugue~=0.8.0 (from pycaret[full])\n",
            "  Using cached fugue-0.8.7-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (2.3.3)\n",
            "Requirement already satisfied: Werkzeug<3.0,>=2.2 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (2.3.8)\n",
            "Requirement already satisfied: pytest<8.0.0 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (7.4.4)\n",
            "Requirement already satisfied: moto<5.0.0 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (4.2.14)\n",
            "Requirement already satisfied: dash[testing] in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (2.18.2)\n",
            "Requirement already satisfied: scikit-learn-intelex>=2023.0.1 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (2025.8.0)\n",
            "Requirement already satisfied: catboost>=0.23.2 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (1.2.8)\n",
            "Requirement already satisfied: tune-sklearn>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (0.5.0)\n",
            "Requirement already satisfied: ray>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ray[tune]>=1.0.0; (python_version != \"3.11\" and platform_system != \"Windows\") and extra == \"full\"->pycaret[full]) (2.44.1)\n",
            "Requirement already satisfied: xgboost>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from pycaret[full]) (3.0.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from sktime==0.26.0->pycaret[full]) (25.0)\n",
            "Requirement already satisfied: scikit-base<0.8.0 in /usr/local/lib/python3.12/dist-packages (from sktime==0.26.0->pycaret[full]) (0.7.8)\n",
            "Requirement already satisfied: botocore<1.41.0,>=1.40.45 in /usr/local/lib/python3.12/dist-packages (from boto3>=1.24.56->pycaret[full]) (1.40.45)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from boto3>=1.24.56->pycaret[full]) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.15.0,>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from boto3>=1.24.56->pycaret[full]) (0.14.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost>=0.23.2->pycaret[full]) (0.21)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost>=0.23.2->pycaret[full]) (1.17.0)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from category-encoders>=2.4.0->pycaret[full]) (1.0.1)\n",
            "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.12/dist-packages (from dask>=2024.4.1->pycaret[full]) (8.3.0)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.12/dist-packages (from dask>=2024.4.1->pycaret[full]) (2025.3.0)\n",
            "Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from dask>=2024.4.1->pycaret[full]) (1.4.2)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from dask>=2024.4.1->pycaret[full]) (0.12.1)\n",
            "Requirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from distributed>=2024.4.1->pycaret[full]) (1.0.0)\n",
            "Requirement already satisfied: msgpack>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from distributed>=2024.4.1->pycaret[full]) (1.1.1)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.5 in /usr/local/lib/python3.12/dist-packages (from distributed>=2024.4.1->pycaret[full]) (2.4.0)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from distributed>=2024.4.1->pycaret[full]) (3.1.0)\n",
            "Requirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from distributed>=2024.4.1->pycaret[full]) (6.4.2)\n",
            "Requirement already satisfied: urllib3>=1.26.5 in /usr/local/lib/python3.12/dist-packages (from distributed>=2024.4.1->pycaret[full]) (1.26.20)\n",
            "Requirement already satisfied: zict>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from distributed>=2024.4.1->pycaret[full]) (3.0.0)\n",
            "Requirement already satisfied: nltk>=3.6.7 in /usr/local/lib/python3.12/dist-packages (from evidently~=0.4.16->pycaret[full]) (3.9.1)\n",
            "Requirement already satisfied: pydantic>=1.10.13 in /usr/local/lib/python3.12/dist-packages (from evidently~=0.4.16->pycaret[full]) (2.11.9)\n",
            "Requirement already satisfied: litestar>=2.8.3 in /usr/local/lib/python3.12/dist-packages (from evidently~=0.4.16->pycaret[full]) (2.17.0)\n",
            "Requirement already satisfied: typing-inspect>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from evidently~=0.4.16->pycaret[full]) (0.9.0)\n",
            "Requirement already satisfied: watchdog>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from evidently~=0.4.16->pycaret[full]) (6.0.0)\n",
            "Requirement already satisfied: typer>=0.3 in /usr/local/lib/python3.12/dist-packages (from evidently~=0.4.16->pycaret[full]) (0.19.2)\n",
            "Requirement already satisfied: rich>=13 in /usr/local/lib/python3.12/dist-packages (from evidently~=0.4.16->pycaret[full]) (13.9.4)\n",
            "Requirement already satisfied: iterative-telemetry>=0.0.5 in /usr/local/lib/python3.12/dist-packages (from evidently~=0.4.16->pycaret[full]) (0.0.10)\n",
            "Requirement already satisfied: dynaconf>=3.2.4 in /usr/local/lib/python3.12/dist-packages (from evidently~=0.4.16->pycaret[full]) (3.2.11)\n",
            "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.12/dist-packages (from evidently~=0.4.16->pycaret[full]) (2025.8.3)\n",
            "Requirement already satisfied: ujson>=5.4.0 in /usr/local/lib/python3.12/dist-packages (from evidently~=0.4.16->pycaret[full]) (5.11.0)\n",
            "Requirement already satisfied: uuid6>=2024.7.10 in /usr/local/lib/python3.12/dist-packages (from evidently~=0.4.16->pycaret[full]) (2025.0.1)\n",
            "Requirement already satisfied: cryptography>=43.0.1 in /usr/local/lib/python3.12/dist-packages (from evidently~=0.4.16->pycaret[full]) (43.0.3)\n",
            "Requirement already satisfied: dash-auth in /usr/local/lib/python3.12/dist-packages (from explainerdashboard>=0.3.8->pycaret[full]) (2.3.0)\n",
            "Requirement already satisfied: dash-bootstrap-components<3,>=1 in /usr/local/lib/python3.12/dist-packages (from explainerdashboard>=0.3.8->pycaret[full]) (1.7.1)\n",
            "Requirement already satisfied: dtreeviz>=2.1 in /usr/local/lib/python3.12/dist-packages (from explainerdashboard>=0.3.8->pycaret[full]) (2.2.2)\n",
            "Requirement already satisfied: flask-simplelogin in /usr/local/lib/python3.12/dist-packages (from explainerdashboard>=0.3.8->pycaret[full]) (0.2.0)\n",
            "Requirement already satisfied: flask-wtf>=1.1 in /usr/local/lib/python3.12/dist-packages (from explainerdashboard>=0.3.8->pycaret[full]) (1.2.2)\n",
            "Requirement already satisfied: jupyter-dash>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from explainerdashboard>=0.3.8->pycaret[full]) (0.4.2)\n",
            "Requirement already satisfied: oyaml in /usr/local/lib/python3.12/dist-packages (from explainerdashboard>=0.3.8->pycaret[full]) (1.0)\n",
            "Requirement already satisfied: waitress in /usr/local/lib/python3.12/dist-packages (from explainerdashboard>=0.3.8->pycaret[full]) (3.0.2)\n",
            "Requirement already satisfied: triad>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from fugue~=0.8.0->pycaret[full]) (0.9.8)\n",
            "Requirement already satisfied: adagio>=0.2.4 in /usr/local/lib/python3.12/dist-packages (from fugue~=0.8.0->pycaret[full]) (0.2.6)\n",
            "Requirement already satisfied: qpd>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from fugue~=0.8.0->pycaret[full]) (0.4.4)\n",
            "Requirement already satisfied: fugue-sql-antlr>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from fugue~=0.8.0->pycaret[full]) (0.2.2)\n",
            "Requirement already satisfied: sqlglot in /usr/local/lib/python3.12/dist-packages (from fugue~=0.8.0->pycaret[full]) (25.20.2)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.50.2->pycaret[full]) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.50.2->pycaret[full]) (4.11.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.50.2->pycaret[full]) (1.1.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio>=3.50.2->pycaret[full]) (0.6.1)\n",
            "Requirement already satisfied: gradio-client==1.13.3 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.50.2->pycaret[full]) (1.13.3)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.50.2->pycaret[full]) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.50.2->pycaret[full]) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.50.2->pycaret[full]) (0.35.3)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.50.2->pycaret[full]) (3.11.3)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.50.2->pycaret[full]) (11.3.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio>=3.50.2->pycaret[full]) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.50.2->pycaret[full]) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.50.2->pycaret[full]) (0.13.2)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.50.2->pycaret[full]) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.50.2->pycaret[full]) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.50.2->pycaret[full]) (0.48.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.50.2->pycaret[full]) (0.13.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.50.2->pycaret[full]) (4.15.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio>=3.50.2->pycaret[full]) (15.0.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.12/dist-packages (from hyperopt>=0.2.7->pycaret[full]) (3.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.12/dist-packages (from hyperopt>=0.2.7->pycaret[full]) (1.0.0)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.12/dist-packages (from hyperopt>=0.2.7->pycaret[full]) (0.10.9.7)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn>=0.12.0->pycaret[full]) (3.6.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata>=4.12.0->pycaret[full]) (3.23.0)\n",
            "Requirement already satisfied: interpret-core==0.7.2 in /usr/local/lib/python3.12/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret>=0.2.7->pycaret[full]) (0.7.2)\n",
            "Requirement already satisfied: ipykernel>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret>=0.2.7->pycaret[full]) (6.17.1)\n",
            "Requirement already satisfied: SALib>=1.3.3 in /usr/local/lib/python3.12/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret>=0.2.7->pycaret[full]) (1.5.1)\n",
            "Requirement already satisfied: dill>=0.2.5 in /usr/local/lib/python3.12/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret>=0.2.7->pycaret[full]) (0.3.8)\n",
            "Requirement already satisfied: aplr>=10.6.1 in /usr/local/lib/python3.12/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret>=0.2.7->pycaret[full]) (10.15.0)\n",
            "Requirement already satisfied: dash-cytoscape>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret>=0.2.7->pycaret[full]) (1.0.2)\n",
            "Requirement already satisfied: gevent>=1.3.6 in /usr/local/lib/python3.12/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret>=0.2.7->pycaret[full]) (25.9.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.12/dist-packages (from ipython>=5.5.0->pycaret[full]) (80.9.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.12/dist-packages (from ipython>=5.5.0->pycaret[full]) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython>=5.5.0->pycaret[full]) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=5.5.0->pycaret[full]) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.12/dist-packages (from ipython>=5.5.0->pycaret[full]) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=5.5.0->pycaret[full]) (3.0.52)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython>=5.5.0->pycaret[full]) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=5.5.0->pycaret[full]) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.12/dist-packages (from ipython>=5.5.0->pycaret[full]) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=5.5.0->pycaret[full]) (4.9.0)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets>=7.6.5->pycaret[full]) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets>=7.6.5->pycaret[full]) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets>=7.6.5->pycaret[full]) (3.0.15)\n",
            "Requirement already satisfied: choreographer>=1.0.10 in /usr/local/lib/python3.12/dist-packages (from kaleido>=0.2.1->pycaret[full]) (1.1.1)\n",
            "Requirement already satisfied: logistro>=1.0.8 in /usr/local/lib/python3.12/dist-packages (from kaleido>=0.2.1->pycaret[full]) (1.1.0)\n",
            "Requirement already satisfied: pytest-timeout>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from kaleido>=0.2.1->pycaret[full]) (2.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.8.0->pycaret[full]) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.8.0->pycaret[full]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.8.0->pycaret[full]) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.8.0->pycaret[full]) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.8.0->pycaret[full]) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.8.0->pycaret[full]) (2.9.0.post0)\n",
            "Requirement already satisfied: mlflow-skinny==3.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow>=2.0.0->pycaret[full]) (3.4.0)\n",
            "Requirement already satisfied: mlflow-tracing==3.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow>=2.0.0->pycaret[full]) (3.4.0)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.12/dist-packages (from mlflow>=2.0.0->pycaret[full]) (1.16.5)\n",
            "Requirement already satisfied: docker<8,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow>=2.0.0->pycaret[full]) (7.1.0)\n",
            "Requirement already satisfied: fastmcp<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow>=2.0.0->pycaret[full]) (2.12.4)\n",
            "Requirement already satisfied: graphene<4 in /usr/local/lib/python3.12/dist-packages (from mlflow>=2.0.0->pycaret[full]) (3.4.3)\n",
            "Requirement already satisfied: gunicorn<24 in /usr/local/lib/python3.12/dist-packages (from mlflow>=2.0.0->pycaret[full]) (23.0.0)\n",
            "Requirement already satisfied: pyarrow<22,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow>=2.0.0->pycaret[full]) (18.1.0)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow>=2.0.0->pycaret[full]) (2.0.43)\n",
            "Requirement already satisfied: cachetools<7,>=5.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow>=2.0.0->pycaret[full]) (5.5.2)\n",
            "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow>=2.0.0->pycaret[full]) (0.67.0)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow>=2.0.0->pycaret[full]) (3.1.45)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow>=2.0.0->pycaret[full]) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-proto<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow>=2.0.0->pycaret[full]) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow>=2.0.0->pycaret[full]) (1.37.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.12.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow>=2.0.0->pycaret[full]) (5.29.5)\n",
            "Requirement already satisfied: python-dotenv<2,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow>=2.0.0->pycaret[full]) (1.1.1)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow>=2.0.0->pycaret[full]) (0.5.3)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.12/dist-packages (from flask->pycaret[full]) (2.2.0)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.12/dist-packages (from flask->pycaret[full]) (1.9.0)\n",
            "Requirement already satisfied: xmltodict in /usr/local/lib/python3.12/dist-packages (from moto<5.0.0->pycaret[full]) (1.0.2)\n",
            "Requirement already satisfied: responses>=0.13.0 in /usr/local/lib/python3.12/dist-packages (from moto<5.0.0->pycaret[full]) (0.25.8)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat>=4.2.0->pycaret[full]) (2.21.2)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.12/dist-packages (from nbformat>=4.2.0->pycaret[full]) (4.23.0)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.12/dist-packages (from nbformat>=4.2.0->pycaret[full]) (5.8.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.55.0->pycaret[full]) (0.43.0)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.12/dist-packages (from optuna>=3.0.0->pycaret[full]) (6.9.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<2.2.0->pycaret[full]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.12/dist-packages (from pandas<2.2.0->pycaret[full]) (2025.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly>=5.14.0->pycaret[full]) (8.5.0)\n",
            "Requirement already satisfied: tsdownsample>=0.1.3 in /usr/local/lib/python3.12/dist-packages (from plotly-resampler>=0.8.3.1->pycaret[full]) (0.1.4.1)\n",
            "Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in /usr/local/lib/python3.12/dist-packages (from pmdarima>=2.0.4->pycaret[full]) (3.0.12)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.12/dist-packages (from pytest<8.0.0->pycaret[full]) (2.1.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from pytest<8.0.0->pycaret[full]) (1.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from ray>=1.0.0->ray[tune]>=1.0.0; (python_version != \"3.11\" and platform_system != \"Windows\") and extra == \"full\"->pycaret[full]) (3.19.1)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.12/dist-packages (from ray>=1.0.0->ray[tune]>=1.0.0; (python_version != \"3.11\" and platform_system != \"Windows\") and extra == \"full\"->pycaret[full]) (1.4.0)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.12/dist-packages (from ray>=1.0.0->ray[tune]>=1.0.0; (python_version != \"3.11\" and platform_system != \"Windows\") and extra == \"full\"->pycaret[full]) (1.7.0)\n",
            "Requirement already satisfied: tensorboardX>=1.9 in /usr/local/lib/python3.12/dist-packages (from ray[tune]>=1.0.0; (python_version != \"3.11\" and platform_system != \"Windows\") and extra == \"full\"->pycaret[full]) (2.6.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.27.1->pycaret[full]) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.27.1->pycaret[full]) (3.10)\n",
            "Requirement already satisfied: daal==2025.8.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn-intelex>=2023.0.1->pycaret[full]) (2025.8.0)\n",
            "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.12/dist-packages (from daal==2025.8.0->scikit-learn-intelex>=2023.0.1->pycaret[full]) (2022.2.0)\n",
            "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.12/dist-packages (from tbb==2022.*->daal==2025.8.0->scikit-learn-intelex>=2023.0.1->pycaret[full]) (1.4.0)\n",
            "Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize>=0.9.0->pycaret[full]) (25.7.0)\n",
            "Requirement already satisfied: slicer==0.0.7 in /usr/local/lib/python3.12/dist-packages (from shap~=0.44.0->pycaret[full]) (0.0.7)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.12/dist-packages (from umap-learn>=0.5.2->pycaret[full]) (0.5.13)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn>=0.17.6->pycaret[full]) (0.16.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost>=1.1.0->pycaret[full]) (2.26.2)\n",
            "Requirement already satisfied: visions<0.8.2,>=0.7.5 in /usr/local/lib/python3.12/dist-packages (from visions[type_image_path]<0.8.2,>=0.7.5->ydata-profiling>=4.3.1->pycaret[full]) (0.8.1)\n",
            "Requirement already satisfied: minify-html>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from ydata-profiling>=4.3.1->pycaret[full]) (0.16.4)\n",
            "Requirement already satisfied: filetype>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ydata-profiling>=4.3.1->pycaret[full]) (1.2.0)\n",
            "Requirement already satisfied: phik<0.13,>=0.11.1 in /usr/local/lib/python3.12/dist-packages (from ydata-profiling>=4.3.1->pycaret[full]) (0.12.5)\n",
            "Requirement already satisfied: seaborn<0.14,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from ydata-profiling>=4.3.1->pycaret[full]) (0.13.2)\n",
            "Requirement already satisfied: multimethod<2,>=1.4 in /usr/local/lib/python3.12/dist-packages (from ydata-profiling>=4.3.1->pycaret[full]) (1.12)\n",
            "Requirement already satisfied: typeguard<5,>=3 in /usr/local/lib/python3.12/dist-packages (from ydata-profiling>=4.3.1->pycaret[full]) (4.4.4)\n",
            "Requirement already satisfied: imagehash==4.3.1 in /usr/local/lib/python3.12/dist-packages (from ydata-profiling>=4.3.1->pycaret[full]) (4.3.1)\n",
            "Requirement already satisfied: wordcloud>=1.9.3 in /usr/local/lib/python3.12/dist-packages (from ydata-profiling>=4.3.1->pycaret[full]) (1.9.4)\n",
            "Requirement already satisfied: dacite>=1.8 in /usr/local/lib/python3.12/dist-packages (from ydata-profiling>=4.3.1->pycaret[full]) (1.9.2)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.12/dist-packages (from imagehash==4.3.1->ydata-profiling>=4.3.1->pycaret[full]) (1.9.0)\n",
            "Requirement already satisfied: dash-html-components==2.0.0 in /usr/local/lib/python3.12/dist-packages (from dash[testing]; extra == \"full\"->pycaret[full]) (2.0.0)\n",
            "Requirement already satisfied: dash-core-components==2.0.0 in /usr/local/lib/python3.12/dist-packages (from dash[testing]; extra == \"full\"->pycaret[full]) (2.0.0)\n",
            "Requirement already satisfied: dash-table==5.0.0 in /usr/local/lib/python3.12/dist-packages (from dash[testing]; extra == \"full\"->pycaret[full]) (5.0.0)\n",
            "Requirement already satisfied: retrying in /usr/local/lib/python3.12/dist-packages (from dash[testing]; extra == \"full\"->pycaret[full]) (1.4.2)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from dash[testing]; extra == \"full\"->pycaret[full]) (1.6.0)\n",
            "Requirement already satisfied: beautifulsoup4>=4.8.2 in /usr/local/lib/python3.12/dist-packages (from dash[testing]; extra == \"full\"->pycaret[full]) (4.13.5)\n",
            "Requirement already satisfied: lxml>=4.6.2 in /usr/local/lib/python3.12/dist-packages (from dash[testing]; extra == \"full\"->pycaret[full]) (5.4.0)\n",
            "Requirement already satisfied: percy>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from dash[testing]; extra == \"full\"->pycaret[full]) (2.0.2)\n",
            "Requirement already satisfied: selenium<=4.2.0,>=3.141.0 in /usr/local/lib/python3.12/dist-packages (from dash[testing]; extra == \"full\"->pycaret[full]) (4.2.0)\n",
            "Requirement already satisfied: multiprocess>=0.70.12 in /usr/local/lib/python3.12/dist-packages (from dash[testing]; extra == \"full\"->pycaret[full]) (0.70.16)\n",
            "Requirement already satisfied: dash-testing-stub>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from dash[testing]; extra == \"full\"->pycaret[full]) (0.0.2)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic!=1.10.0,<2->mlflow>=2.0.0->pycaret[full]) (1.3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio>=3.50.2->pycaret[full]) (1.3.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.8.2->dash[testing]; extra == \"full\"->pycaret[full]) (2.8)\n",
            "Requirement already satisfied: simplejson>=3.19.3 in /usr/local/lib/python3.12/dist-packages (from choreographer>=1.0.10->kaleido>=0.2.1->pycaret[full]) (3.20.2)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=43.0.1->evidently~=0.4.16->pycaret[full]) (2.0.0)\n",
            "Requirement already satisfied: colour in /usr/local/lib/python3.12/dist-packages (from dtreeviz>=2.1->explainerdashboard>=0.3.8->pycaret[full]) (0.1.5)\n",
            "Requirement already satisfied: authlib>=1.5.2 in /usr/local/lib/python3.12/dist-packages (from fastmcp<3,>=2.0.0->mlflow>=2.0.0->pycaret[full]) (1.6.4)\n",
            "Requirement already satisfied: cyclopts>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from fastmcp<3,>=2.0.0->mlflow>=2.0.0->pycaret[full]) (3.24.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.2.2 in /usr/local/lib/python3.12/dist-packages (from fastmcp<3,>=2.0.0->mlflow>=2.0.0->pycaret[full]) (1.3.0)\n",
            "Requirement already satisfied: mcp<2.0.0,>=1.12.4 in /usr/local/lib/python3.12/dist-packages (from fastmcp<3,>=2.0.0->mlflow>=2.0.0->pycaret[full]) (1.15.0)\n",
            "Requirement already satisfied: openapi-core>=0.19.5 in /usr/local/lib/python3.12/dist-packages (from fastmcp<3,>=2.0.0->mlflow>=2.0.0->pycaret[full]) (0.19.5)\n",
            "Requirement already satisfied: openapi-pydantic>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from fastmcp<3,>=2.0.0->mlflow>=2.0.0->pycaret[full]) (0.5.1)\n",
            "Requirement already satisfied: pyperclip>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from fastmcp<3,>=2.0.0->mlflow>=2.0.0->pycaret[full]) (1.11.0)\n",
            "Requirement already satisfied: wtforms in /usr/local/lib/python3.12/dist-packages (from flask-wtf>=1.1->explainerdashboard>=0.3.8->pycaret[full]) (3.2.1)\n",
            "Requirement already satisfied: antlr4-python3-runtime<4.12 in /usr/local/lib/python3.12/dist-packages (from fugue-sql-antlr>=0.1.6->fugue~=0.8.0->pycaret[full]) (4.9.3)\n",
            "Requirement already satisfied: graphql-core<3.3,>=3.1 in /usr/local/lib/python3.12/dist-packages (from graphene<4->mlflow>=2.0.0->pycaret[full]) (3.2.6)\n",
            "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /usr/local/lib/python3.12/dist-packages (from graphene<4->mlflow>=2.0.0->pycaret[full]) (3.2.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio>=3.50.2->pycaret[full]) (1.0.9)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio>=3.50.2->pycaret[full]) (1.1.10)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret>=0.2.7->pycaret[full]) (1.8.15)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret>=0.2.7->pycaret[full]) (7.4.9)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret>=0.2.7->pycaret[full]) (26.2.1)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.12/dist-packages (from iterative-telemetry>=0.0.5->evidently~=0.4.16->pycaret[full]) (1.4.4)\n",
            "Requirement already satisfied: distro in /usr/local/lib/python3.12/dist-packages (from iterative-telemetry>=0.0.5->evidently~=0.4.16->pycaret[full]) (1.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=5.5.0->pycaret[full]) (0.8.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret[full]) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret[full]) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret[full]) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret[full]) (0.27.1)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=4.2.0->pycaret[full]) (4.4.0)\n",
            "Requirement already satisfied: ansi2html in /usr/local/lib/python3.12/dist-packages (from jupyter-dash>=0.4.1->explainerdashboard>=0.3.8->pycaret[full]) (1.9.2)\n",
            "Requirement already satisfied: litestar-htmx>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from litestar>=2.8.3->evidently~=0.4.16->pycaret[full]) (0.5.0)\n",
            "Requirement already satisfied: msgspec>=0.18.2 in /usr/local/lib/python3.12/dist-packages (from litestar>=2.8.3->evidently~=0.4.16->pycaret[full]) (0.19.0)\n",
            "Requirement already satisfied: multidict>=6.0.2 in /usr/local/lib/python3.12/dist-packages (from litestar>=2.8.3->evidently~=0.4.16->pycaret[full]) (6.6.4)\n",
            "Requirement already satisfied: multipart>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from litestar>=2.8.3->evidently~=0.4.16->pycaret[full]) (1.3.0)\n",
            "Requirement already satisfied: polyfactory>=2.6.3 in /usr/local/lib/python3.12/dist-packages (from litestar>=2.8.3->evidently~=0.4.16->pycaret[full]) (2.22.2)\n",
            "Requirement already satisfied: rich-click in /usr/local/lib/python3.12/dist-packages (from litestar>=2.8.3->evidently~=0.4.16->pycaret[full]) (1.9.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>=3.6.7->evidently~=0.4.16->pycaret[full]) (2024.11.6)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython>=5.5.0->pycaret[full]) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.5.0->pycaret[full]) (0.2.14)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.10.13->evidently~=0.4.16->pycaret[full]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.10.13->evidently~=0.4.16->pycaret[full]) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.10.13->evidently~=0.4.16->pycaret[full]) (0.4.2)\n",
            "Collecting antlr4-python3-runtime<4.12 (from fugue-sql-antlr>=0.1.6->fugue~=0.8.0->pycaret[full])\n",
            "  Using cached antlr4_python3_runtime-4.11.1-py3-none-any.whl.metadata (291 bytes)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13->evidently~=0.4.16->pycaret[full]) (4.0.0)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.12/dist-packages (from selenium<=4.2.0,>=3.141.0->dash[testing]; extra == \"full\"->pycaret[full]) (0.31.0)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.12/dist-packages (from selenium<=4.2.0,>=3.141.0->dash[testing]; extra == \"full\"->pycaret[full]) (0.12.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow>=2.0.0->pycaret[full]) (3.2.4)\n",
            "Requirement already satisfied: fs in /usr/local/lib/python3.12/dist-packages (from triad>=0.9.3->fugue~=0.8.0->pycaret[full]) (2.4.16)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.3->evidently~=0.4.16->pycaret[full]) (1.5.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect>=0.9.0->evidently~=0.4.16->pycaret[full]) (1.1.0)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.22.0->evidently~=0.4.16->pycaret[full]) (0.6.4)\n",
            "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.22.0->evidently~=0.4.16->pycaret[full]) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.22.0->evidently~=0.4.16->pycaret[full]) (1.1.0)\n",
            "Requirement already satisfied: puremagic in /usr/local/lib/python3.12/dist-packages (from visions<0.8.2,>=0.7.5->visions[type_image_path]<0.8.2,>=0.7.5->ydata-profiling>=4.3.1->pycaret[full]) (1.30)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.12/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (6.5.7)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=43.0.1->evidently~=0.4.16->pycaret[full]) (2.23)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.12/dist-packages (from cyclopts>=3.0.0->fastmcp<3,>=2.0.0->mlflow>=2.0.0->pycaret[full]) (0.17.0)\n",
            "Requirement already satisfied: rich-rst<2.0.0,>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from cyclopts>=3.0.0->fastmcp<3,>=2.0.0->mlflow>=2.0.0->pycaret[full]) (1.3.1)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.12/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.4.0->mlflow>=2.0.0->pycaret[full]) (2.38.0)\n",
            "Requirement already satisfied: zope.event in /usr/local/lib/python3.12/dist-packages (from gevent>=1.3.6->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret>=0.2.7->pycaret[full]) (6.0)\n",
            "Requirement already satisfied: zope.interface in /usr/local/lib/python3.12/dist-packages (from gevent>=1.3.6->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret>=0.2.7->pycaret[full]) (8.0.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.4.0->mlflow>=2.0.0->pycaret[full]) (4.0.12)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.2->interpret>=0.2.7->pycaret[full]) (0.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=13->evidently~=0.4.16->pycaret[full]) (0.1.2)\n",
            "Requirement already satisfied: httpx-sse>=0.4 in /usr/local/lib/python3.12/dist-packages (from mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow>=2.0.0->pycaret[full]) (0.4.1)\n",
            "Requirement already satisfied: pydantic-settings>=2.5.2 in /usr/local/lib/python3.12/dist-packages (from mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow>=2.0.0->pycaret[full]) (2.11.0)\n",
            "Requirement already satisfied: sse-starlette>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow>=2.0.0->pycaret[full]) (3.0.2)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (25.1.0)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (7.16.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (0.23.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (1.3.3)\n",
            "Requirement already satisfied: isodate in /usr/local/lib/python3.12/dist-packages (from openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow>=2.0.0->pycaret[full]) (0.7.2)\n",
            "Requirement already satisfied: jsonschema-path<0.4.0,>=0.3.1 in /usr/local/lib/python3.12/dist-packages (from openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow>=2.0.0->pycaret[full]) (0.3.4)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow>=2.0.0->pycaret[full]) (10.8.0)\n",
            "Requirement already satisfied: openapi-schema-validator<0.7.0,>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow>=2.0.0->pycaret[full]) (0.6.3)\n",
            "Requirement already satisfied: openapi-spec-validator<0.8.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow>=2.0.0->pycaret[full]) (0.7.2)\n",
            "Requirement already satisfied: parse in /usr/local/lib/python3.12/dist-packages (from openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow>=2.0.0->pycaret[full]) (1.20.2)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.4.0->mlflow>=2.0.0->pycaret[full]) (0.58b0)\n",
            "Requirement already satisfied: faker>=5.0.0 in /usr/local/lib/python3.12/dist-packages (from polyfactory>=2.6.3->litestar>=2.8.3->evidently~=0.4.16->pycaret[full]) (37.8.0)\n",
            "Requirement already satisfied: email-validator>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pydantic[email]>=2.11.7->fastmcp<3,>=2.0.0->mlflow>=2.0.0->pycaret[full]) (2.3.0)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.12/dist-packages (from trio~=0.17->selenium<=4.2.0,>=3.141.0->dash[testing]; extra == \"full\"->pycaret[full]) (1.3.0.post0)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.12/dist-packages (from trio-websocket~=0.9->selenium<=4.2.0,>=3.141.0->dash[testing]; extra == \"full\"->pycaret[full]) (1.2.0)\n",
            "Requirement already satisfied: pyOpenSSL>=0.14 in /usr/local/lib/python3.12/dist-packages (from urllib3[secure,socks]~=1.26->selenium<=4.2.0,>=3.141.0->dash[testing]; extra == \"full\"->pycaret[full]) (24.2.1)\n",
            "Requirement already satisfied: urllib3-secure-extra in /usr/local/lib/python3.12/dist-packages (from urllib3[secure,socks]~=1.26->selenium<=4.2.0,>=3.141.0->dash[testing]; extra == \"full\"->pycaret[full]) (0.1.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from urllib3[secure,socks]~=1.26->selenium<=4.2.0,>=3.141.0->dash[testing]; extra == \"full\"->pycaret[full]) (1.7.1)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from email-validator>=2.0.0->pydantic[email]>=2.11.7->fastmcp<3,>=2.0.0->mlflow>=2.0.0->pycaret[full]) (2.8.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.4.0->mlflow>=2.0.0->pycaret[full]) (5.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.4.0->mlflow>=2.0.0->pycaret[full]) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.4.0->mlflow>=2.0.0->pycaret[full]) (4.9.1)\n",
            "Requirement already satisfied: pathable<0.5.0,>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema-path<0.4.0,>=0.3.1->openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow>=2.0.0->pycaret[full]) (0.4.4)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.12/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (0.2.4)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (3.1.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (1.5.1)\n",
            "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.12/dist-packages (from openapi-schema-validator<0.7.0,>=0.6.0->openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow>=2.0.0->pycaret[full]) (0.1.4)\n",
            "Requirement already satisfied: lazy-object-proxy<2.0.0,>=1.7.1 in /usr/local/lib/python3.12/dist-packages (from openapi-spec-validator<0.8.0,>=0.7.1->openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow>=2.0.0->pycaret[full]) (1.12.0)\n",
            "Requirement already satisfied: docutils in /usr/local/lib/python3.12/dist-packages (from rich-rst<2.0.0,>=1.3.1->cyclopts>=3.0.0->fastmcp<3,>=2.0.0->mlflow>=2.0.0->pycaret[full]) (0.21.2)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.12/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (25.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (1.4.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.12/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (2.14.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.4.0->mlflow>=2.0.0->pycaret[full]) (0.6.1)\n",
            "Requirement already satisfied: jupyter-events>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (0.12.0)\n",
            "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (0.5.3)\n",
            "Requirement already satisfied: overrides>=5.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (7.7.0)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (1.8.0)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (3.3.0)\n",
            "Requirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (0.1.1)\n",
            "Requirement already satisfied: fqdn in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (1.5.1)\n",
            "Requirement already satisfied: isoduration in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (20.11.0)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (3.0.0)\n",
            "Requirement already satisfied: uri-template in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (1.3.0)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (24.11.1)\n",
            "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (1.3.0)\n",
            "Requirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.12/dist-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (2.9.0.20250822)\n",
            "Using cached fugue-0.8.7-py3-none-any.whl (279 kB)\n",
            "Using cached statsforecast-1.5.0-py3-none-any.whl (99 kB)\n",
            "Using cached antlr4_python3_runtime-4.11.1-py3-none-any.whl (144 kB)\n",
            "Installing collected packages: antlr4-python3-runtime, fugue, statsforecast\n",
            "  Attempting uninstall: antlr4-python3-runtime\n",
            "    Found existing installation: antlr4-python3-runtime 4.9.3\n",
            "    Uninstalling antlr4-python3-runtime-4.9.3:\n",
            "      Successfully uninstalled antlr4-python3-runtime-4.9.3\n",
            "  Attempting uninstall: fugue\n",
            "    Found existing installation: fugue 0.9.1\n",
            "    Uninstalling fugue-0.9.1:\n",
            "      Successfully uninstalled fugue-0.9.1\n",
            "  Attempting uninstall: statsforecast\n",
            "    Found existing installation: statsforecast 2.0.1\n",
            "    Uninstalling statsforecast-2.0.1:\n",
            "      Successfully uninstalled statsforecast-2.0.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "autogluon-timeseries 1.4.0 requires fugue>=0.9.0, but you have fugue 0.8.7 which is incompatible.\n",
            "autogluon-timeseries 1.4.0 requires statsforecast<2.0.2,>=1.7.0, but you have statsforecast 1.5.0 which is incompatible.\n",
            "omegaconf 2.3.0 requires antlr4-python3-runtime==4.9.*, but you have antlr4-python3-runtime 4.11.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed antlr4-python3-runtime-4.11.1 fugue-0.8.7 statsforecast-1.5.0\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.12/dist-packages (0.14.0)\n",
            "Requirement already satisfied: numpy<3,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy<2,>=1.11.4 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (1.4.2)\n",
            "Requirement already satisfied: joblib<2,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (3.6.0)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Descomente no Colab:\n",
        "!pip install --no-build-isolation autogluon\n",
        "!pip install flaml\n",
        "!pip install pycaret[full]\n",
        "!pip install imbalanced-learn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0aa8c3a6",
      "metadata": {
        "id": "0aa8c3a6"
      },
      "source": [
        "## 1) Robust reading (fixes ParserError)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ef2fa64",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ef2fa64",
        "outputId": "1999e63a-f520-4439-8ea2-b7e22b734131"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyCaret indisponível. Instale se quiser usar. ('Pycaret only supports python 3.9, 3.10, 3.11. Your actual Python version: ', sys.version_info(major=3, minor=12, micro=11, releaselevel='final', serial=0), 'Please DOWNGRADE your Python version.')\n"
          ]
        }
      ],
      "source": [
        "import os, json, csv, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
        "from functools import reduce\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report, f1_score, recall_score, precision_score,\n",
        "    roc_curve, roc_auc_score, precision_recall_curve, average_precision_score,\n",
        "    ConfusionMatrixDisplay\n",
        ")\n",
        "\n",
        "# AutoML libs\n",
        "try:\n",
        "    from autogluon.tabular import TabularPredictor\n",
        "    _AG_OK = True\n",
        "except Exception as e:\n",
        "    print(\"AutoGluon indisponível. Instale se quiser usar.\", e); _AG_OK = False\n",
        "\n",
        "try:\n",
        "    from flaml import AutoML\n",
        "    _FLAML_OK = True\n",
        "except Exception as e:\n",
        "    print(\"FLAML indisponível. Instale se quiser usar.\", e); _FLAML_OK = False\n",
        "\n",
        "try:\n",
        "    from pycaret.classification import setup as pc_setup, compare_models, finalize_model, predict_model\n",
        "    _PYCARET_OK = True\n",
        "except Exception as e:\n",
        "    print(\"PyCaret indisponível. Instale se quiser usar.\", e); _PYCARET_OK = False\n",
        "\n",
        "# Configs\n",
        "RANDOM_STATE = 42\n",
        "TEST_SIZE = 0.2\n",
        "EVAL_METRIC = 'f1'\n",
        "IMBALANCE_STRATEGY = 'weights'  # 'weights' | 'smote' | None\n",
        "\n",
        "NASA_FILES = [\n",
        "    'k2pandc_2025.10.03_15.51.12.csv',\n",
        "    'cumulative_2025.10.03_16.08.03.csv',\n",
        "    'TOI_2025.10.03_16.04.34.csv',\n",
        "]\n",
        "UNION_MODE = 'concat'  # 'concat' ou 'merge'\n",
        "MERGE_KEYS = []\n",
        "\n",
        "READ_PARAMS = {'sep': ',', 'engine': 'python', 'encoding': 'utf-8'}\n",
        "\n",
        "COLUMN_MAP = {\n",
        "    'period':                'koi_period',\n",
        "    'transit_epoch_bjd':     'koi_time0bk',\n",
        "    'transit_duration_hrs':  'koi_duration',\n",
        "    'transit_depth_ppm':     'koi_depth',\n",
        "    'planet_radius_earth':   'koi_prad',\n",
        "    'star_radius_sol':       'koi_srad',\n",
        "    'star_teff':             'koi_steff',\n",
        "    'star_logg':             'koi_slogg',\n",
        "    'disposition_text':      'koi_disposition',\n",
        "    'source':                None,\n",
        "}\n",
        "\n",
        "POSITIVE_LABELS = ['CONFIRMED', 'CANDIDATE', 'PC', 'CP', 'PUBLISHED CONFIRMED']\n",
        "\n",
        "MASTER_OUT = 'nasa_master_clean.csv'\n",
        "REPORT_THR_CSV = 'report_thresholds.csv'\n",
        "REPORT_FN_CSV  = 'report_false_negatives.csv'\n",
        "\n",
        "TARGET = 'target_encoded'\n",
        "DROP_COLS = ['disposition_text', 'source']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8cd12042",
      "metadata": {
        "id": "8cd12042"
      },
      "source": [
        "## 2) Normalization → data + target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b45985c3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b45985c3",
        "outputId": "7d1b4bc9-1f20-4dc1-b2b7-8c3fc6770f9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ k2pandc_2025.10.03_15.51.12.csv | sep=, enc=utf-8 skip=98 shape=(4004, 95)\n",
            "✅ cumulative_2025.10.03_16.08.03.csv | sep=, enc=utf-8 skip=7 shape=(9564, 49)\n",
            "✅ TOI_2025.10.03_16.04.34.csv | sep=, enc=utf-8 skip=69 shape=(7703, 65)\n",
            "🔹 raw: (21271, 174)\n"
          ]
        }
      ],
      "source": [
        "HEADER_HINTS = ['koi_', 'kep', 'kepler', 'pl_', 'st_', 'tfopwg', 'tic', 'toi_', 'disposition', 'tfopwg_disp']\n",
        "\n",
        "def infer_header_row(text, max_lines=200):\n",
        "    lines = text.splitlines()\n",
        "    best_idx, best_score = 0, -1\n",
        "    for i, ln in enumerate(lines[:max_lines]):\n",
        "        s = sum(h in ln.lower() for h in HEADER_HINTS)\n",
        "        if s > best_score:\n",
        "            best_idx, best_score = i, s\n",
        "    return best_idx\n",
        "\n",
        "def sniff_sep(text):\n",
        "    try:\n",
        "        return csv.Sniffer().sniff(text, delimiters=[',',';','\\t','|']).delimiter\n",
        "    except Exception:\n",
        "        for cand in [',',';','\\t','|']:\n",
        "            if cand in text: return cand\n",
        "    return ','\n",
        "\n",
        "def smart_read_csv(fp, base_params=None, preview_bytes=200_000):\n",
        "    base_params = base_params or {}\n",
        "    with open(fp, 'rb') as f:\n",
        "        sample = f.read(preview_bytes)\n",
        "    encoding = None\n",
        "    for enc in ['utf-8', 'latin-1']:\n",
        "        try:\n",
        "            text = sample.decode(enc)\n",
        "            encoding = enc; break\n",
        "        except UnicodeDecodeError:\n",
        "            pass\n",
        "    if encoding is None:\n",
        "        text = sample.decode('latin-1', errors='replace'); encoding = 'latin-1'\n",
        "    sep = sniff_sep(text)\n",
        "    header_row = infer_header_row(text)\n",
        "\n",
        "\n",
        "    params = dict(\n",
        "    sep=sep,\n",
        "    encoding=encoding,\n",
        "    engine='python',\n",
        "    on_bad_lines='skip',\n",
        "    comment='#',\n",
        "    skiprows=header_row\n",
        ")\n",
        "\n",
        "    params.update(base_params or {})\n",
        "    df = pd.read_csv(fp, **params)\n",
        "    return df, dict(sep=sep, encoding=encoding, skiprows=header_row)\n",
        "\n",
        "# Leitura\n",
        "assert len(NASA_FILES) > 0, \"Preencha 'NASA_FILES' com pelo menos um CSV.\"\n",
        "dfs, meta_report = [], []\n",
        "for fp in NASA_FILES:\n",
        "    try:\n",
        "        df_i, meta = smart_read_csv(fp, READ_PARAMS)\n",
        "        dfs.append(df_i)\n",
        "        meta_report.append({'file': os.path.basename(fp), **meta, 'shape': df_i.shape})\n",
        "        print(f\"✅ {fp} | sep={meta['sep']} enc={meta['encoding']} skip={meta['skiprows']} shape={df_i.shape}\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Falha ao ler {fp}: {e}\")\n",
        "\n",
        "if UNION_MODE == 'concat':\n",
        "    raw = pd.concat(dfs, ignore_index=True)\n",
        "elif UNION_MODE == 'merge':\n",
        "    assert len(dfs) >= 2 and MERGE_KEYS, \"Para 'merge', forneça >=2 arquivos e MERGE_KEYS.\"\n",
        "    raw = reduce(lambda l, r: pd.merge(l, r, on=MERGE_KEYS, how='outer'), dfs)\n",
        "else:\n",
        "    raise ValueError(\"UNION_MODE inválido.\")\n",
        "\n",
        "print(\"🔹 raw:\", raw.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46ccd4a5",
      "metadata": {
        "id": "46ccd4a5"
      },
      "source": [
        "## 3) Cleaning (core NaNs + outliers) → df_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c86c2afa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "id": "c86c2afa",
        "outputId": "d53a0b54-626c-45c5-97d7-81bc38fb502c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 data: (21271, 11) | positivos: 4725\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "repr_error": "Out of range float values are not JSON compliant: nan",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-106377fc-86e4-4faf-9b2a-a1896767d7b8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>period</th>\n",
              "      <th>transit_epoch_bjd</th>\n",
              "      <th>transit_duration_hrs</th>\n",
              "      <th>transit_depth_ppm</th>\n",
              "      <th>planet_radius_earth</th>\n",
              "      <th>star_radius_sol</th>\n",
              "      <th>star_teff</th>\n",
              "      <th>star_logg</th>\n",
              "      <th>disposition_text</th>\n",
              "      <th>source</th>\n",
              "      <th>target_encoded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NASA</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NASA</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NASA</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-106377fc-86e4-4faf-9b2a-a1896767d7b8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-106377fc-86e4-4faf-9b2a-a1896767d7b8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-106377fc-86e4-4faf-9b2a-a1896767d7b8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-362b2c0a-30f6-4e97-94c9-9362bd2febea\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-362b2c0a-30f6-4e97-94c9-9362bd2febea')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-362b2c0a-30f6-4e97-94c9-9362bd2febea button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   period  transit_epoch_bjd  transit_duration_hrs  transit_depth_ppm  \\\n",
              "0     NaN                NaN                   NaN                NaN   \n",
              "1     NaN                NaN                   NaN                NaN   \n",
              "2     NaN                NaN                   NaN                NaN   \n",
              "\n",
              "   planet_radius_earth  star_radius_sol  star_teff  star_logg  \\\n",
              "0                  NaN              NaN        NaN        NaN   \n",
              "1                  NaN              NaN        NaN        NaN   \n",
              "2                  NaN              NaN        NaN        NaN   \n",
              "\n",
              "  disposition_text source  target_encoded  \n",
              "0              NaN   NASA               0  \n",
              "1              NaN   NASA               0  \n",
              "2              NaN   NASA               0  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def normalize_columns(df, colmap):\n",
        "    out = pd.DataFrame(index=df.index.copy())\n",
        "    for std, src in colmap.items():\n",
        "        out[std] = df[src] if (src and src in df.columns) else np.nan\n",
        "    return out\n",
        "\n",
        "data = normalize_columns(raw, COLUMN_MAP)\n",
        "if 'source' in data.columns and data['source'].isna().all():\n",
        "    data['source'] = 'NASA'\n",
        "\n",
        "data[TARGET] = data['disposition_text'].apply(\n",
        "    lambda x: 1 if pd.notna(x) and str(x).upper() in [p.upper() for p in POSITIVE_LABELS] else 0\n",
        ")\n",
        "\n",
        "print(\"🔹 data:\", data.shape, \"| positivos:\", int((data[TARGET]==1).sum()))\n",
        "display(data.head(3))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ea34821",
      "metadata": {
        "id": "8ea34821"
      },
      "source": [
        "## 4) Split + class weighting for imbalance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d606d6a8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "id": "d606d6a8",
        "outputId": "da7223fd-3784-4f37-baef-68b80a79adf7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes: (3964, 9) (992, 9)\n",
            "Balance (train):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>target_encoded</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1199</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "target_encoded\n",
              "1    2765\n",
              "0    1199\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pesos: {1: 0.7168173598553346, 0: 1.6530442035029191}\n"
          ]
        }
      ],
      "source": [
        "X = df_final[[c for c in df_final.columns if c not in DROP_COLS + [TARGET]]].copy()\n",
        "y = df_final[TARGET].astype(int).copy()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=TEST_SIZE, stratify=y, random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "train_df = X_train.copy(); train_df[TARGET] = y_train.values\n",
        "test_df  = X_test.copy();  test_df[TARGET]  = y_test.values\n",
        "\n",
        "print(\"Shapes:\", train_df.shape, test_df.shape)\n",
        "print(\"Balance (train):\"); display(train_df[TARGET].value_counts())\n",
        "\n",
        "# Pesos por classe (simples) -> coluna 'sample_weight'\n",
        "if IMBALANCE_STRATEGY == 'weights':\n",
        "    counts = train_df[TARGET].value_counts()\n",
        "    w_map = (len(train_df) / (2.0*counts)).to_dict()  # balanceia 0 e 1\n",
        "    train_df['sample_weight'] = train_df[TARGET].map(w_map).astype('float32')\n",
        "    print(\"Pesos:\", w_map)\n",
        "else:\n",
        "    print(\"Sem pesos explicitos (IMBALANCE_STRATEGY != 'weights').\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21c44105",
      "metadata": {
        "id": "21c44105"
      },
      "source": [
        "## 5) Helper functions (thresholds + reports)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9325fe9c",
      "metadata": {
        "id": "9325fe9c"
      },
      "outputs": [],
      "source": [
        "def _pos_proba(proba):\n",
        "    # garante vetor 1D da classe positiva\n",
        "    if isinstance(proba, pd.DataFrame):\n",
        "        return proba[1].to_numpy() if 1 in proba.columns else proba.iloc[:,-1].to_numpy()\n",
        "    arr = np.asarray(proba)\n",
        "    return arr[:, -1] if arr.ndim == 2 else arr\n",
        "\n",
        "def sweep_thresholds(y_true, proba, thresholds):\n",
        "    p = _pos_proba(proba); rows = []\n",
        "    for thr in thresholds:\n",
        "        y_pred = (p >= thr).astype(int)\n",
        "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "        acc  = (tp+tn)/(tp+tn+fp+fn)\n",
        "        rec  = recall_score(y_true, y_pred, zero_division=0)\n",
        "        prec = precision_score(y_true, y_pred, zero_division=0)\n",
        "        f1   = f1_score(y_true, y_pred, zero_division=0)\n",
        "        spec = tn/(tn+fp) if (tn+fp)>0 else 0.0\n",
        "        rows.append({'threshold':thr,'TP':tp,'FP':fp,'FN':fn,'TN':tn,\n",
        "                     'FN_rate(%)':100*fn/(tp+fn) if (tp+fn)>0 else 0,\n",
        "                     'Precision':prec,'Recall':rec,'F1':f1,'Specificity':spec,'Accuracy':acc})\n",
        "    return pd.DataFrame(rows).sort_values('threshold').reset_index(drop=True)\n",
        "\n",
        "def best_threshold(y_true, proba, optimize='f1', min_recall=None):\n",
        "    p = _pos_proba(proba); ts = np.linspace(0.01,0.99,99)\n",
        "    if min_recall is not None:\n",
        "        cands = []\n",
        "        for thr in ts:\n",
        "            y_pred=(p>=thr).astype(int)\n",
        "            if recall_score(y_true,y_pred,zero_division=0) >= min_recall:\n",
        "                cands.append(thr)\n",
        "        return max(cands) if cands else None\n",
        "    best_thr, best_score = 0.5, -1\n",
        "    for thr in ts:\n",
        "        y_pred=(p>=thr).astype(int)\n",
        "        score = f1_score(y_true,y_pred,zero_division=0) if optimize=='f1' else recall_score(y_true,y_pred,zero_division=0)\n",
        "        if score>best_score: best_score, best_thr = score, thr\n",
        "    return best_thr\n",
        "\n",
        "def final_reports(y_true, proba, thr, title_prefix=\"\"):\n",
        "    p = _pos_proba(proba)\n",
        "    y_pred = (p>=thr).astype(int)\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    print(f\"{title_prefix}TP={tp} | FP={fp} | FN={fn} | TN={tn}\")\n",
        "    print(classification_report(y_true, y_pred, digits=3))\n",
        "    ConfusionMatrixDisplay(confusion_matrix=[[tn,fp],[fn,tp]]).plot()\n",
        "    plt.title(f\"{title_prefix}Matriz de Confusão (thr={thr:.2f})\"); plt.show()\n",
        "    fpr,tpr,_=roc_curve(y_true,p); auc=roc_auc_score(y_true,p)\n",
        "    plt.figure(); plt.plot(fpr,tpr); plt.plot([0,1],[0,1],'--'); plt.title(f\"{title_prefix}ROC (AUC={auc:.3f})\"); plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.show()\n",
        "    prec,rec,_=precision_recall_curve(y_true,p); ap=average_precision_score(y_true,p)\n",
        "    plt.figure(); plt.plot(rec,prec); plt.title(f\"{title_prefix}Precision-Recall (AP={ap:.3f})\"); plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e29fedc5",
      "metadata": {
        "id": "e29fedc5"
      },
      "source": [
        "## 6) AutoGluon (com sample_weight no construtor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e353caa5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "e353caa5",
        "outputId": "71dfdbdf-084a-4463-bc8e-09c5678aaf59"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20251004_215642\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.4.0\n",
            "Python Version:     3.12.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Sat Sep  6 09:54:41 UTC 2025\n",
            "CPU Count:          2\n",
            "Memory Avail:       9.22 GB / 12.67 GB (72.8%)\n",
            "Disk Space Avail:   59.60 GB / 107.72 GB (55.3%)\n",
            "===================================================\n",
            "Presets specified: ['best_quality']\n",
            "Warning: hyperparameter tuning is currently experimental and may cause the process to hang.\n",
            "Using hyperparameters preset: hyperparameters='zeroshot'\n",
            "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
            "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
            "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
            "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
            "\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n",
            "\t\tContext path: \"/content/AutogluonModels/ag-20251004_215642/ds_sub_fit/sub_fit_ho\"\n",
            "Leaderboard on holdout data (DyStack):\n",
            "                          model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0           WeightedEnsemble_L2       0.855027   0.813987          f1        0.934382       1.555831  154.173023                 0.005502                0.004680           1.140002            2       True         64\n",
            "1           WeightedEnsemble_L3       0.855027   0.813987          f1        0.935874       1.556711  154.136958                 0.006993                0.005560           1.103937            3       True         65\n",
            "2           XGBoost_r194_BAG_L1       0.854836   0.875806          f1        0.055711       0.072915   20.984499                 0.055711                0.072915          20.984499            1       True         18\n",
            "3        ExtraTrees_r178_BAG_L1       0.854836   0.874095          f1        0.117803       0.246605    5.094396                 0.117803                0.246605           5.094396            1       True         42\n",
            "4       RandomForest_r15_BAG_L1       0.849292   0.880615          f1        0.103287       0.217791    7.852690                 0.103287                0.217791           7.852690            1       True         46\n",
            "5            XGBoost_r22_BAG_L1       0.846057   0.875430          f1        0.060219       0.135926   17.408836                 0.060219                0.135926          17.408836            1       True         48\n",
            "6            XGBoost_r95_BAG_L1       0.845642   0.875660          f1        0.041236       0.058714   21.373297                 0.041236                0.058714          21.373297            1       True         61\n",
            "7        ExtraTrees_r172_BAG_L1       0.844342   0.875401          f1        0.132046       0.218435    2.056591                 0.132046                0.218435           2.056591            1       True         19\n",
            "8            XGBoost_r89_BAG_L1       0.843797   0.875963          f1        0.086840       0.162806   19.685070                 0.086840                0.162806          19.685070            1       True         15\n",
            "9          LightGBMLarge_BAG_L1       0.842622   0.794377          f1        3.257005       0.068549   42.188594                 3.257005                0.068549          42.188594            1       True          5\n",
            "10       ExtraTrees_r126_BAG_L1       0.841458   0.871058          f1        0.109271       0.300925    3.172054                 0.109271                0.300925           3.172054            1       True         58\n",
            "11          LightGBM_r15_BAG_L1       0.840929   0.867213          f1        0.032976       0.140872   30.517066                 0.032976                0.140872          30.517066            1       True         28\n",
            "12           XGBoost_r31_BAG_L1       0.839751   0.872426          f1        0.076893       0.057445   18.017893                 0.076893                0.057445          18.017893            1       True         44\n",
            "13     RandomForest_r127_BAG_L1       0.837485   0.875872          f1        0.094108       0.218871    8.274290                 0.094108                0.218871           8.274290            1       True         32\n",
            "14         LightGBM_r130_BAG_L1       0.837400   0.871511          f1        0.076211       0.063071   30.548320                 0.076211                0.063071          30.548320            1       True         16\n",
            "15         LightGBM_r143_BAG_L1       0.837400   0.863011          f1        0.085102       0.128480   33.517029                 0.085102                0.128480          33.517029            1       True         31\n",
            "16         ExtraTrees_r4_BAG_L1       0.836796   0.864007          f1        0.101242       0.472767    2.850632                 0.101242                0.472767           2.850632            1       True         37\n",
            "17          LightGBM_r30_BAG_L1       0.836754   0.862963          f1        0.059468       0.163874   32.894056                 0.059468                0.163874          32.894056            1       True         40\n",
            "18         LightGBM_r161_BAG_L1       0.836236   0.868373          f1        0.209503       0.055679   30.935098                 0.209503                0.055679          30.935098            1       True         21\n",
            "19           XGBoost_r98_BAG_L1       0.835083   0.859123          f1        0.042765       0.045150   17.184245                 0.042765                0.045150          17.184245            1       True         27\n",
            "20         LightGBM_r121_BAG_L1       0.833942   0.867130          f1        0.089255       0.052058   32.830034                 0.089255                0.052058          32.830034            1       True         51\n",
            "21         LightGBM_r131_BAG_L1       0.833849   0.866543          f1        0.085162       0.182990   29.609079                 0.085162                0.182990          29.609079            1       True          6\n",
            "22           XGBoost_r49_BAG_L1       0.833426   0.871597          f1        0.052312       0.110238   17.531771                 0.052312                0.110238          17.531771            1       True         41\n",
            "23         LightGBM_r135_BAG_L1       0.832699   0.869278          f1        0.061333       0.093993   29.817653                 0.061333                0.093993          29.817653            1       True         47\n",
            "24          LightGBM_r96_BAG_L1       0.831281   0.850759          f1        0.068946       0.193278   30.216156                 0.068946                0.193278          30.216156            1       True          8\n",
            "25           XGBoost_r34_BAG_L1       0.830585   0.862363          f1        0.058523       0.103344   17.945711                 0.058523                0.103344          17.945711            1       True         62\n",
            "26        ExtraTrees_r42_BAG_L1       0.830557   0.886800          f1        0.207927       0.242639    3.885593                 0.207927                0.242639           3.885593            1       True         10\n",
            "27         LightGBM_r188_BAG_L1       0.829621   0.871732          f1        0.109673       0.309344   29.013752                 0.109673                0.309344          29.013752            1       True         13\n",
            "28       ExtraTrees_r197_BAG_L1       0.827906   0.886120          f1        0.170190       0.247624    2.787185                 0.170190                0.247624           2.787185            1       True         53\n",
            "29           XGBoost_r33_BAG_L1       0.827562   0.868208          f1        0.138993       0.069705   17.480972                 0.138993                0.069705          17.480972            1       True          9\n",
            "30     RandomForest_r166_BAG_L1       0.827300   0.887305          f1        0.106218       0.218688    4.570074                 0.106218                0.218688           4.570074            1       True         43\n",
            "31          LightGBM_r94_BAG_L1       0.826681   0.856617          f1        0.042485       0.069808   29.930073                 0.042485                0.069808          29.930073            1       True         35\n",
            "32   NeuralNetFastAI_r95_BAG_L1       0.826464   0.850212          f1        0.115957       0.302631   39.334135                 0.115957                0.302631          39.334135            1       True         26\n",
            "33     RandomForest_r195_BAG_L1       0.825664   0.882932          f1        0.326183       0.300840   10.375181                 0.326183                0.300840          10.375181            1       True         12\n",
            "34      RandomForest_r16_BAG_L1       0.825041   0.881625          f1        0.110292       0.227427   11.453920                 0.110292                0.227427          11.453920            1       True         55\n",
            "35          LightGBM_r42_BAG_L1       0.824876   0.857261          f1        0.070088       0.105636   30.449101                 0.070088                0.105636          30.449101            1       True         63\n",
            "36      RandomForestGini_BAG_L1       0.824651   0.884150          f1        0.233150       0.221185    4.494014                 0.233150                0.221185           4.494014            1       True          1\n",
            "37      RandomForest_r39_BAG_L1       0.823390   0.882721          f1        0.118113       0.218679    9.224829                 0.118113                0.218679           9.224829            1       True         25\n",
            "38    NeuralNetFastAI_r4_BAG_L1       0.823235   0.815657          f1        0.074938       0.782881   38.897216                 0.074938                0.782881          38.897216            1       True         57\n",
            "39        ExtraTrees_r49_BAG_L1       0.821667   0.883349          f1        0.227040       0.409079    4.046802                 0.227040                0.409079           4.046802            1       True         30\n",
            "40        ExtraTreesEntr_BAG_L1       0.821667   0.883508          f1        0.302931       0.257019    1.661385                 0.302931                0.257019           1.661385            1       True          4\n",
            "41        ExtraTreesGini_BAG_L1       0.821667   0.883349          f1        0.367205       0.318563    3.172113                 0.367205                0.318563           3.172113            1       True          3\n",
            "42      RandomForest_r34_BAG_L1       0.821569   0.862528          f1        0.098290       0.257365    5.368011                 0.098290                0.257365           5.368011            1       True         34\n",
            "43  NeuralNetFastAI_r102_BAG_L1       0.820690   0.881806          f1        0.105080       0.104177   40.591309                 0.105080                0.104177          40.591309            1       True         11\n",
            "44      RandomForestEntr_BAG_L1       0.820387   0.886159          f1        0.218957       0.372526    4.852813                 0.218957                0.372526           4.852813            1       True          2\n",
            "45   NeuralNetFastAI_r37_BAG_L1       0.819414   0.860534          f1        0.080547       0.128648   38.715084                 0.080547                0.128648          38.715084            1       True         29\n",
            "46  NeuralNetFastAI_r187_BAG_L1       0.818088   0.881167          f1        0.069803       0.215535   40.853985                 0.069803                0.215535          40.853985            1       True         60\n",
            "47  NeuralNetFastAI_r127_BAG_L1       0.811855   0.884171          f1        0.068900       0.092840   41.169288                 0.068900                0.092840          41.169288            1       True         54\n",
            "48  NeuralNetFastAI_r143_BAG_L1       0.811659   0.866553          f1        0.134709       0.109590   41.445849                 0.134709                0.109590          41.445849            1       True         22\n",
            "49  NeuralNetFastAI_r103_BAG_L1       0.808104   0.855916          f1        0.186651       0.168764   40.894492                 0.186651                0.168764          40.894492            1       True         20\n",
            "50         LightGBM_r196_BAG_L1       0.804838   0.828148          f1        0.061975       0.085538   30.881731                 0.061975                0.085538          30.881731            1       True         24\n",
            "51  NeuralNetFastAI_r194_BAG_L1       0.800439   0.856974          f1        0.095438       0.204546   39.227604                 0.095438                0.204546          39.227604            1       True         56\n",
            "52  NeuralNetFastAI_r172_BAG_L1       0.798312   0.875379          f1        0.069912       0.091185   40.573799                 0.069912                0.091185          40.573799            1       True         52\n",
            "53   NeuralNetFastAI_r69_BAG_L1       0.796071   0.855146          f1        0.111404       0.173697   39.783656                 0.111404                0.173697          39.783656            1       True         49\n",
            "54  NeuralNetFastAI_r145_BAG_L1       0.795346   0.855075          f1        0.192310       0.342854   39.697233                 0.192310                0.342854          39.697233            1       True         14\n",
            "55  NeuralNetFastAI_r138_BAG_L1       0.787542   0.801839          f1        0.133276       0.688229   42.745648                 0.133276                0.688229          42.745648            1       True         50\n",
            "56   NeuralNetFastAI_r88_BAG_L1       0.786070   0.865812          f1        0.064745       0.100534   40.170070                 0.064745                0.100534          40.170070            1       True         39\n",
            "57   NeuralNetFastAI_r11_BAG_L1       0.785805   0.823867          f1        0.209198       0.279310   38.673106                 0.209198                0.279310          38.673106            1       True         17\n",
            "58  NeuralNetFastAI_r191_BAG_L1       0.780353   0.755895          f1        1.916544       0.252707   38.612023                 1.916544                0.252707          38.612023            1       True          7\n",
            "59  NeuralNetFastAI_r160_BAG_L1       0.757188   0.852746          f1        0.172863       0.199997   38.033307                 0.172863                0.199997          38.033307            1       True         45\n",
            "60  NeuralNetFastAI_r111_BAG_L1       0.755940   0.765027          f1        0.081454       0.118702   42.326641                 0.081454                0.118702          42.326641            1       True         36\n",
            "61   NeuralNetFastAI_r65_BAG_L1       0.685693   0.778679          f1        0.062440       0.072529   39.096191                 0.062440                0.072529          39.096191            1       True         38\n",
            "62  NeuralNetFastAI_r156_BAG_L1       0.676144   0.809842          f1        0.098354       0.312384   37.250242                 0.098354                0.312384          37.250242            1       True         23\n",
            "63  NeuralNetFastAI_r134_BAG_L1       0.653096   0.633171          f1        0.096956       0.155848   39.775918                 0.096956                0.155848          39.775918            1       True         33\n",
            "64  NeuralNetFastAI_r100_BAG_L1       0.544712   0.580774          f1        0.100731       0.246001   37.616688                 0.100731                0.246001          37.616688            1       True         59\n",
            "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
            "\t2001s\t = DyStack   runtime |\t1599s\t = Remaining runtime\n",
            "Starting main fit with num_stack_levels=1.\n",
            "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
            "Values in column 'sample_weight' used as sample weights instead of predictive features. Evaluation will report weighted metrics, so ensure same column exists in test data.\n",
            "Beginning AutoGluon training ... Time limit = 1599s\n",
            "AutoGluon will save models to \"/content/AutogluonModels/ag-20251004_215642\"\n",
            "Train Data Rows:    3964\n",
            "Train Data Columns: 9\n",
            "Label Column:       target_encoded\n",
            "Problem Type:       binary\n",
            "Preprocessing data ...\n",
            "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    8899.09 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.24 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 8 | ['period', 'transit_epoch_bjd', 'transit_duration_hrs', 'transit_depth_ppm', 'planet_radius_earth', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 8 | ['period', 'transit_epoch_bjd', 'transit_duration_hrs', 'transit_depth_ppm', 'planet_radius_earth', ...]\n",
            "\t0.1s = Fit runtime\n",
            "\t8 features in original data used to generate 8 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.24 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.18s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'f1'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
            "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
            "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "}\n",
            "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
            "Hyperparameter tuning model: LightGBMXT_BAG_L1 ... Tuning model for up to 8.88s of the 1598.72s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
            "Classification metrics can't handle a mix of unknown and binary targets\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 104, in fit_and_save_model\n",
            "    model.val_score = model.score_with_y_pred_proba(y=fit_args[\"y\"], y_pred_proba=oof_pred_proba)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1376, in score_with_y_pred_proba\n",
            "    return compute_metric(\n",
            "           ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/metrics/score_func.py\", line 97, in compute_metric\n",
            "    return func(y, predictions, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/metrics/__init__.py\", line 111, in __call__\n",
            "    return self._score(y_true=y_true, y_pred=y_pred, **k)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/metrics/__init__.py\", line 149, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **kwargs)\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py\", line 1271, in f1_score\n",
            "    return fbeta_score(\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\", line 186, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py\", line 1463, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\", line 186, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py\", line 1767, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py\", line 1539, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py\", line 94, in _check_targets\n",
            "    raise ValueError(\n",
            "ValueError: Classification metrics can't handle a mix of unknown and binary targets\n",
            "\tStopping HPO to satisfy time limit...\n",
            "No model was trained during hyperparameter tuning LightGBMXT_BAG_L1... Skipping this model.\n",
            "Hyperparameter tuning model: LightGBM_BAG_L1 ... Tuning model for up to 8.88s of the 1547.72s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
            "Classification metrics can't handle a mix of unknown and binary targets\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 104, in fit_and_save_model\n",
            "    model.val_score = model.score_with_y_pred_proba(y=fit_args[\"y\"], y_pred_proba=oof_pred_proba)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1376, in score_with_y_pred_proba\n",
            "    return compute_metric(\n",
            "           ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/metrics/score_func.py\", line 97, in compute_metric\n",
            "    return func(y, predictions, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/metrics/__init__.py\", line 111, in __call__\n",
            "    return self._score(y_true=y_true, y_pred=y_pred, **k)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/metrics/__init__.py\", line 149, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **kwargs)\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py\", line 1271, in f1_score\n",
            "    return fbeta_score(\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\", line 186, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py\", line 1463, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\", line 186, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py\", line 1767, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py\", line 1539, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py\", line 94, in _check_targets\n",
            "    raise ValueError(\n",
            "ValueError: Classification metrics can't handle a mix of unknown and binary targets\n",
            "\tStopping HPO to satisfy time limit...\n",
            "No model was trained during hyperparameter tuning LightGBM_BAG_L1... Skipping this model.\n",
            "Hyperparameter tuning model: RandomForestGini_BAG_L1 ... Tuning model for up to 8.88s of the 1495.62s of remaining time.\n",
            "\tNo hyperparameter search space specified for RandomForestGini_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "Fitted model: RandomForestGini_BAG_L1 ...\n",
            "\t0.8872\t = Validation score   (f1)\n",
            "\t8.55s\t = Training   runtime\n",
            "\t0.53s\t = Validation runtime\n",
            "Hyperparameter tuning model: RandomForestEntr_BAG_L1 ... Tuning model for up to 8.88s of the 1486.94s of remaining time.\n",
            "\tNo hyperparameter search space specified for RandomForestEntr_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "Fitted model: RandomForestEntr_BAG_L1 ...\n",
            "\t0.8891\t = Validation score   (f1)\n",
            "\t7.34s\t = Training   runtime\n",
            "\t0.23s\t = Validation runtime\n",
            "Hyperparameter tuning model: CatBoost_BAG_L1 ... Tuning model for up to 8.88s of the 1479.53s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=4.12%)\n",
            "\tStopping HPO to satisfy time limit...\n",
            "No model was trained during hyperparameter tuning CatBoost_BAG_L1... Skipping this model.\n",
            "Hyperparameter tuning model: ExtraTreesGini_BAG_L1 ... Tuning model for up to 8.88s of the 1473.62s of remaining time.\n",
            "\tNo hyperparameter search space specified for ExtraTreesGini_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "2025-10-04 22:32:11,019\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "Fitted model: ExtraTreesGini_BAG_L1 ...\n",
            "\t0.888\t = Validation score   (f1)\n",
            "\t3.12s\t = Training   runtime\n",
            "\t0.43s\t = Validation runtime\n",
            "Hyperparameter tuning model: ExtraTreesEntr_BAG_L1 ... Tuning model for up to 8.88s of the 1470.45s of remaining time.\n",
            "\tNo hyperparameter search space specified for ExtraTreesEntr_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "Fitted model: ExtraTreesEntr_BAG_L1 ...\n",
            "\t0.8873\t = Validation score   (f1)\n",
            "\t3.88s\t = Training   runtime\n",
            "\t0.47s\t = Validation runtime\n",
            "Hyperparameter tuning model: NeuralNetFastAI_BAG_L1 ... Tuning model for up to 8.88s of the 1466.52s of remaining time.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------------------------------------------------------+\n",
            "| Configuration for experiment     NeuralNetFastAI_BAG_L1   |\n",
            "+-----------------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator          |\n",
            "| Scheduler                        FIFOScheduler            |\n",
            "| Number of trials                 1000                     |\n",
            "+-----------------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/AutogluonModels/ag-20251004_215642/models/NeuralNetFastAI_BAG_L1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-04 22:32:26,515\tINFO timeout.py:54 -- Reached timeout of 8.879837046424548 seconds. Stopping all trials.\n",
            "2025-10-04 22:32:26,534\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/content/AutogluonModels/ag-20251004_215642/models/NeuralNetFastAI_BAG_L1' in 0.0143s.\n",
            "2025-10-04 22:32:36,588\tWARNING experiment_analysis.py:180 -- Failed to fetch metrics for 2 trial(s):\n",
            "- beddba75: FileNotFoundError('Could not fetch metrics for beddba75: both result.json and progress.csv were not found at /content/AutogluonModels/ag-20251004_215642/models/NeuralNetFastAI_BAG_L1/beddba75')\n",
            "- 30e75ff9: FileNotFoundError('Could not fetch metrics for 30e75ff9: both result.json and progress.csv were not found at /content/AutogluonModels/ag-20251004_215642/models/NeuralNetFastAI_BAG_L1/30e75ff9')\n",
            "No model was trained during hyperparameter tuning NeuralNetFastAI_BAG_L1... Skipping this model.\n",
            "Hyperparameter tuning model: XGBoost_BAG_L1 ... Tuning model for up to 8.88s of the 1447.34s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.13%)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Classification metrics can't handle a mix of unknown and binary targets\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 104, in fit_and_save_model\n",
            "    model.val_score = model.score_with_y_pred_proba(y=fit_args[\"y\"], y_pred_proba=oof_pred_proba)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1376, in score_with_y_pred_proba\n",
            "    return compute_metric(\n",
            "           ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/metrics/score_func.py\", line 97, in compute_metric\n",
            "    return func(y, predictions, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/metrics/__init__.py\", line 111, in __call__\n",
            "    return self._score(y_true=y_true, y_pred=y_pred, **k)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/metrics/__init__.py\", line 149, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **kwargs)\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py\", line 1271, in f1_score\n",
            "    return fbeta_score(\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\", line 186, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py\", line 1463, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\", line 186, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py\", line 1767, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py\", line 1539, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py\", line 94, in _check_targets\n",
            "    raise ValueError(\n",
            "ValueError: Classification metrics can't handle a mix of unknown and binary targets\n",
            "\tStopping HPO to satisfy time limit...\n",
            "No model was trained during hyperparameter tuning XGBoost_BAG_L1... Skipping this model.\n",
            "Hyperparameter tuning model: NeuralNetTorch_BAG_L1 ... Tuning model for up to 8.88s of the 1414.6s of remaining time.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------------------------------------------------------+\n",
            "| Configuration for experiment     NeuralNetTorch_BAG_L1   |\n",
            "+----------------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator         |\n",
            "| Scheduler                        FIFOScheduler           |\n",
            "| Number of trials                 1000                    |\n",
            "+----------------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_BAG_L1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-04 22:33:18,418\tINFO timeout.py:54 -- Reached timeout of 8.879837046424548 seconds. Stopping all trials.\n",
            "2025-10-04 22:33:18,479\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_BAG_L1' in 0.0458s.\n",
            "2025-10-04 22:33:26,736\tWARNING experiment_analysis.py:180 -- Failed to fetch metrics for 2 trial(s):\n",
            "- 6e25d02b: FileNotFoundError('Could not fetch metrics for 6e25d02b: both result.json and progress.csv were not found at /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_BAG_L1/6e25d02b')\n",
            "- 458a9350: FileNotFoundError('Could not fetch metrics for 458a9350: both result.json and progress.csv were not found at /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_BAG_L1/458a9350')\n",
            "No model was trained during hyperparameter tuning NeuralNetTorch_BAG_L1... Skipping this model.\n",
            "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 8.88s of the 1397.19s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.24%)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\t0.8109\t = Validation score   (f1)\n",
            "\t45.72s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Hyperparameter tuning model: CatBoost_r177_BAG_L1 ... Tuning model for up to 8.88s of the 1340.85s of remaining time.\n",
            "\tNo hyperparameter search space specified for CatBoost_r177_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=4.32%)\n",
            "Fitted model: CatBoost_r177_BAG_L1 ...\n",
            "\t0.8718\t = Validation score   (f1)\n",
            "\t22.76s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Hyperparameter tuning model: NeuralNetTorch_r79_BAG_L1 ... Tuning model for up to 8.88s of the 1318.06s of remaining time.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------------------+\n",
            "| Configuration for experiment     NeuralNetTorch_r79_BAG_L1   |\n",
            "+--------------------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator             |\n",
            "| Scheduler                        FIFOScheduler               |\n",
            "| Number of trials                 1000                        |\n",
            "+--------------------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r79_BAG_L1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-04 22:34:54,956\tINFO timeout.py:54 -- Reached timeout of 8.879837046424548 seconds. Stopping all trials.\n",
            "2025-10-04 22:34:54,988\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r79_BAG_L1' in 0.0204s.\n",
            "2025-10-04 22:35:04,443\tWARNING experiment_analysis.py:180 -- Failed to fetch metrics for 2 trial(s):\n",
            "- b52d3b77: FileNotFoundError('Could not fetch metrics for b52d3b77: both result.json and progress.csv were not found at /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r79_BAG_L1/b52d3b77')\n",
            "- 4d4dc9e7: FileNotFoundError('Could not fetch metrics for 4d4dc9e7: both result.json and progress.csv were not found at /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r79_BAG_L1/4d4dc9e7')\n",
            "No model was trained during hyperparameter tuning NeuralNetTorch_r79_BAG_L1... Skipping this model.\n",
            "Hyperparameter tuning model: LightGBM_r131_BAG_L1 ... Tuning model for up to 8.88s of the 1299.47s of remaining time.\n",
            "\tNo hyperparameter search space specified for LightGBM_r131_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.11%)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fitted model: LightGBM_r131_BAG_L1 ...\n",
            "\t0.8773\t = Validation score   (f1)\n",
            "\t39.71s\t = Training   runtime\n",
            "\t0.26s\t = Validation runtime\n",
            "Hyperparameter tuning model: NeuralNetFastAI_r191_BAG_L1 ... Tuning model for up to 8.88s of the 1259.67s of remaining time.\n",
            "\tNo hyperparameter search space specified for NeuralNetFastAI_r191_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
            "Fitted model: NeuralNetFastAI_r191_BAG_L1 ...\n",
            "\t0.8547\t = Validation score   (f1)\n",
            "\t43.31s\t = Training   runtime\n",
            "\t0.24s\t = Validation runtime\n",
            "Hyperparameter tuning model: CatBoost_r9_BAG_L1 ... Tuning model for up to 8.88s of the 1216.32s of remaining time.\n",
            "\tNo hyperparameter search space specified for CatBoost_r9_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=4.40%)\n",
            "Fitted model: CatBoost_r9_BAG_L1 ...\n",
            "\t0.8723\t = Validation score   (f1)\n",
            "\t21.62s\t = Training   runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Hyperparameter tuning model: LightGBM_r96_BAG_L1 ... Tuning model for up to 8.88s of the 1194.66s of remaining time.\n",
            "\tNo hyperparameter search space specified for LightGBM_r96_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
            "Fitted model: LightGBM_r96_BAG_L1 ...\n",
            "\t0.8654\t = Validation score   (f1)\n",
            "\t38.1s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Hyperparameter tuning model: NeuralNetTorch_r22_BAG_L1 ... Tuning model for up to 8.88s of the 1156.53s of remaining time.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------------------+\n",
            "| Configuration for experiment     NeuralNetTorch_r22_BAG_L1   |\n",
            "+--------------------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator             |\n",
            "| Scheduler                        FIFOScheduler               |\n",
            "| Number of trials                 1000                        |\n",
            "+--------------------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r22_BAG_L1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-04 22:37:36,461\tINFO timeout.py:54 -- Reached timeout of 8.879837046424548 seconds. Stopping all trials.\n",
            "2025-10-04 22:37:36,493\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r22_BAG_L1' in 0.0229s.\n",
            "2025-10-04 22:37:44,426\tWARNING experiment_analysis.py:180 -- Failed to fetch metrics for 2 trial(s):\n",
            "- 679eb2dc: FileNotFoundError('Could not fetch metrics for 679eb2dc: both result.json and progress.csv were not found at /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r22_BAG_L1/679eb2dc')\n",
            "- 635ae106: FileNotFoundError('Could not fetch metrics for 635ae106: both result.json and progress.csv were not found at /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r22_BAG_L1/635ae106')\n",
            "No model was trained during hyperparameter tuning NeuralNetTorch_r22_BAG_L1... Skipping this model.\n",
            "Hyperparameter tuning model: XGBoost_r33_BAG_L1 ... Tuning model for up to 8.88s of the 1139.5s of remaining time.\n",
            "\tNo hyperparameter search space specified for XGBoost_r33_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.43%)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fitted model: XGBoost_r33_BAG_L1 ...\n",
            "\t0.8721\t = Validation score   (f1)\n",
            "\t21.9s\t = Training   runtime\n",
            "\t0.13s\t = Validation runtime\n",
            "Hyperparameter tuning model: ExtraTrees_r42_BAG_L1 ... Tuning model for up to 8.88s of the 1117.56s of remaining time.\n",
            "\tNo hyperparameter search space specified for ExtraTrees_r42_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "Fitted model: ExtraTrees_r42_BAG_L1 ...\n",
            "\t0.8907\t = Validation score   (f1)\n",
            "\t3.78s\t = Training   runtime\n",
            "\t0.26s\t = Validation runtime\n",
            "Hyperparameter tuning model: CatBoost_r137_BAG_L1 ... Tuning model for up to 8.88s of the 1113.73s of remaining time.\n",
            "\tNo hyperparameter search space specified for CatBoost_r137_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=4.06%)\n",
            "Warning: Exception caused CatBoost_r137_BAG_L1 to fail during hyperparameter tuning... Skipping this model.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1578, in _hyperparameter_tune\n",
            "    hpo_executor.validate_search_space(search_space, self.name)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/hpo/executors.py\", line 528, in validate_search_space\n",
            "    raise EmptySearchSpace\n",
            "autogluon.core.hpo.exceptions.EmptySearchSpace\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 583, in _process_fold_results\n",
            "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
            "                                                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/_private/worker.py\", line 2782, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/_private/worker.py\", line 929, in get_objects\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(TimeLimitExceeded): \u001b[36mray::_ray_fit()\u001b[39m (pid=101052, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 446, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1068, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 229, in _fit\n",
            "    raise TimeLimitExceeded\n",
            "autogluon.core.utils.exceptions.TimeLimitExceeded\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2557, in _train_single_full\n",
            "    hpo_models, hpo_results = model.hyperparameter_tune(\n",
            "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1972, in hyperparameter_tune\n",
            "    return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 289, in _hyperparameter_tune\n",
            "    return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1580, in _hyperparameter_tune\n",
            "    return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n",
            "    fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1068, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 389, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 868, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 723, in after_all_folds_scheduled\n",
            "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 664, in _run_parallel\n",
            "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 606, in _process_fold_results\n",
            "    raise TimeLimitExceeded\n",
            "autogluon.core.utils.exceptions.TimeLimitExceeded\n",
            "\n",
            "Hyperparameter tuning model: NeuralNetFastAI_r102_BAG_L1 ... Tuning model for up to 8.88s of the 1098.96s of remaining time.\n",
            "\tNo hyperparameter search space specified for NeuralNetFastAI_r102_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
            "2025-10-04 22:38:30,713\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "Fitted model: NeuralNetFastAI_r102_BAG_L1 ...\n",
            "\t0.8797\t = Validation score   (f1)\n",
            "\t38.61s\t = Training   runtime\n",
            "\t0.28s\t = Validation runtime\n",
            "Hyperparameter tuning model: CatBoost_r13_BAG_L1 ... Tuning model for up to 8.88s of the 1060.27s of remaining time.\n",
            "\tNo hyperparameter search space specified for CatBoost_r13_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=4.40%)\n",
            "Fitted model: CatBoost_r13_BAG_L1 ...\n",
            "\t0.8731\t = Validation score   (f1)\n",
            "\t26.38s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Hyperparameter tuning model: RandomForest_r195_BAG_L1 ... Tuning model for up to 8.88s of the 1033.86s of remaining time.\n",
            "\tNo hyperparameter search space specified for RandomForest_r195_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "Fitted model: RandomForest_r195_BAG_L1 ...\n",
            "\t0.8861\t = Validation score   (f1)\n",
            "\t7.71s\t = Training   runtime\n",
            "\t0.3s\t = Validation runtime\n",
            "Hyperparameter tuning model: LightGBM_r188_BAG_L1 ... Tuning model for up to 8.88s of the 1026.11s of remaining time.\n",
            "\tNo hyperparameter search space specified for LightGBM_r188_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.22%)\n",
            "Fitted model: LightGBM_r188_BAG_L1 ...\n",
            "\t0.879\t = Validation score   (f1)\n",
            "\t37.52s\t = Training   runtime\n",
            "\t0.34s\t = Validation runtime\n",
            "Hyperparameter tuning model: NeuralNetFastAI_r145_BAG_L1 ... Tuning model for up to 8.88s of the 988.53s of remaining time.\n",
            "\tNo hyperparameter search space specified for NeuralNetFastAI_r145_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
            "Fitted model: NeuralNetFastAI_r145_BAG_L1 ...\n",
            "\t0.8742\t = Validation score   (f1)\n",
            "\t42.31s\t = Training   runtime\n",
            "\t0.44s\t = Validation runtime\n",
            "Hyperparameter tuning model: XGBoost_r89_BAG_L1 ... Tuning model for up to 8.88s of the 946.18s of remaining time.\n",
            "\tNo hyperparameter search space specified for XGBoost_r89_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
            "Fitted model: XGBoost_r89_BAG_L1 ...\n",
            "\t0.8803\t = Validation score   (f1)\n",
            "\t22.6s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Hyperparameter tuning model: NeuralNetTorch_r30_BAG_L1 ... Tuning model for up to 8.88s of the 923.55s of remaining time.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------------------+\n",
            "| Configuration for experiment     NeuralNetTorch_r30_BAG_L1   |\n",
            "+--------------------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator             |\n",
            "| Scheduler                        FIFOScheduler               |\n",
            "| Number of trials                 1000                        |\n",
            "+--------------------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r30_BAG_L1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-04 22:41:29,480\tINFO timeout.py:54 -- Reached timeout of 8.879837046424548 seconds. Stopping all trials.\n",
            "2025-10-04 22:41:29,535\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r30_BAG_L1' in 0.0407s.\n",
            "2025-10-04 22:41:39,585\tWARNING experiment_analysis.py:180 -- Failed to fetch metrics for 2 trial(s):\n",
            "- 44660564: FileNotFoundError('Could not fetch metrics for 44660564: both result.json and progress.csv were not found at /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r30_BAG_L1/44660564')\n",
            "- 08c9019d: FileNotFoundError('Could not fetch metrics for 08c9019d: both result.json and progress.csv were not found at /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r30_BAG_L1/08c9019d')\n",
            "No model was trained during hyperparameter tuning NeuralNetTorch_r30_BAG_L1... Skipping this model.\n",
            "Hyperparameter tuning model: LightGBM_r130_BAG_L1 ... Tuning model for up to 8.88s of the 904.33s of remaining time.\n",
            "\tNo hyperparameter search space specified for LightGBM_r130_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.17%)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fitted model: LightGBM_r130_BAG_L1 ...\n",
            "\t0.8775\t = Validation score   (f1)\n",
            "\t37.09s\t = Training   runtime\n",
            "\t0.19s\t = Validation runtime\n",
            "Hyperparameter tuning model: NeuralNetTorch_r86_BAG_L1 ... Tuning model for up to 8.88s of the 867.17s of remaining time.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------------------+\n",
            "| Configuration for experiment     NeuralNetTorch_r86_BAG_L1   |\n",
            "+--------------------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator             |\n",
            "| Scheduler                        FIFOScheduler               |\n",
            "| Number of trials                 1000                        |\n",
            "+--------------------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r86_BAG_L1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-04 22:42:25,827\tINFO timeout.py:54 -- Reached timeout of 8.879837046424548 seconds. Stopping all trials.\n",
            "2025-10-04 22:42:25,870\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r86_BAG_L1' in 0.0268s.\n",
            "2025-10-04 22:42:33,591\tWARNING experiment_analysis.py:180 -- Failed to fetch metrics for 2 trial(s):\n",
            "- 72dd3bf9: FileNotFoundError('Could not fetch metrics for 72dd3bf9: both result.json and progress.csv were not found at /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r86_BAG_L1/72dd3bf9')\n",
            "- 0a111093: FileNotFoundError('Could not fetch metrics for 0a111093: both result.json and progress.csv were not found at /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r86_BAG_L1/0a111093')\n",
            "No model was trained during hyperparameter tuning NeuralNetTorch_r86_BAG_L1... Skipping this model.\n",
            "Hyperparameter tuning model: CatBoost_r50_BAG_L1 ... Tuning model for up to 8.88s of the 850.33s of remaining time.\n",
            "\tNo hyperparameter search space specified for CatBoost_r50_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=4.33%)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fitted model: CatBoost_r50_BAG_L1 ...\n",
            "\t0.8726\t = Validation score   (f1)\n",
            "\t26.09s\t = Training   runtime\n",
            "\t0.16s\t = Validation runtime\n",
            "Hyperparameter tuning model: NeuralNetFastAI_r11_BAG_L1 ... Tuning model for up to 8.88s of the 824.18s of remaining time.\n",
            "\tNo hyperparameter search space specified for NeuralNetFastAI_r11_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
            "Fitted model: NeuralNetFastAI_r11_BAG_L1 ...\n",
            "\t0.87\t = Validation score   (f1)\n",
            "\t45.64s\t = Training   runtime\n",
            "\t0.6s\t = Validation runtime\n",
            "Hyperparameter tuning model: XGBoost_r194_BAG_L1 ... Tuning model for up to 8.88s of the 778.51s of remaining time.\n",
            "\tNo hyperparameter search space specified for XGBoost_r194_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.18%)\n",
            "Fitted model: XGBoost_r194_BAG_L1 ...\n",
            "\t0.8806\t = Validation score   (f1)\n",
            "\t22.82s\t = Training   runtime\n",
            "\t0.13s\t = Validation runtime\n",
            "Hyperparameter tuning model: ExtraTrees_r172_BAG_L1 ... Tuning model for up to 8.88s of the 755.66s of remaining time.\n",
            "\tNo hyperparameter search space specified for ExtraTrees_r172_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "Fitted model: ExtraTrees_r172_BAG_L1 ...\n",
            "\t0.8796\t = Validation score   (f1)\n",
            "\t3.57s\t = Training   runtime\n",
            "\t0.56s\t = Validation runtime\n",
            "Hyperparameter tuning model: CatBoost_r69_BAG_L1 ... Tuning model for up to 8.88s of the 752.03s of remaining time.\n",
            "\tNo hyperparameter search space specified for CatBoost_r69_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=4.16%)\n",
            "Warning: Exception caused CatBoost_r69_BAG_L1 to fail during hyperparameter tuning... Skipping this model.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1578, in _hyperparameter_tune\n",
            "    hpo_executor.validate_search_space(search_space, self.name)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/hpo/executors.py\", line 528, in validate_search_space\n",
            "    raise EmptySearchSpace\n",
            "autogluon.core.hpo.exceptions.EmptySearchSpace\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 583, in _process_fold_results\n",
            "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
            "                                                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/_private/worker.py\", line 2782, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/_private/worker.py\", line 929, in get_objects\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(TimeLimitExceeded): \u001b[36mray::_ray_fit()\u001b[39m (pid=104898, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 446, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1068, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 229, in _fit\n",
            "    raise TimeLimitExceeded\n",
            "autogluon.core.utils.exceptions.TimeLimitExceeded\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2557, in _train_single_full\n",
            "    hpo_models, hpo_results = model.hyperparameter_tune(\n",
            "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1972, in hyperparameter_tune\n",
            "    return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 289, in _hyperparameter_tune\n",
            "    return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1580, in _hyperparameter_tune\n",
            "    return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n",
            "    fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1068, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 389, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 868, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 723, in after_all_folds_scheduled\n",
            "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 664, in _run_parallel\n",
            "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 606, in _process_fold_results\n",
            "    raise TimeLimitExceeded\n",
            "autogluon.core.utils.exceptions.TimeLimitExceeded\n",
            "\n",
            "Hyperparameter tuning model: NeuralNetFastAI_r103_BAG_L1 ... Tuning model for up to 8.88s of the 737.63s of remaining time.\n",
            "\tNo hyperparameter search space specified for NeuralNetFastAI_r103_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
            "2025-10-04 22:44:32,222\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "Fitted model: NeuralNetFastAI_r103_BAG_L1 ...\n",
            "\t0.8518\t = Validation score   (f1)\n",
            "\t40.41s\t = Training   runtime\n",
            "\t0.4s\t = Validation runtime\n",
            "Hyperparameter tuning model: NeuralNetTorch_r14_BAG_L1 ... Tuning model for up to 8.88s of the 697.15s of remaining time.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------------------+\n",
            "| Configuration for experiment     NeuralNetTorch_r14_BAG_L1   |\n",
            "+--------------------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator             |\n",
            "| Scheduler                        FIFOScheduler               |\n",
            "| Number of trials                 1000                        |\n",
            "+--------------------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r14_BAG_L1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-04 22:45:15,832\tINFO timeout.py:54 -- Reached timeout of 8.879837046424548 seconds. Stopping all trials.\n",
            "2025-10-04 22:45:15,859\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r14_BAG_L1' in 0.0218s.\n",
            "2025-10-04 22:45:15,868\tWARNING experiment_analysis.py:180 -- Failed to fetch metrics for 2 trial(s):\n",
            "- c423baa0: FileNotFoundError('Could not fetch metrics for c423baa0: both result.json and progress.csv were not found at /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r14_BAG_L1/c423baa0')\n",
            "- 1195dfab: FileNotFoundError('Could not fetch metrics for 1195dfab: both result.json and progress.csv were not found at /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r14_BAG_L1/1195dfab')\n",
            "No model was trained during hyperparameter tuning NeuralNetTorch_r14_BAG_L1... Skipping this model.\n",
            "Hyperparameter tuning model: LightGBM_r161_BAG_L1 ... Tuning model for up to 8.88s of the 688.07s of remaining time.\n",
            "\tNo hyperparameter search space specified for LightGBM_r161_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.42%)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fitted model: LightGBM_r161_BAG_L1 ...\n",
            "\t0.8731\t = Validation score   (f1)\n",
            "\t36.22s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Hyperparameter tuning model: NeuralNetFastAI_r143_BAG_L1 ... Tuning model for up to 8.88s of the 651.8s of remaining time.\n",
            "\tNo hyperparameter search space specified for NeuralNetFastAI_r143_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
            "Fitted model: NeuralNetFastAI_r143_BAG_L1 ...\n",
            "\t0.8924\t = Validation score   (f1)\n",
            "\t45.26s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Hyperparameter tuning model: CatBoost_r70_BAG_L1 ... Tuning model for up to 8.88s of the 606.49s of remaining time.\n",
            "\tNo hyperparameter search space specified for CatBoost_r70_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=4.31%)\n",
            "Fitted model: CatBoost_r70_BAG_L1 ...\n",
            "\t0.8752\t = Validation score   (f1)\n",
            "\t31.71s\t = Training   runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "Hyperparameter tuning model: NeuralNetFastAI_r156_BAG_L1 ... Tuning model for up to 8.88s of the 574.73s of remaining time.\n",
            "\tNo hyperparameter search space specified for NeuralNetFastAI_r156_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
            "Fitted model: NeuralNetFastAI_r156_BAG_L1 ...\n",
            "\t0.8734\t = Validation score   (f1)\n",
            "\t47.98s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Hyperparameter tuning model: LightGBM_r196_BAG_L1 ... Tuning model for up to 8.88s of the 526.71s of remaining time.\n",
            "\tNo hyperparameter search space specified for LightGBM_r196_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.24%)\n",
            "Fitted model: LightGBM_r196_BAG_L1 ...\n",
            "\t0.8376\t = Validation score   (f1)\n",
            "\t35.63s\t = Training   runtime\n",
            "\t0.14s\t = Validation runtime\n",
            "Hyperparameter tuning model: RandomForest_r39_BAG_L1 ... Tuning model for up to 8.88s of the 491.04s of remaining time.\n",
            "\tNo hyperparameter search space specified for RandomForest_r39_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "Fitted model: RandomForest_r39_BAG_L1 ...\n",
            "\t0.8866\t = Validation score   (f1)\n",
            "\t9.7s\t = Training   runtime\n",
            "\t0.33s\t = Validation runtime\n",
            "Hyperparameter tuning model: CatBoost_r167_BAG_L1 ... Tuning model for up to 8.88s of the 481.31s of remaining time.\n",
            "\tNo hyperparameter search space specified for CatBoost_r167_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=4.12%)\n",
            "Fitted model: CatBoost_r167_BAG_L1 ...\n",
            "\t0.8703\t = Validation score   (f1)\n",
            "\t20.68s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Hyperparameter tuning model: NeuralNetFastAI_r95_BAG_L1 ... Tuning model for up to 8.88s of the 460.59s of remaining time.\n",
            "\tNo hyperparameter search space specified for NeuralNetFastAI_r95_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
            "Fitted model: NeuralNetFastAI_r95_BAG_L1 ...\n",
            "\t0.8714\t = Validation score   (f1)\n",
            "\t42.97s\t = Training   runtime\n",
            "\t0.57s\t = Validation runtime\n",
            "Hyperparameter tuning model: NeuralNetTorch_r41_BAG_L1 ... Tuning model for up to 8.88s of the 417.57s of remaining time.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------------------+\n",
            "| Configuration for experiment     NeuralNetTorch_r41_BAG_L1   |\n",
            "+--------------------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator             |\n",
            "| Scheduler                        FIFOScheduler               |\n",
            "| Number of trials                 1000                        |\n",
            "+--------------------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r41_BAG_L1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-04 22:49:55,497\tINFO timeout.py:54 -- Reached timeout of 8.879837046424548 seconds. Stopping all trials.\n",
            "2025-10-04 22:49:55,515\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r41_BAG_L1' in 0.0136s.\n",
            "2025-10-04 22:49:55,953\tWARNING experiment_analysis.py:180 -- Failed to fetch metrics for 2 trial(s):\n",
            "- 700db149: FileNotFoundError('Could not fetch metrics for 700db149: both result.json and progress.csv were not found at /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r41_BAG_L1/700db149')\n",
            "- 3281301d: FileNotFoundError('Could not fetch metrics for 3281301d: both result.json and progress.csv were not found at /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r41_BAG_L1/3281301d')\n",
            "No model was trained during hyperparameter tuning NeuralNetTorch_r41_BAG_L1... Skipping this model.\n",
            "Hyperparameter tuning model: XGBoost_r98_BAG_L1 ... Tuning model for up to 8.88s of the 407.98s of remaining time.\n",
            "\tNo hyperparameter search space specified for XGBoost_r98_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.26%)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fitted model: XGBoost_r98_BAG_L1 ...\n",
            "\t0.8664\t = Validation score   (f1)\n",
            "\t22.04s\t = Training   runtime\n",
            "\t0.16s\t = Validation runtime\n",
            "Hyperparameter tuning model: LightGBM_r15_BAG_L1 ... Tuning model for up to 8.88s of the 385.89s of remaining time.\n",
            "\tNo hyperparameter search space specified for LightGBM_r15_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
            "Fitted model: LightGBM_r15_BAG_L1 ...\n",
            "\t0.8757\t = Validation score   (f1)\n",
            "\t34.75s\t = Training   runtime\n",
            "\t0.19s\t = Validation runtime\n",
            "Hyperparameter tuning model: NeuralNetTorch_r158_BAG_L1 ... Tuning model for up to 8.88s of the 351.09s of remaining time.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------------------------------------------------------+\n",
            "| Configuration for experiment     NeuralNetTorch_r158_BAG_L1   |\n",
            "+---------------------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator              |\n",
            "| Scheduler                        FIFOScheduler                |\n",
            "| Number of trials                 1000                         |\n",
            "+---------------------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r158_BAG_L1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-04 22:51:01,968\tINFO timeout.py:54 -- Reached timeout of 8.879837046424548 seconds. Stopping all trials.\n",
            "2025-10-04 22:51:01,992\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r158_BAG_L1' in 0.0127s.\n",
            "2025-10-04 22:51:11,383\tWARNING experiment_analysis.py:180 -- Failed to fetch metrics for 2 trial(s):\n",
            "- 99b87569: FileNotFoundError('Could not fetch metrics for 99b87569: both result.json and progress.csv were not found at /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r158_BAG_L1/99b87569')\n",
            "- 40948aea: FileNotFoundError('Could not fetch metrics for 40948aea: both result.json and progress.csv were not found at /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r158_BAG_L1/40948aea')\n",
            "No model was trained during hyperparameter tuning NeuralNetTorch_r158_BAG_L1... Skipping this model.\n",
            "Hyperparameter tuning model: CatBoost_r86_BAG_L1 ... Tuning model for up to 8.88s of the 332.54s of remaining time.\n",
            "\tNo hyperparameter search space specified for CatBoost_r86_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=4.61%)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fitted model: CatBoost_r86_BAG_L1 ...\n",
            "\t0.8731\t = Validation score   (f1)\n",
            "\t24.69s\t = Training   runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Hyperparameter tuning model: NeuralNetFastAI_r37_BAG_L1 ... Tuning model for up to 8.88s of the 307.79s of remaining time.\n",
            "\tNo hyperparameter search space specified for NeuralNetFastAI_r37_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
            "Fitted model: NeuralNetFastAI_r37_BAG_L1 ...\n",
            "\t0.8766\t = Validation score   (f1)\n",
            "\t45.71s\t = Training   runtime\n",
            "\t0.34s\t = Validation runtime\n",
            "Hyperparameter tuning model: NeuralNetTorch_r197_BAG_L1 ... Tuning model for up to 8.88s of the 262.04s of remaining time.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------------------------------------------------------+\n",
            "| Configuration for experiment     NeuralNetTorch_r197_BAG_L1   |\n",
            "+---------------------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator              |\n",
            "| Scheduler                        FIFOScheduler                |\n",
            "| Number of trials                 1000                         |\n",
            "+---------------------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r197_BAG_L1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-04 22:52:31,029\tINFO timeout.py:54 -- Reached timeout of 8.879837046424548 seconds. Stopping all trials.\n",
            "2025-10-04 22:52:31,068\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r197_BAG_L1' in 0.0282s.\n",
            "2025-10-04 22:52:38,991\tWARNING experiment_analysis.py:180 -- Failed to fetch metrics for 2 trial(s):\n",
            "- 859ca495: FileNotFoundError('Could not fetch metrics for 859ca495: both result.json and progress.csv were not found at /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r197_BAG_L1/859ca495')\n",
            "- c1c3441f: FileNotFoundError('Could not fetch metrics for c1c3441f: both result.json and progress.csv were not found at /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r197_BAG_L1/c1c3441f')\n",
            "No model was trained during hyperparameter tuning NeuralNetTorch_r197_BAG_L1... Skipping this model.\n",
            "Hyperparameter tuning model: CatBoost_r49_BAG_L1 ... Tuning model for up to 8.88s of the 244.93s of remaining time.\n",
            "\tNo hyperparameter search space specified for CatBoost_r49_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=4.43%)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: Exception caused CatBoost_r49_BAG_L1 to fail during hyperparameter tuning... Skipping this model.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1578, in _hyperparameter_tune\n",
            "    hpo_executor.validate_search_space(search_space, self.name)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/hpo/executors.py\", line 528, in validate_search_space\n",
            "    raise EmptySearchSpace\n",
            "autogluon.core.hpo.exceptions.EmptySearchSpace\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 583, in _process_fold_results\n",
            "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
            "                                                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/_private/worker.py\", line 2782, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/_private/worker.py\", line 929, in get_objects\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(TimeLimitExceeded): \u001b[36mray::_ray_fit()\u001b[39m (pid=110117, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 446, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1068, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 229, in _fit\n",
            "    raise TimeLimitExceeded\n",
            "autogluon.core.utils.exceptions.TimeLimitExceeded\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2557, in _train_single_full\n",
            "    hpo_models, hpo_results = model.hyperparameter_tune(\n",
            "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1972, in hyperparameter_tune\n",
            "    return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 289, in _hyperparameter_tune\n",
            "    return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1580, in _hyperparameter_tune\n",
            "    return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n",
            "    fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1068, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 389, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 868, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 723, in after_all_folds_scheduled\n",
            "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 664, in _run_parallel\n",
            "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 606, in _process_fold_results\n",
            "    raise TimeLimitExceeded\n",
            "autogluon.core.utils.exceptions.TimeLimitExceeded\n",
            "\n",
            "Hyperparameter tuning model: ExtraTrees_r49_BAG_L1 ... Tuning model for up to 8.88s of the 226.13s of remaining time.\n",
            "\tNo hyperparameter search space specified for ExtraTrees_r49_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "2025-10-04 22:52:58,777\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "Fitted model: ExtraTrees_r49_BAG_L1 ...\n",
            "\t0.888\t = Validation score   (f1)\n",
            "\t3.23s\t = Training   runtime\n",
            "\t0.37s\t = Validation runtime\n",
            "Hyperparameter tuning model: LightGBM_r143_BAG_L1 ... Tuning model for up to 8.88s of the 222.83s of remaining time.\n",
            "\tNo hyperparameter search space specified for LightGBM_r143_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.30%)\n",
            "Fitted model: LightGBM_r143_BAG_L1 ...\n",
            "\t0.8738\t = Validation score   (f1)\n",
            "\t34.68s\t = Training   runtime\n",
            "\t0.32s\t = Validation runtime\n",
            "Hyperparameter tuning model: RandomForest_r127_BAG_L1 ... Tuning model for up to 8.88s of the 188.1s of remaining time.\n",
            "\tNo hyperparameter search space specified for RandomForest_r127_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "Fitted model: RandomForest_r127_BAG_L1 ...\n",
            "\t0.8826\t = Validation score   (f1)\n",
            "\t10.86s\t = Training   runtime\n",
            "\t0.22s\t = Validation runtime\n",
            "Hyperparameter tuning model: NeuralNetFastAI_r134_BAG_L1 ... Tuning model for up to 8.88s of the 177.2s of remaining time.\n",
            "\tNo hyperparameter search space specified for NeuralNetFastAI_r134_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
            "Fitted model: NeuralNetFastAI_r134_BAG_L1 ...\n",
            "\t0.6743\t = Validation score   (f1)\n",
            "\t45.65s\t = Training   runtime\n",
            "\t0.26s\t = Validation runtime\n",
            "Hyperparameter tuning model: RandomForest_r34_BAG_L1 ... Tuning model for up to 8.88s of the 131.51s of remaining time.\n",
            "\tNo hyperparameter search space specified for RandomForest_r34_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "Fitted model: RandomForest_r34_BAG_L1 ...\n",
            "\t0.8665\t = Validation score   (f1)\n",
            "\t5.41s\t = Training   runtime\n",
            "\t0.32s\t = Validation runtime\n",
            "Hyperparameter tuning model: LightGBM_r94_BAG_L1 ... Tuning model for up to 8.88s of the 126.07s of remaining time.\n",
            "\tNo hyperparameter search space specified for LightGBM_r94_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
            "Fitted model: LightGBM_r94_BAG_L1 ...\n",
            "\t0.8661\t = Validation score   (f1)\n",
            "\t36.13s\t = Training   runtime\n",
            "\t0.16s\t = Validation runtime\n",
            "Hyperparameter tuning model: NeuralNetTorch_r143_BAG_L1 ... Tuning model for up to 8.88s of the 89.89s of remaining time.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------------------------------------------------------+\n",
            "| Configuration for experiment     NeuralNetTorch_r143_BAG_L1   |\n",
            "+---------------------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator              |\n",
            "| Scheduler                        FIFOScheduler                |\n",
            "| Number of trials                 1000                         |\n",
            "+---------------------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r143_BAG_L1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-04 22:55:23,096\tINFO timeout.py:54 -- Reached timeout of 8.879837046424548 seconds. Stopping all trials.\n",
            "2025-10-04 22:55:23,158\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r143_BAG_L1' in 0.0507s.\n",
            "2025-10-04 22:55:33,188\tWARNING experiment_analysis.py:180 -- Failed to fetch metrics for 2 trial(s):\n",
            "- 33a4137b: FileNotFoundError('Could not fetch metrics for 33a4137b: both result.json and progress.csv were not found at /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r143_BAG_L1/33a4137b')\n",
            "- e3b2d516: FileNotFoundError('Could not fetch metrics for e3b2d516: both result.json and progress.csv were not found at /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r143_BAG_L1/e3b2d516')\n",
            "No model was trained during hyperparameter tuning NeuralNetTorch_r143_BAG_L1... Skipping this model.\n",
            "Hyperparameter tuning model: CatBoost_r128_BAG_L1 ... Tuning model for up to 8.88s of the 70.73s of remaining time.\n",
            "\tNo hyperparameter search space specified for CatBoost_r128_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=4.55%)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: Exception caused CatBoost_r128_BAG_L1 to fail during hyperparameter tuning... Skipping this model.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1578, in _hyperparameter_tune\n",
            "    hpo_executor.validate_search_space(search_space, self.name)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/hpo/executors.py\", line 528, in validate_search_space\n",
            "    raise EmptySearchSpace\n",
            "autogluon.core.hpo.exceptions.EmptySearchSpace\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 583, in _process_fold_results\n",
            "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
            "                                                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/_private/worker.py\", line 2782, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/_private/worker.py\", line 929, in get_objects\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(TimeLimitExceeded): \u001b[36mray::_ray_fit()\u001b[39m (pid=111621, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 446, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1068, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 229, in _fit\n",
            "    raise TimeLimitExceeded\n",
            "autogluon.core.utils.exceptions.TimeLimitExceeded\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2557, in _train_single_full\n",
            "    hpo_models, hpo_results = model.hyperparameter_tune(\n",
            "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1972, in hyperparameter_tune\n",
            "    return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 289, in _hyperparameter_tune\n",
            "    return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1580, in _hyperparameter_tune\n",
            "    return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n",
            "    fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1068, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 389, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 868, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 723, in after_all_folds_scheduled\n",
            "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 664, in _run_parallel\n",
            "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 606, in _process_fold_results\n",
            "    raise TimeLimitExceeded\n",
            "autogluon.core.utils.exceptions.TimeLimitExceeded\n",
            "\n",
            "Hyperparameter tuning model: NeuralNetFastAI_r111_BAG_L1 ... Tuning model for up to 8.88s of the 61.76s of remaining time.\n",
            "\tNo hyperparameter search space specified for NeuralNetFastAI_r111_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "2025-10-04 22:55:42,315\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
            "Fitted model: NeuralNetFastAI_r111_BAG_L1 ...\n",
            "\t0.8011\t = Validation score   (f1)\n",
            "\t44.83s\t = Training   runtime\n",
            "\t0.55s\t = Validation runtime\n",
            "Hyperparameter tuning model: NeuralNetTorch_r31_BAG_L1 ... Tuning model for up to 8.88s of the 16.82s of remaining time.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------------------+\n",
            "| Configuration for experiment     NeuralNetTorch_r31_BAG_L1   |\n",
            "+--------------------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator             |\n",
            "| Scheduler                        FIFOScheduler               |\n",
            "| Number of trials                 1000                        |\n",
            "+--------------------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r31_BAG_L1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-04 22:56:36,255\tINFO timeout.py:54 -- Reached timeout of 8.879837046424548 seconds. Stopping all trials.\n",
            "2025-10-04 22:56:36,271\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r31_BAG_L1' in 0.0118s.\n",
            "2025-10-04 22:56:45,459\tWARNING experiment_analysis.py:180 -- Failed to fetch metrics for 2 trial(s):\n",
            "- 5c1a6e61: FileNotFoundError('Could not fetch metrics for 5c1a6e61: both result.json and progress.csv were not found at /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r31_BAG_L1/5c1a6e61')\n",
            "- b205bed0: FileNotFoundError('Could not fetch metrics for b205bed0: both result.json and progress.csv were not found at /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r31_BAG_L1/b205bed0')\n",
            "No model was trained during hyperparameter tuning NeuralNetTorch_r31_BAG_L1... Skipping this model.\n",
            "Hyperparameter tuning model: ExtraTrees_r4_BAG_L1 ... Tuning model for up to 8.88s of the -1.53s of remaining time.\n",
            "\tNo hyperparameter search space specified for ExtraTrees_r4_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fitted model: ExtraTrees_r4_BAG_L1 ...\n",
            "\t0.8676\t = Validation score   (f1)\n",
            "\t3.18s\t = Training   runtime\n",
            "\t0.44s\t = Validation runtime\n",
            "Hyperparameter tuning model: NeuralNetFastAI_r65_BAG_L1 ... Tuning model for up to 8.88s of the -4.8s of remaining time.\n",
            "\tNo hyperparameter search space specified for NeuralNetFastAI_r65_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
            "Fitted model: NeuralNetFastAI_r65_BAG_L1 ...\n",
            "\t0.8018\t = Validation score   (f1)\n",
            "\t53.41s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Hyperparameter tuning model: NeuralNetFastAI_r88_BAG_L1 ... Tuning model for up to 8.88s of the -58.29s of remaining time.\n",
            "\tNo hyperparameter search space specified for NeuralNetFastAI_r88_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
            "Fitted model: NeuralNetFastAI_r88_BAG_L1 ...\n",
            "\t0.8737\t = Validation score   (f1)\n",
            "\t47.29s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Hyperparameter tuning model: LightGBM_r30_BAG_L1 ... Tuning model for up to 8.88s of the -105.62s of remaining time.\n",
            "\tNo hyperparameter search space specified for LightGBM_r30_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.20%)\n",
            "Fitted model: LightGBM_r30_BAG_L1 ...\n",
            "\t0.869\t = Validation score   (f1)\n",
            "\t38.99s\t = Training   runtime\n",
            "\t0.29s\t = Validation runtime\n",
            "Hyperparameter tuning model: XGBoost_r49_BAG_L1 ... Tuning model for up to 8.88s of the -144.65s of remaining time.\n",
            "\tNo hyperparameter search space specified for XGBoost_r49_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.17%)\n",
            "Fitted model: XGBoost_r49_BAG_L1 ...\n",
            "\t0.8746\t = Validation score   (f1)\n",
            "\t21.95s\t = Training   runtime\n",
            "\t0.14s\t = Validation runtime\n",
            "Hyperparameter tuning model: CatBoost_r5_BAG_L1 ... Tuning model for up to 8.88s of the -166.64s of remaining time.\n",
            "\tNo hyperparameter search space specified for CatBoost_r5_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=4.13%)\n",
            "Warning: Exception caused CatBoost_r5_BAG_L1 to fail during hyperparameter tuning... Skipping this model.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1578, in _hyperparameter_tune\n",
            "    hpo_executor.validate_search_space(search_space, self.name)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/hpo/executors.py\", line 528, in validate_search_space\n",
            "    raise EmptySearchSpace\n",
            "autogluon.core.hpo.exceptions.EmptySearchSpace\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 583, in _process_fold_results\n",
            "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
            "                                                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/_private/worker.py\", line 2782, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/_private/worker.py\", line 929, in get_objects\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(TimeLimitExceeded): \u001b[36mray::_ray_fit()\u001b[39m (pid=114041, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 446, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1068, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 229, in _fit\n",
            "    raise TimeLimitExceeded\n",
            "autogluon.core.utils.exceptions.TimeLimitExceeded\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2557, in _train_single_full\n",
            "    hpo_models, hpo_results = model.hyperparameter_tune(\n",
            "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1972, in hyperparameter_tune\n",
            "    return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 289, in _hyperparameter_tune\n",
            "    return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1580, in _hyperparameter_tune\n",
            "    return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n",
            "    fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1068, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 389, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 868, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 723, in after_all_folds_scheduled\n",
            "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 664, in _run_parallel\n",
            "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 606, in _process_fold_results\n",
            "    raise TimeLimitExceeded\n",
            "autogluon.core.utils.exceptions.TimeLimitExceeded\n",
            "\n",
            "Hyperparameter tuning model: NeuralNetTorch_r87_BAG_L1 ... Tuning model for up to 8.88s of the -182.41s of remaining time.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------------------+\n",
            "| Configuration for experiment     NeuralNetTorch_r87_BAG_L1   |\n",
            "+--------------------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator             |\n",
            "| Scheduler                        FIFOScheduler               |\n",
            "| Number of trials                 1000                        |\n",
            "+--------------------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r87_BAG_L1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-04 22:59:46,930\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "2025-10-04 22:59:55,685\tINFO timeout.py:54 -- Reached timeout of 8.879837046424548 seconds. Stopping all trials.\n",
            "2025-10-04 22:59:55,708\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r87_BAG_L1' in 0.0106s.\n",
            "2025-10-04 23:00:04,910\tWARNING experiment_analysis.py:180 -- Failed to fetch metrics for 2 trial(s):\n",
            "- 34c982ec: FileNotFoundError('Could not fetch metrics for 34c982ec: both result.json and progress.csv were not found at /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r87_BAG_L1/34c982ec')\n",
            "- 0e4eaf44: FileNotFoundError('Could not fetch metrics for 0e4eaf44: both result.json and progress.csv were not found at /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r87_BAG_L1/0e4eaf44')\n",
            "No model was trained during hyperparameter tuning NeuralNetTorch_r87_BAG_L1... Skipping this model.\n",
            "Hyperparameter tuning model: NeuralNetTorch_r71_BAG_L1 ... Tuning model for up to 8.88s of the -201.0s of remaining time.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "+--------------------------------------------------------------+\n",
            "| Configuration for experiment     NeuralNetTorch_r71_BAG_L1   |\n",
            "+--------------------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator             |\n",
            "| Scheduler                        FIFOScheduler               |\n",
            "| Number of trials                 1000                        |\n",
            "+--------------------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r71_BAG_L1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-04 23:00:14,163\tINFO timeout.py:54 -- Reached timeout of 8.879837046424548 seconds. Stopping all trials.\n",
            "2025-10-04 23:00:14,179\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r71_BAG_L1' in 0.0120s.\n",
            "2025-10-04 23:00:15,084\tWARNING experiment_analysis.py:180 -- Failed to fetch metrics for 2 trial(s):\n",
            "- 00e1db53: FileNotFoundError('Could not fetch metrics for 00e1db53: both result.json and progress.csv were not found at /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r71_BAG_L1/00e1db53')\n",
            "- ff3c371f: FileNotFoundError('Could not fetch metrics for ff3c371f: both result.json and progress.csv were not found at /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r71_BAG_L1/ff3c371f')\n",
            "No model was trained during hyperparameter tuning NeuralNetTorch_r71_BAG_L1... Skipping this model.\n",
            "Hyperparameter tuning model: CatBoost_r143_BAG_L1 ... Tuning model for up to 8.88s of the -211.16s of remaining time.\n",
            "\tNo hyperparameter search space specified for CatBoost_r143_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=4.16%)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fitted model: CatBoost_r143_BAG_L1 ...\n",
            "\t0.8763\t = Validation score   (f1)\n",
            "\t23.55s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Hyperparameter tuning model: ExtraTrees_r178_BAG_L1 ... Tuning model for up to 8.88s of the -234.76s of remaining time.\n",
            "\tNo hyperparameter search space specified for ExtraTrees_r178_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "Fitted model: ExtraTrees_r178_BAG_L1 ...\n",
            "\t0.8806\t = Validation score   (f1)\n",
            "\t2.31s\t = Training   runtime\n",
            "\t0.27s\t = Validation runtime\n",
            "Hyperparameter tuning model: RandomForest_r166_BAG_L1 ... Tuning model for up to 8.88s of the -237.09s of remaining time.\n",
            "\tNo hyperparameter search space specified for RandomForest_r166_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "Fitted model: RandomForest_r166_BAG_L1 ...\n",
            "\t0.8871\t = Validation score   (f1)\n",
            "\t4.94s\t = Training   runtime\n",
            "\t0.36s\t = Validation runtime\n",
            "Hyperparameter tuning model: XGBoost_r31_BAG_L1 ... Tuning model for up to 8.88s of the -242.1s of remaining time.\n",
            "\tNo hyperparameter search space specified for XGBoost_r31_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.10%)\n",
            "Fitted model: XGBoost_r31_BAG_L1 ...\n",
            "\t0.8758\t = Validation score   (f1)\n",
            "\t23.07s\t = Training   runtime\n",
            "\t0.37s\t = Validation runtime\n",
            "Hyperparameter tuning model: NeuralNetTorch_r185_BAG_L1 ... Tuning model for up to 8.88s of the -265.24s of remaining time.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------------------------------------------------------+\n",
            "| Configuration for experiment     NeuralNetTorch_r185_BAG_L1   |\n",
            "+---------------------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator              |\n",
            "| Scheduler                        FIFOScheduler                |\n",
            "| Number of trials                 1000                         |\n",
            "+---------------------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r185_BAG_L1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-04 23:01:18,277\tINFO timeout.py:54 -- Reached timeout of 8.879837046424548 seconds. Stopping all trials.\n",
            "2025-10-04 23:01:18,454\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r185_BAG_L1' in 0.1290s.\n",
            "2025-10-04 23:01:27,322\tWARNING experiment_analysis.py:180 -- Failed to fetch metrics for 2 trial(s):\n",
            "- b879e52e: FileNotFoundError('Could not fetch metrics for b879e52e: both result.json and progress.csv were not found at /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r185_BAG_L1/b879e52e')\n",
            "- 83184636: FileNotFoundError('Could not fetch metrics for 83184636: both result.json and progress.csv were not found at /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r185_BAG_L1/83184636')\n",
            "No model was trained during hyperparameter tuning NeuralNetTorch_r185_BAG_L1... Skipping this model.\n",
            "Hyperparameter tuning model: NeuralNetFastAI_r160_BAG_L1 ... Tuning model for up to 8.88s of the -283.4s of remaining time.\n",
            "\tNo hyperparameter search space specified for NeuralNetFastAI_r160_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.04%)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fitted model: NeuralNetFastAI_r160_BAG_L1 ...\n",
            "\t0.8772\t = Validation score   (f1)\n",
            "\t45.09s\t = Training   runtime\n",
            "\t0.3s\t = Validation runtime\n",
            "Hyperparameter tuning model: CatBoost_r60_BAG_L1 ... Tuning model for up to 8.88s of the -328.55s of remaining time.\n",
            "\tNo hyperparameter search space specified for CatBoost_r60_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=4.27%)\n",
            "Fitted model: CatBoost_r60_BAG_L1 ...\n",
            "\t0.8708\t = Validation score   (f1)\n",
            "\t27.98s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Hyperparameter tuning model: RandomForest_r15_BAG_L1 ... Tuning model for up to 8.88s of the -356.57s of remaining time.\n",
            "\tNo hyperparameter search space specified for RandomForest_r15_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "Fitted model: RandomForest_r15_BAG_L1 ...\n",
            "\t0.8865\t = Validation score   (f1)\n",
            "\t7.75s\t = Training   runtime\n",
            "\t0.41s\t = Validation runtime\n",
            "Hyperparameter tuning model: LightGBM_r135_BAG_L1 ... Tuning model for up to 8.88s of the -364.37s of remaining time.\n",
            "\tNo hyperparameter search space specified for LightGBM_r135_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.35%)\n",
            "Fitted model: LightGBM_r135_BAG_L1 ...\n",
            "\t0.882\t = Validation score   (f1)\n",
            "\t37.98s\t = Training   runtime\n",
            "\t0.26s\t = Validation runtime\n",
            "Hyperparameter tuning model: XGBoost_r22_BAG_L1 ... Tuning model for up to 8.88s of the -402.43s of remaining time.\n",
            "\tNo hyperparameter search space specified for XGBoost_r22_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.13%)\n",
            "Fitted model: XGBoost_r22_BAG_L1 ...\n",
            "\t0.8795\t = Validation score   (f1)\n",
            "\t22.23s\t = Training   runtime\n",
            "\t0.12s\t = Validation runtime\n",
            "Hyperparameter tuning model: NeuralNetFastAI_r69_BAG_L1 ... Tuning model for up to 8.88s of the -424.69s of remaining time.\n",
            "\tNo hyperparameter search space specified for NeuralNetFastAI_r69_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
            "Fitted model: NeuralNetFastAI_r69_BAG_L1 ...\n",
            "\t0.8737\t = Validation score   (f1)\n",
            "\t46.41s\t = Training   runtime\n",
            "\t1.0s\t = Validation runtime\n",
            "Hyperparameter tuning model: CatBoost_r6_BAG_L1 ... Tuning model for up to 8.88s of the -471.17s of remaining time.\n",
            "\tNo hyperparameter search space specified for CatBoost_r6_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=4.25%)\n",
            "Warning: Exception caused CatBoost_r6_BAG_L1 to fail during hyperparameter tuning... Skipping this model.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1578, in _hyperparameter_tune\n",
            "    hpo_executor.validate_search_space(search_space, self.name)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/hpo/executors.py\", line 528, in validate_search_space\n",
            "    raise EmptySearchSpace\n",
            "autogluon.core.hpo.exceptions.EmptySearchSpace\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 583, in _process_fold_results\n",
            "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
            "                                                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/_private/worker.py\", line 2782, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/_private/worker.py\", line 929, in get_objects\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(TimeLimitExceeded): \u001b[36mray::_ray_fit()\u001b[39m (pid=117339, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 446, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1068, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 229, in _fit\n",
            "    raise TimeLimitExceeded\n",
            "autogluon.core.utils.exceptions.TimeLimitExceeded\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2557, in _train_single_full\n",
            "    hpo_models, hpo_results = model.hyperparameter_tune(\n",
            "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1972, in hyperparameter_tune\n",
            "    return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 289, in _hyperparameter_tune\n",
            "    return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1580, in _hyperparameter_tune\n",
            "    return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n",
            "    fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1068, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 389, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 868, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 723, in after_all_folds_scheduled\n",
            "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 664, in _run_parallel\n",
            "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 606, in _process_fold_results\n",
            "    raise TimeLimitExceeded\n",
            "autogluon.core.utils.exceptions.TimeLimitExceeded\n",
            "\n",
            "Hyperparameter tuning model: NeuralNetFastAI_r138_BAG_L1 ... Tuning model for up to 8.88s of the -488.37s of remaining time.\n",
            "\tNo hyperparameter search space specified for NeuralNetFastAI_r138_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
            "2025-10-04 23:04:58,932\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "Fitted model: NeuralNetFastAI_r138_BAG_L1 ...\n",
            "\t0.8179\t = Validation score   (f1)\n",
            "\t42.4s\t = Training   runtime\n",
            "\t0.81s\t = Validation runtime\n",
            "Hyperparameter tuning model: LightGBM_r121_BAG_L1 ... Tuning model for up to 8.88s of the -530.83s of remaining time.\n",
            "\tNo hyperparameter search space specified for LightGBM_r121_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.37%)\n",
            "Fitted model: LightGBM_r121_BAG_L1 ...\n",
            "\t0.8751\t = Validation score   (f1)\n",
            "\t39.36s\t = Training   runtime\n",
            "\t0.19s\t = Validation runtime\n",
            "Hyperparameter tuning model: NeuralNetFastAI_r172_BAG_L1 ... Tuning model for up to 8.88s of the -570.24s of remaining time.\n",
            "\tNo hyperparameter search space specified for NeuralNetFastAI_r172_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
            "Fitted model: NeuralNetFastAI_r172_BAG_L1 ...\n",
            "\t0.8901\t = Validation score   (f1)\n",
            "\t48.24s\t = Training   runtime\n",
            "\t0.12s\t = Validation runtime\n",
            "Hyperparameter tuning model: CatBoost_r180_BAG_L1 ... Tuning model for up to 8.88s of the -618.52s of remaining time.\n",
            "\tNo hyperparameter search space specified for CatBoost_r180_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=4.31%)\n",
            "Warning: Exception caused CatBoost_r180_BAG_L1 to fail during hyperparameter tuning... Skipping this model.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1578, in _hyperparameter_tune\n",
            "    hpo_executor.validate_search_space(search_space, self.name)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/hpo/executors.py\", line 528, in validate_search_space\n",
            "    raise EmptySearchSpace\n",
            "autogluon.core.hpo.exceptions.EmptySearchSpace\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 583, in _process_fold_results\n",
            "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
            "                                                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/_private/worker.py\", line 2782, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/_private/worker.py\", line 929, in get_objects\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(TimeLimitExceeded): \u001b[36mray::_ray_fit()\u001b[39m (pid=118764, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 446, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1068, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 229, in _fit\n",
            "    raise TimeLimitExceeded\n",
            "autogluon.core.utils.exceptions.TimeLimitExceeded\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2557, in _train_single_full\n",
            "    hpo_models, hpo_results = model.hyperparameter_tune(\n",
            "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1972, in hyperparameter_tune\n",
            "    return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 289, in _hyperparameter_tune\n",
            "    return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1580, in _hyperparameter_tune\n",
            "    return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n",
            "    fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1068, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 389, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 868, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 723, in after_all_folds_scheduled\n",
            "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 664, in _run_parallel\n",
            "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 606, in _process_fold_results\n",
            "    raise TimeLimitExceeded\n",
            "autogluon.core.utils.exceptions.TimeLimitExceeded\n",
            "\n",
            "Hyperparameter tuning model: NeuralNetTorch_r76_BAG_L1 ... Tuning model for up to 8.88s of the -642.02s of remaining time.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------------------+\n",
            "| Configuration for experiment     NeuralNetTorch_r76_BAG_L1   |\n",
            "+--------------------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator             |\n",
            "| Scheduler                        FIFOScheduler               |\n",
            "| Number of trials                 1000                        |\n",
            "+--------------------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r76_BAG_L1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-04 23:07:26,681\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "2025-10-04 23:07:35,200\tINFO timeout.py:54 -- Reached timeout of 8.879837046424548 seconds. Stopping all trials.\n",
            "2025-10-04 23:07:35,233\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r76_BAG_L1' in 0.0298s.\n",
            "2025-10-04 23:07:45,260\tWARNING experiment_analysis.py:180 -- Failed to fetch metrics for 2 trial(s):\n",
            "- 16475b5a: FileNotFoundError('Could not fetch metrics for 16475b5a: both result.json and progress.csv were not found at /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r76_BAG_L1/16475b5a')\n",
            "- ee702345: FileNotFoundError('Could not fetch metrics for ee702345: both result.json and progress.csv were not found at /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r76_BAG_L1/ee702345')\n",
            "No model was trained during hyperparameter tuning NeuralNetTorch_r76_BAG_L1... Skipping this model.\n",
            "Hyperparameter tuning model: ExtraTrees_r197_BAG_L1 ... Tuning model for up to 8.88s of the -661.34s of remaining time.\n",
            "\tNo hyperparameter search space specified for ExtraTrees_r197_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fitted model: ExtraTrees_r197_BAG_L1 ...\n",
            "\t0.8895\t = Validation score   (f1)\n",
            "\t3.14s\t = Training   runtime\n",
            "\t0.48s\t = Validation runtime\n",
            "Hyperparameter tuning model: NeuralNetTorch_r121_BAG_L1 ... Tuning model for up to 8.88s of the -664.53s of remaining time.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------------------------------------------------------+\n",
            "| Configuration for experiment     NeuralNetTorch_r121_BAG_L1   |\n",
            "+---------------------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator              |\n",
            "| Scheduler                        FIFOScheduler                |\n",
            "| Number of trials                 1000                         |\n",
            "+---------------------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r121_BAG_L1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-04 23:07:57,573\tINFO timeout.py:54 -- Reached timeout of 8.879837046424548 seconds. Stopping all trials.\n",
            "2025-10-04 23:07:57,649\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r121_BAG_L1' in 0.0511s.\n",
            "2025-10-04 23:08:06,566\tWARNING experiment_analysis.py:180 -- Failed to fetch metrics for 2 trial(s):\n",
            "- 62023bfb: FileNotFoundError('Could not fetch metrics for 62023bfb: both result.json and progress.csv were not found at /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r121_BAG_L1/62023bfb')\n",
            "- 01be6a2a: FileNotFoundError('Could not fetch metrics for 01be6a2a: both result.json and progress.csv were not found at /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r121_BAG_L1/01be6a2a')\n",
            "No model was trained during hyperparameter tuning NeuralNetTorch_r121_BAG_L1... Skipping this model.\n",
            "Hyperparameter tuning model: NeuralNetFastAI_r127_BAG_L1 ... Tuning model for up to 8.88s of the -682.66s of remaining time.\n",
            "\tNo hyperparameter search space specified for NeuralNetFastAI_r127_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.04%)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fitted model: NeuralNetFastAI_r127_BAG_L1 ...\n",
            "\t0.8858\t = Validation score   (f1)\n",
            "\t49.46s\t = Training   runtime\n",
            "\t0.14s\t = Validation runtime\n",
            "Hyperparameter tuning model: RandomForest_r16_BAG_L1 ... Tuning model for up to 8.88s of the -732.19s of remaining time.\n",
            "\tNo hyperparameter search space specified for RandomForest_r16_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "Fitted model: RandomForest_r16_BAG_L1 ...\n",
            "\t0.8847\t = Validation score   (f1)\n",
            "\t12.36s\t = Training   runtime\n",
            "\t0.33s\t = Validation runtime\n",
            "Hyperparameter tuning model: NeuralNetFastAI_r194_BAG_L1 ... Tuning model for up to 8.88s of the -744.6s of remaining time.\n",
            "\tNo hyperparameter search space specified for NeuralNetFastAI_r194_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
            "Fitted model: NeuralNetFastAI_r194_BAG_L1 ...\n",
            "\t0.875\t = Validation score   (f1)\n",
            "\t45.27s\t = Training   runtime\n",
            "\t0.27s\t = Validation runtime\n",
            "Hyperparameter tuning model: CatBoost_r12_BAG_L1 ... Tuning model for up to 8.88s of the -789.92s of remaining time.\n",
            "\tNo hyperparameter search space specified for CatBoost_r12_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=4.32%)\n",
            "Fitted model: CatBoost_r12_BAG_L1 ...\n",
            "\t0.8719\t = Validation score   (f1)\n",
            "\t25.26s\t = Training   runtime\n",
            "\t0.13s\t = Validation runtime\n",
            "Hyperparameter tuning model: NeuralNetTorch_r135_BAG_L1 ... Tuning model for up to 8.88s of the -815.24s of remaining time.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------------------------------------------------------+\n",
            "| Configuration for experiment     NeuralNetTorch_r135_BAG_L1   |\n",
            "+---------------------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator              |\n",
            "| Scheduler                        FIFOScheduler                |\n",
            "| Number of trials                 1000                         |\n",
            "+---------------------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r135_BAG_L1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-04 23:10:28,351\tINFO timeout.py:54 -- Reached timeout of 8.879837046424548 seconds. Stopping all trials.\n",
            "2025-10-04 23:10:28,413\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r135_BAG_L1' in 0.0502s.\n",
            "2025-10-04 23:10:37,754\tWARNING experiment_analysis.py:180 -- Failed to fetch metrics for 2 trial(s):\n",
            "- dc813ca1: FileNotFoundError('Could not fetch metrics for dc813ca1: both result.json and progress.csv were not found at /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r135_BAG_L1/dc813ca1')\n",
            "- b0110872: FileNotFoundError('Could not fetch metrics for b0110872: both result.json and progress.csv were not found at /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r135_BAG_L1/b0110872')\n",
            "No model was trained during hyperparameter tuning NeuralNetTorch_r135_BAG_L1... Skipping this model.\n",
            "Hyperparameter tuning model: NeuralNetFastAI_r4_BAG_L1 ... Tuning model for up to 8.88s of the -833.85s of remaining time.\n",
            "\tNo hyperparameter search space specified for NeuralNetFastAI_r4_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.04%)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fitted model: NeuralNetFastAI_r4_BAG_L1 ...\n",
            "\t0.8784\t = Validation score   (f1)\n",
            "\t47.26s\t = Training   runtime\n",
            "\t1.09s\t = Validation runtime\n",
            "Hyperparameter tuning model: ExtraTrees_r126_BAG_L1 ... Tuning model for up to 8.88s of the -881.19s of remaining time.\n",
            "\tNo hyperparameter search space specified for ExtraTrees_r126_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "Fitted model: ExtraTrees_r126_BAG_L1 ...\n",
            "\t0.8745\t = Validation score   (f1)\n",
            "\t2.73s\t = Training   runtime\n",
            "\t0.73s\t = Validation runtime\n",
            "Hyperparameter tuning model: NeuralNetTorch_r36_BAG_L1 ... Tuning model for up to 8.88s of the -883.99s of remaining time.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------------------+\n",
            "| Configuration for experiment     NeuralNetTorch_r36_BAG_L1   |\n",
            "+--------------------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator             |\n",
            "| Scheduler                        FIFOScheduler               |\n",
            "| Number of trials                 1000                        |\n",
            "+--------------------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r36_BAG_L1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-04 23:11:37,250\tINFO timeout.py:54 -- Reached timeout of 8.879837046424548 seconds. Stopping all trials.\n",
            "2025-10-04 23:11:37,288\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r36_BAG_L1' in 0.0248s.\n",
            "2025-10-04 23:11:46,663\tWARNING experiment_analysis.py:180 -- Failed to fetch metrics for 2 trial(s):\n",
            "- 6719adcb: FileNotFoundError('Could not fetch metrics for 6719adcb: both result.json and progress.csv were not found at /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r36_BAG_L1/6719adcb')\n",
            "- 8b628697: FileNotFoundError('Could not fetch metrics for 8b628697: both result.json and progress.csv were not found at /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r36_BAG_L1/8b628697')\n",
            "No model was trained during hyperparameter tuning NeuralNetTorch_r36_BAG_L1... Skipping this model.\n",
            "Hyperparameter tuning model: NeuralNetFastAI_r100_BAG_L1 ... Tuning model for up to 8.88s of the -902.75s of remaining time.\n",
            "\tNo hyperparameter search space specified for NeuralNetFastAI_r100_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.04%)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fitted model: NeuralNetFastAI_r100_BAG_L1 ...\n",
            "\t0.6359\t = Validation score   (f1)\n",
            "\t49.74s\t = Training   runtime\n",
            "\t0.18s\t = Validation runtime\n",
            "Hyperparameter tuning model: CatBoost_r163_BAG_L1 ... Tuning model for up to 8.88s of the -952.55s of remaining time.\n",
            "\tNo hyperparameter search space specified for CatBoost_r163_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=4.31%)\n",
            "Warning: Exception caused CatBoost_r163_BAG_L1 to fail during hyperparameter tuning... Skipping this model.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1578, in _hyperparameter_tune\n",
            "    hpo_executor.validate_search_space(search_space, self.name)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/hpo/executors.py\", line 528, in validate_search_space\n",
            "    raise EmptySearchSpace\n",
            "autogluon.core.hpo.exceptions.EmptySearchSpace\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 583, in _process_fold_results\n",
            "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
            "                                                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/_private/worker.py\", line 2782, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/_private/worker.py\", line 929, in get_objects\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(TimeLimitExceeded): \u001b[36mray::_ray_fit()\u001b[39m (pid=121943, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 446, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1068, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 229, in _fit\n",
            "    raise TimeLimitExceeded\n",
            "autogluon.core.utils.exceptions.TimeLimitExceeded\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2557, in _train_single_full\n",
            "    hpo_models, hpo_results = model.hyperparameter_tune(\n",
            "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1972, in hyperparameter_tune\n",
            "    return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 289, in _hyperparameter_tune\n",
            "    return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1580, in _hyperparameter_tune\n",
            "    return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n",
            "    fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1068, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 389, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 868, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 723, in after_all_folds_scheduled\n",
            "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 664, in _run_parallel\n",
            "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 606, in _process_fold_results\n",
            "    raise TimeLimitExceeded\n",
            "autogluon.core.utils.exceptions.TimeLimitExceeded\n",
            "\n",
            "Hyperparameter tuning model: CatBoost_r198_BAG_L1 ... Tuning model for up to 8.88s of the -959.99s of remaining time.\n",
            "\tNo hyperparameter search space specified for CatBoost_r198_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=4.29%)\n",
            "2025-10-04 23:12:50,111\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "Warning: Exception caused CatBoost_r198_BAG_L1 to fail during hyperparameter tuning... Skipping this model.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1578, in _hyperparameter_tune\n",
            "    hpo_executor.validate_search_space(search_space, self.name)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/hpo/executors.py\", line 528, in validate_search_space\n",
            "    raise EmptySearchSpace\n",
            "autogluon.core.hpo.exceptions.EmptySearchSpace\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 583, in _process_fold_results\n",
            "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
            "                                                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/_private/worker.py\", line 2782, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/_private/worker.py\", line 929, in get_objects\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(TimeLimitExceeded): \u001b[36mray::_ray_fit()\u001b[39m (pid=122199, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 446, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1068, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 229, in _fit\n",
            "    raise TimeLimitExceeded\n",
            "autogluon.core.utils.exceptions.TimeLimitExceeded\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2557, in _train_single_full\n",
            "    hpo_models, hpo_results = model.hyperparameter_tune(\n",
            "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1972, in hyperparameter_tune\n",
            "    return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 289, in _hyperparameter_tune\n",
            "    return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1580, in _hyperparameter_tune\n",
            "    return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n",
            "    fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1068, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 389, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 868, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 723, in after_all_folds_scheduled\n",
            "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 664, in _run_parallel\n",
            "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 606, in _process_fold_results\n",
            "    raise TimeLimitExceeded\n",
            "autogluon.core.utils.exceptions.TimeLimitExceeded\n",
            "\n",
            "Hyperparameter tuning model: NeuralNetFastAI_r187_BAG_L1 ... Tuning model for up to 8.88s of the -976.11s of remaining time.\n",
            "\tNo hyperparameter search space specified for NeuralNetFastAI_r187_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
            "2025-10-04 23:13:00,600\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "Fitted model: NeuralNetFastAI_r187_BAG_L1 ...\n",
            "\t0.8766\t = Validation score   (f1)\n",
            "\t41.91s\t = Training   runtime\n",
            "\t0.27s\t = Validation runtime\n",
            "Hyperparameter tuning model: NeuralNetTorch_r19_BAG_L1 ... Tuning model for up to 8.88s of the -1018.13s of remaining time.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------------------+\n",
            "| Configuration for experiment     NeuralNetTorch_r19_BAG_L1   |\n",
            "+--------------------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator             |\n",
            "| Scheduler                        FIFOScheduler               |\n",
            "| Number of trials                 1000                        |\n",
            "+--------------------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r19_BAG_L1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-04 23:13:51,148\tINFO timeout.py:54 -- Reached timeout of 8.879837046424548 seconds. Stopping all trials.\n",
            "2025-10-04 23:13:51,184\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r19_BAG_L1' in 0.0235s.\n",
            "2025-10-04 23:14:01,231\tWARNING experiment_analysis.py:180 -- Failed to fetch metrics for 2 trial(s):\n",
            "- 90d8b6ad: FileNotFoundError('Could not fetch metrics for 90d8b6ad: both result.json and progress.csv were not found at /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r19_BAG_L1/90d8b6ad')\n",
            "- c58ce016: FileNotFoundError('Could not fetch metrics for c58ce016: both result.json and progress.csv were not found at /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r19_BAG_L1/c58ce016')\n",
            "No model was trained during hyperparameter tuning NeuralNetTorch_r19_BAG_L1... Skipping this model.\n",
            "Hyperparameter tuning model: XGBoost_r95_BAG_L1 ... Tuning model for up to 8.88s of the -1037.32s of remaining time.\n",
            "\tNo hyperparameter search space specified for XGBoost_r95_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.12%)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fitted model: XGBoost_r95_BAG_L1 ...\n",
            "\t0.8807\t = Validation score   (f1)\n",
            "\t25.69s\t = Training   runtime\n",
            "\t0.12s\t = Validation runtime\n",
            "Hyperparameter tuning model: XGBoost_r34_BAG_L1 ... Tuning model for up to 8.88s of the -1063.07s of remaining time.\n",
            "\tNo hyperparameter search space specified for XGBoost_r34_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.42%)\n",
            "Fitted model: XGBoost_r34_BAG_L1 ...\n",
            "\t0.871\t = Validation score   (f1)\n",
            "\t24.58s\t = Training   runtime\n",
            "\t0.18s\t = Validation runtime\n",
            "Hyperparameter tuning model: LightGBM_r42_BAG_L1 ... Tuning model for up to 8.88s of the -1087.69s of remaining time.\n",
            "\tNo hyperparameter search space specified for LightGBM_r42_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.34%)\n",
            "Fitted model: LightGBM_r42_BAG_L1 ...\n",
            "\t0.8611\t = Validation score   (f1)\n",
            "\t34.4s\t = Training   runtime\n",
            "\t0.2s\t = Validation runtime\n",
            "Hyperparameter tuning model: NeuralNetTorch_r1_BAG_L1 ... Tuning model for up to 8.88s of the -1122.12s of remaining time.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------------------------------------------------------+\n",
            "| Configuration for experiment     NeuralNetTorch_r1_BAG_L1   |\n",
            "+-------------------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator            |\n",
            "| Scheduler                        FIFOScheduler              |\n",
            "| Number of trials                 1000                       |\n",
            "+-------------------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r1_BAG_L1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-04 23:15:35,174\tINFO timeout.py:54 -- Reached timeout of 8.879837046424548 seconds. Stopping all trials.\n",
            "2025-10-04 23:15:35,198\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r1_BAG_L1' in 0.0127s.\n",
            "2025-10-04 23:15:35,202\tWARNING experiment_analysis.py:180 -- Failed to fetch metrics for 2 trial(s):\n",
            "- 7e37ff36: FileNotFoundError('Could not fetch metrics for 7e37ff36: both result.json and progress.csv were not found at /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r1_BAG_L1/7e37ff36')\n",
            "- e2b5fc88: FileNotFoundError('Could not fetch metrics for e2b5fc88: both result.json and progress.csv were not found at /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r1_BAG_L1/e2b5fc88')\n",
            "No model was trained during hyperparameter tuning NeuralNetTorch_r1_BAG_L1... Skipping this model.\n",
            "Hyperparameter tuning model: NeuralNetTorch_r89_BAG_L1 ... Tuning model for up to 8.88s of the -1131.27s of remaining time.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "+--------------------------------------------------------------+\n",
            "| Configuration for experiment     NeuralNetTorch_r89_BAG_L1   |\n",
            "+--------------------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator             |\n",
            "| Scheduler                        FIFOScheduler               |\n",
            "| Number of trials                 1000                        |\n",
            "+--------------------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r89_BAG_L1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-04 23:15:44,377\tINFO timeout.py:54 -- Reached timeout of 8.879837046424548 seconds. Stopping all trials.\n",
            "2025-10-04 23:15:44,400\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r89_BAG_L1' in 0.0158s.\n",
            "2025-10-04 23:15:53,213\tWARNING experiment_analysis.py:180 -- Failed to fetch metrics for 2 trial(s):\n",
            "- 55efec48: FileNotFoundError('Could not fetch metrics for 55efec48: both result.json and progress.csv were not found at /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r89_BAG_L1/55efec48')\n",
            "- a65d1c37: FileNotFoundError('Could not fetch metrics for a65d1c37: both result.json and progress.csv were not found at /content/AutogluonModels/ag-20251004_215642/models/NeuralNetTorch_r89_BAG_L1/a65d1c37')\n",
            "No model was trained during hyperparameter tuning NeuralNetTorch_r89_BAG_L1... Skipping this model.\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the -1149.45s of remaining time.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\tEnsemble Weights: {'LightGBM_r135_BAG_L1': 0.238, 'XGBoost_r95_BAG_L1': 0.238, 'ExtraTrees_r42_BAG_L1': 0.19, 'CatBoost_r143_BAG_L1': 0.143, 'RandomForestGini_BAG_L1': 0.095, 'NeuralNetFastAI_r172_BAG_L1': 0.095}\n",
            "\t0.8196\t = Validation score   (f1)\n",
            "\t3.76s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the -1153.91s of remaining time.\n",
            "\tEnsemble Weights: {'LightGBM_r135_BAG_L1': 0.238, 'XGBoost_r95_BAG_L1': 0.238, 'ExtraTrees_r42_BAG_L1': 0.19, 'CatBoost_r143_BAG_L1': 0.143, 'RandomForestGini_BAG_L1': 0.095, 'NeuralNetFastAI_r172_BAG_L1': 0.095}\n",
            "\t0.8196\t = Validation score   (f1)\n",
            "\t2.75s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 2755.67s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1165.3 rows/s (793 batch size)\n",
            "Enabling decision threshold calibration (calibrate_decision_threshold='auto', metric is valid, problem_type is 'binary')\n",
            "Calibrating decision threshold to optimize metric f1 | Checking 51 thresholds...\n",
            "Calibrating decision threshold via fine-grained search | Checking 38 thresholds...\n",
            "\tBase Threshold: 0.500\t| val: 0.8196\n",
            "\tBest Threshold: 0.542\t| val: 0.8201\n",
            "Updating predictor.decision_threshold from 0.5 -> 0.542\n",
            "\tThis will impact how prediction probabilities are converted to predictions in binary classification.\n",
            "\tPrediction probabilities of the positive class >0.542 will be predicted as the positive class (1). This can significantly impact metric scores.\n",
            "\tYou can update this value via `predictor.set_decision_threshold`.\n",
            "\tYou can calculate an optimal decision threshold on the validation data via `predictor.calibrate_decision_threshold()`.\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20251004_215642\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📁 AutoGluon path: /content/AutogluonModels/ag-20251004_215642\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"lb\",\n  \"rows\": 75,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 75,\n        \"samples\": [\n          \"ExtraTrees_r42_BAG_L1\",\n          \"NeuralNetFastAI_r88_BAG_L1\",\n          \"WeightedEnsemble_L3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_test\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06348094070312048,\n        \"min\": 0.34673389764440915,\n        \"max\": 0.8412144785101078,\n        \"num_unique_values\": 71,\n        \"samples\": [\n          0.8234624578734439,\n          0.8412144785101078,\n          0.80834627261303\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_val\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.040331091689641156,\n        \"min\": 0.6359256710254646,\n        \"max\": 0.8923955010911533,\n        \"num_unique_values\": 73,\n        \"samples\": [\n          0.8907048008171604,\n          0.8661041819515775,\n          0.8873048200950441\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_metric\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"f1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_test\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.23875934481628802,\n        \"min\": 0.015406370162963867,\n        \"max\": 1.426687240600586,\n        \"num_unique_values\": 75,\n        \"samples\": [\n          0.3437364101409912\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_val\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2722822334209095,\n        \"min\": 0.02076244354248047,\n        \"max\": 1.3146934509277344,\n        \"num_unique_values\": 75,\n        \"samples\": [\n          0.2593703269958496\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 25.19195002962909,\n        \"min\": 2.305192708969116,\n        \"max\": 151.5346233844757,\n        \"num_unique_values\": 75,\n        \"samples\": [\n          3.7775425910949707\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_test_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1368635388665397,\n        \"min\": 0.005523681640625,\n        \"max\": 0.5951614379882812,\n        \"num_unique_values\": 75,\n        \"samples\": [\n          0.3437364101409912\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_val_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.21809791394051561,\n        \"min\": 0.007880926132202148,\n        \"max\": 1.094165325164795,\n        \"num_unique_values\": 75,\n        \"samples\": [\n          0.2593703269958496\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_time_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16.03394531981681,\n        \"min\": 2.305192708969116,\n        \"max\": 53.41342258453369,\n        \"num_unique_values\": 75,\n        \"samples\": [\n          3.7775425910949707\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stack_level\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"can_infer\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_order\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 21,\n        \"min\": 1,\n        \"max\": 75,\n        \"num_unique_values\": 75,\n        \"samples\": [\n          12\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "lb"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-50cdbb61-a618-423f-b1c7-fb3515bcd68d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>score_test</th>\n",
              "      <th>score_val</th>\n",
              "      <th>eval_metric</th>\n",
              "      <th>pred_time_test</th>\n",
              "      <th>pred_time_val</th>\n",
              "      <th>fit_time</th>\n",
              "      <th>pred_time_test_marginal</th>\n",
              "      <th>pred_time_val_marginal</th>\n",
              "      <th>fit_time_marginal</th>\n",
              "      <th>stack_level</th>\n",
              "      <th>can_infer</th>\n",
              "      <th>fit_order</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RandomForest_r195_BAG_L1</td>\n",
              "      <td>0.841214</td>\n",
              "      <td>0.886111</td>\n",
              "      <td>f1</td>\n",
              "      <td>0.186986</td>\n",
              "      <td>0.299486</td>\n",
              "      <td>7.709634</td>\n",
              "      <td>0.186986</td>\n",
              "      <td>0.299486</td>\n",
              "      <td>7.709634</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RandomForest_r39_BAG_L1</td>\n",
              "      <td>0.840473</td>\n",
              "      <td>0.886569</td>\n",
              "      <td>f1</td>\n",
              "      <td>0.245001</td>\n",
              "      <td>0.334600</td>\n",
              "      <td>9.700997</td>\n",
              "      <td>0.245001</td>\n",
              "      <td>0.334600</td>\n",
              "      <td>9.700997</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RandomForest_r15_BAG_L1</td>\n",
              "      <td>0.839209</td>\n",
              "      <td>0.886475</td>\n",
              "      <td>f1</td>\n",
              "      <td>0.140883</td>\n",
              "      <td>0.409038</td>\n",
              "      <td>7.745776</td>\n",
              "      <td>0.140883</td>\n",
              "      <td>0.409038</td>\n",
              "      <td>7.745776</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RandomForest_r16_BAG_L1</td>\n",
              "      <td>0.837441</td>\n",
              "      <td>0.884721</td>\n",
              "      <td>f1</td>\n",
              "      <td>0.275381</td>\n",
              "      <td>0.325804</td>\n",
              "      <td>12.358092</td>\n",
              "      <td>0.275381</td>\n",
              "      <td>0.325804</td>\n",
              "      <td>12.358092</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ExtraTrees_r42_BAG_L1</td>\n",
              "      <td>0.832541</td>\n",
              "      <td>0.890705</td>\n",
              "      <td>f1</td>\n",
              "      <td>0.343736</td>\n",
              "      <td>0.259370</td>\n",
              "      <td>3.777543</td>\n",
              "      <td>0.343736</td>\n",
              "      <td>0.259370</td>\n",
              "      <td>3.777543</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>LightGBM_r96_BAG_L1</td>\n",
              "      <td>0.768111</td>\n",
              "      <td>0.865443</td>\n",
              "      <td>f1</td>\n",
              "      <td>0.089585</td>\n",
              "      <td>0.068288</td>\n",
              "      <td>38.096897</td>\n",
              "      <td>0.089585</td>\n",
              "      <td>0.068288</td>\n",
              "      <td>38.096897</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>LightGBM_r196_BAG_L1</td>\n",
              "      <td>0.749434</td>\n",
              "      <td>0.837553</td>\n",
              "      <td>f1</td>\n",
              "      <td>0.194065</td>\n",
              "      <td>0.141486</td>\n",
              "      <td>35.630457</td>\n",
              "      <td>0.194065</td>\n",
              "      <td>0.141486</td>\n",
              "      <td>35.630457</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>NeuralNetFastAI_r65_BAG_L1</td>\n",
              "      <td>0.715387</td>\n",
              "      <td>0.801797</td>\n",
              "      <td>f1</td>\n",
              "      <td>0.084133</td>\n",
              "      <td>0.093175</td>\n",
              "      <td>53.413423</td>\n",
              "      <td>0.084133</td>\n",
              "      <td>0.093175</td>\n",
              "      <td>53.413423</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>NeuralNetFastAI_r134_BAG_L1</td>\n",
              "      <td>0.573276</td>\n",
              "      <td>0.674291</td>\n",
              "      <td>f1</td>\n",
              "      <td>0.193936</td>\n",
              "      <td>0.260282</td>\n",
              "      <td>45.648884</td>\n",
              "      <td>0.193936</td>\n",
              "      <td>0.260282</td>\n",
              "      <td>45.648884</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>NeuralNetFastAI_r100_BAG_L1</td>\n",
              "      <td>0.346734</td>\n",
              "      <td>0.635926</td>\n",
              "      <td>f1</td>\n",
              "      <td>0.203614</td>\n",
              "      <td>0.183020</td>\n",
              "      <td>49.742010</td>\n",
              "      <td>0.203614</td>\n",
              "      <td>0.183020</td>\n",
              "      <td>49.742010</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>69</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>75 rows × 13 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-50cdbb61-a618-423f-b1c7-fb3515bcd68d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-50cdbb61-a618-423f-b1c7-fb3515bcd68d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-50cdbb61-a618-423f-b1c7-fb3515bcd68d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-539d7e2d-ac31-4155-aaa9-2a8fc8388561\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-539d7e2d-ac31-4155-aaa9-2a8fc8388561')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-539d7e2d-ac31-4155-aaa9-2a8fc8388561 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_a1258cfa-3910-48cb-9204-3618fcdabfb2\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('lb')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_a1258cfa-3910-48cb-9204-3618fcdabfb2 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('lb');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                          model  score_test  score_val eval_metric  \\\n",
              "0      RandomForest_r195_BAG_L1    0.841214   0.886111          f1   \n",
              "1       RandomForest_r39_BAG_L1    0.840473   0.886569          f1   \n",
              "2       RandomForest_r15_BAG_L1    0.839209   0.886475          f1   \n",
              "3       RandomForest_r16_BAG_L1    0.837441   0.884721          f1   \n",
              "4         ExtraTrees_r42_BAG_L1    0.832541   0.890705          f1   \n",
              "..                          ...         ...        ...         ...   \n",
              "70          LightGBM_r96_BAG_L1    0.768111   0.865443          f1   \n",
              "71         LightGBM_r196_BAG_L1    0.749434   0.837553          f1   \n",
              "72   NeuralNetFastAI_r65_BAG_L1    0.715387   0.801797          f1   \n",
              "73  NeuralNetFastAI_r134_BAG_L1    0.573276   0.674291          f1   \n",
              "74  NeuralNetFastAI_r100_BAG_L1    0.346734   0.635926          f1   \n",
              "\n",
              "    pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  \\\n",
              "0         0.186986       0.299486   7.709634                 0.186986   \n",
              "1         0.245001       0.334600   9.700997                 0.245001   \n",
              "2         0.140883       0.409038   7.745776                 0.140883   \n",
              "3         0.275381       0.325804  12.358092                 0.275381   \n",
              "4         0.343736       0.259370   3.777543                 0.343736   \n",
              "..             ...            ...        ...                      ...   \n",
              "70        0.089585       0.068288  38.096897                 0.089585   \n",
              "71        0.194065       0.141486  35.630457                 0.194065   \n",
              "72        0.084133       0.093175  53.413423                 0.084133   \n",
              "73        0.193936       0.260282  45.648884                 0.193936   \n",
              "74        0.203614       0.183020  49.742010                 0.203614   \n",
              "\n",
              "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
              "0                 0.299486           7.709634            1       True   \n",
              "1                 0.334600           9.700997            1       True   \n",
              "2                 0.409038           7.745776            1       True   \n",
              "3                 0.325804          12.358092            1       True   \n",
              "4                 0.259370           3.777543            1       True   \n",
              "..                     ...                ...          ...        ...   \n",
              "70                0.068288          38.096897            1       True   \n",
              "71                0.141486          35.630457            1       True   \n",
              "72                0.093175          53.413423            1       True   \n",
              "73                0.260282          45.648884            1       True   \n",
              "74                0.183020          49.742010            1       True   \n",
              "\n",
              "    fit_order  \n",
              "0          15  \n",
              "1          30  \n",
              "2          55  \n",
              "3          64  \n",
              "4          12  \n",
              "..        ...  \n",
              "70         10  \n",
              "71         29  \n",
              "72         45  \n",
              "73         40  \n",
              "74         69  \n",
              "\n",
              "[75 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"    print(f\\\"\\u2705 Exports: {REPORT_THR_CSV} | {REPORT_FN_CSV}\\\")\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"threshold\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.15138251770487454,\n        \"min\": 0.05,\n        \"max\": 0.49999999999999994,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.44999999999999996,\n          0.1,\n          0.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17,\n        \"min\": 637,\n        \"max\": 691,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          651,\n          687,\n          674\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 54,\n        \"min\": 89,\n        \"max\": 256,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          97,\n          208,\n          130\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FN\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17,\n        \"min\": 1,\n        \"max\": 55,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          41,\n          5,\n          18\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TN\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 54,\n        \"min\": 44,\n        \"max\": 211,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          203,\n          92,\n          170\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FN_rate(%)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.532683657102748,\n        \"min\": 0.14450867052023122,\n        \"max\": 7.9479768786127165,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          5.92485549132948,\n          0.7225433526011561,\n          2.601156069364162\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04890988306130659,\n        \"min\": 0.7296726504751848,\n        \"max\": 0.8774104683195593,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.8703208556149733,\n          0.7675977653631285,\n          0.8383084577114428\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.025326836571027488,\n        \"min\": 0.9205202312138728,\n        \"max\": 0.9985549132947977,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.9407514450867052,\n          0.9927745664739884,\n          0.9739884393063584\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02094897234464253,\n        \"min\": 0.8431970713849909,\n        \"max\": 0.9089673913043478,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.9041666666666667,\n          0.8657844990548205,\n          0.9010695187165776\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Specificity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1808675936140941,\n        \"min\": 0.14666666666666667,\n        \"max\": 0.7033333333333334,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.6766666666666666,\n          0.30666666666666664,\n          0.5666666666666667\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.040521044965862445,\n        \"min\": 0.7409274193548387,\n        \"max\": 0.8649193548387096,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.8608870967741935,\n          0.7852822580645161,\n          0.8508064516129032\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-9ced5e71-2466-4b6b-84bb-dfc1bbbdef6e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>threshold</th>\n",
              "      <th>TP</th>\n",
              "      <th>FP</th>\n",
              "      <th>FN</th>\n",
              "      <th>TN</th>\n",
              "      <th>FN_rate(%)</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.05</td>\n",
              "      <td>691</td>\n",
              "      <td>256</td>\n",
              "      <td>1</td>\n",
              "      <td>44</td>\n",
              "      <td>0.144509</td>\n",
              "      <td>0.729673</td>\n",
              "      <td>0.998555</td>\n",
              "      <td>0.843197</td>\n",
              "      <td>0.146667</td>\n",
              "      <td>0.740927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.10</td>\n",
              "      <td>687</td>\n",
              "      <td>208</td>\n",
              "      <td>5</td>\n",
              "      <td>92</td>\n",
              "      <td>0.722543</td>\n",
              "      <td>0.767598</td>\n",
              "      <td>0.992775</td>\n",
              "      <td>0.865784</td>\n",
              "      <td>0.306667</td>\n",
              "      <td>0.785282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.15</td>\n",
              "      <td>685</td>\n",
              "      <td>184</td>\n",
              "      <td>7</td>\n",
              "      <td>116</td>\n",
              "      <td>1.011561</td>\n",
              "      <td>0.788262</td>\n",
              "      <td>0.989884</td>\n",
              "      <td>0.877643</td>\n",
              "      <td>0.386667</td>\n",
              "      <td>0.807460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.20</td>\n",
              "      <td>682</td>\n",
              "      <td>166</td>\n",
              "      <td>10</td>\n",
              "      <td>134</td>\n",
              "      <td>1.445087</td>\n",
              "      <td>0.804245</td>\n",
              "      <td>0.985549</td>\n",
              "      <td>0.885714</td>\n",
              "      <td>0.446667</td>\n",
              "      <td>0.822581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.25</td>\n",
              "      <td>680</td>\n",
              "      <td>146</td>\n",
              "      <td>12</td>\n",
              "      <td>154</td>\n",
              "      <td>1.734104</td>\n",
              "      <td>0.823245</td>\n",
              "      <td>0.982659</td>\n",
              "      <td>0.895916</td>\n",
              "      <td>0.513333</td>\n",
              "      <td>0.840726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.30</td>\n",
              "      <td>674</td>\n",
              "      <td>130</td>\n",
              "      <td>18</td>\n",
              "      <td>170</td>\n",
              "      <td>2.601156</td>\n",
              "      <td>0.838308</td>\n",
              "      <td>0.973988</td>\n",
              "      <td>0.901070</td>\n",
              "      <td>0.566667</td>\n",
              "      <td>0.850806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.35</td>\n",
              "      <td>669</td>\n",
              "      <td>111</td>\n",
              "      <td>23</td>\n",
              "      <td>189</td>\n",
              "      <td>3.323699</td>\n",
              "      <td>0.857692</td>\n",
              "      <td>0.966763</td>\n",
              "      <td>0.908967</td>\n",
              "      <td>0.630000</td>\n",
              "      <td>0.864919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.40</td>\n",
              "      <td>659</td>\n",
              "      <td>105</td>\n",
              "      <td>33</td>\n",
              "      <td>195</td>\n",
              "      <td>4.768786</td>\n",
              "      <td>0.862565</td>\n",
              "      <td>0.952312</td>\n",
              "      <td>0.905220</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.860887</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.45</td>\n",
              "      <td>651</td>\n",
              "      <td>97</td>\n",
              "      <td>41</td>\n",
              "      <td>203</td>\n",
              "      <td>5.924855</td>\n",
              "      <td>0.870321</td>\n",
              "      <td>0.940751</td>\n",
              "      <td>0.904167</td>\n",
              "      <td>0.676667</td>\n",
              "      <td>0.860887</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.50</td>\n",
              "      <td>637</td>\n",
              "      <td>89</td>\n",
              "      <td>55</td>\n",
              "      <td>211</td>\n",
              "      <td>7.947977</td>\n",
              "      <td>0.877410</td>\n",
              "      <td>0.920520</td>\n",
              "      <td>0.898449</td>\n",
              "      <td>0.703333</td>\n",
              "      <td>0.854839</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9ced5e71-2466-4b6b-84bb-dfc1bbbdef6e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9ced5e71-2466-4b6b-84bb-dfc1bbbdef6e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9ced5e71-2466-4b6b-84bb-dfc1bbbdef6e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-aa463aba-8584-40c6-bb9a-0cf4675373c4\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-aa463aba-8584-40c6-bb9a-0cf4675373c4')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-aa463aba-8584-40c6-bb9a-0cf4675373c4 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   threshold   TP   FP  FN   TN  FN_rate(%)  Precision    Recall        F1  \\\n",
              "0       0.05  691  256   1   44    0.144509   0.729673  0.998555  0.843197   \n",
              "1       0.10  687  208   5   92    0.722543   0.767598  0.992775  0.865784   \n",
              "2       0.15  685  184   7  116    1.011561   0.788262  0.989884  0.877643   \n",
              "3       0.20  682  166  10  134    1.445087   0.804245  0.985549  0.885714   \n",
              "4       0.25  680  146  12  154    1.734104   0.823245  0.982659  0.895916   \n",
              "5       0.30  674  130  18  170    2.601156   0.838308  0.973988  0.901070   \n",
              "6       0.35  669  111  23  189    3.323699   0.857692  0.966763  0.908967   \n",
              "7       0.40  659  105  33  195    4.768786   0.862565  0.952312  0.905220   \n",
              "8       0.45  651   97  41  203    5.924855   0.870321  0.940751  0.904167   \n",
              "9       0.50  637   89  55  211    7.947977   0.877410  0.920520  0.898449   \n",
              "\n",
              "   Specificity  Accuracy  \n",
              "0     0.146667  0.740927  \n",
              "1     0.306667  0.785282  \n",
              "2     0.386667  0.807460  \n",
              "3     0.446667  0.822581  \n",
              "4     0.513333  0.840726  \n",
              "5     0.566667  0.850806  \n",
              "6     0.630000  0.864919  \n",
              "7     0.650000  0.860887  \n",
              "8     0.676667  0.860887  \n",
              "9     0.703333  0.854839  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Limiar AutoGluon: {'thr_f1': 0.35000000000000003, 'thr_rec': 0.01, 'thr90': 0.56}\n",
            "[AutoGluon] TP=669 | FP=111 | FN=23 | TN=189\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.892     0.630     0.738       300\n",
            "           1      0.858     0.967     0.909       692\n",
            "\n",
            "    accuracy                          0.865       992\n",
            "   macro avg      0.875     0.798     0.824       992\n",
            "weighted avg      0.868     0.865     0.857       992\n",
            "\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'list' object has no attribute 'shape'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-731546937.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mTHR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthr_f1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthr_f1\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mfinal_reports\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_proba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTHR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"[AutoGluon] \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;31m# 6) Exports úteis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-468002529.py\u001b[0m in \u001b[0;36mfinal_reports\u001b[0;34m(y_true, proba, thr, title_prefix)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{title_prefix}TP={tp} | FP={fp} | FN={fn} | TN={tn}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdigits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mConfusionMatrixDisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{title_prefix}Matriz de Confusão (thr={thr:.2f})\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_plot/confusion_matrix.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, include_values, cmap, xticks_rotation, values_format, ax, colorbar, im_kw, text_kw)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0mn_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mdefault_im_kw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"nearest\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# =====================================\n",
        "# ✅ CONFIGURAÇÃO BASE (antes do AutoGluon)\n",
        "# =====================================\n",
        "from autogluon.tabular import TabularPredictor\n",
        "import numpy as np\n",
        "\n",
        "# Calcula pesos para classes desbalanceadas\n",
        "if 'sample_weight' not in train_df.columns:\n",
        "    counts = train_df[TARGET].value_counts()\n",
        "    w_map = (len(train_df) / (2.0 * counts)).to_dict()\n",
        "    train_df = train_df.copy()\n",
        "    train_df['sample_weight'] = train_df[TARGET].map(w_map).astype('float32')\n",
        "else:\n",
        "    counts = train_df[TARGET].value_counts()\n",
        "    w_map = (len(train_df) / (2.0 * counts)).to_dict()\n",
        "\n",
        "# Replica pesos no conjunto de teste\n",
        "test_df = test_df.copy()\n",
        "test_df['sample_weight'] = test_df[TARGET].map(w_map).astype('float32')\n",
        "\n",
        "# =====================================\n",
        "# 🚀 AUTOGLUON COM PESOS\n",
        "# =====================================\n",
        "if not _AG_OK:\n",
        "    print(\"AutoGluon indisponível.\")\n",
        "else:\n",
        "    ag_predictor = TabularPredictor(\n",
        "        label=TARGET,\n",
        "        problem_type='binary',\n",
        "        eval_metric=EVAL_METRIC,\n",
        "        sample_weight='sample_weight',\n",
        "        weight_evaluation=True,\n",
        "        verbosity=2\n",
        "    )\n",
        "\n",
        "    fit_kwargs = dict(\n",
        "        train_data=train_df,\n",
        "        presets='best_quality',\n",
        "        time_limit=3600,\n",
        "        hyperparameter_tune_kwargs='auto'\n",
        "    )\n",
        "\n",
        "    ag_predictor = ag_predictor.fit(**fit_kwargs)\n",
        "\n",
        "    print(\"📁 AutoGluon path:\", ag_predictor.path)\n",
        "\n",
        "    # Leaderboard ponderado\n",
        "    try:\n",
        "        lb = ag_predictor.leaderboard(test_df, silent=True)\n",
        "    except Exception as e:\n",
        "        print(\"⚠️ leaderboard com pesos falhou, tentando sem pesos:\", e)\n",
        "        lb = ag_predictor.leaderboard(test_df.drop(columns=['sample_weight']), silent=True)\n",
        "    display(lb)\n",
        "\n",
        "    # --- Probabilidades e limiares ---\n",
        "    ag_proba = ag_predictor.predict_proba(test_df.drop(columns=['sample_weight'], errors='ignore'))\n",
        "    y_true = test_df[TARGET].values\n",
        "\n",
        "    ag_thr_tbl = sweep_thresholds(y_true, ag_proba, np.linspace(0.05, 0.95, 19))\n",
        "    display(ag_thr_tbl.head(10))\n",
        "\n",
        "    thr_f1  = best_threshold(y_true, ag_proba, optimize='f1')\n",
        "    thr_rec = best_threshold(y_true, ag_proba, optimize='recall')\n",
        "    thr90   = best_threshold(y_true, ag_proba, min_recall=0.90)\n",
        "\n",
        "    print(\"Limiar AutoGluon:\", {\"thr_f1\": thr_f1, \"thr_rec\": thr_rec, \"thr90\": thr90})\n",
        "    THR = thr_f1 if thr_f1 is not None else 0.5\n",
        "\n",
        "    # --- Relatórios visuais ---\n",
        "    metrics = final_reports(y_true, ag_proba, THR, title_prefix=\"[AutoGluon] \")\n",
        "\n",
        "    # --- Exports úteis ---\n",
        "    ag_thr_tbl.to_csv(REPORT_THR_CSV, index=False)\n",
        "    y_pred_exp = (_pos_proba(ag_proba) >= THR).astype(int)\n",
        "    fn_mask = (test_df[TARGET].values == 1) & (y_pred_exp == 0)\n",
        "    test_df.loc[fn_mask].to_csv(REPORT_FN_CSV, index=False)\n",
        "\n",
        "    print(f\"✅ Exports salvos:\\n - {REPORT_THR_CSV}\\n - {REPORT_FN_CSV}\")\n",
        "    print(\"📈 Métricas resumidas:\", metrics)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08c2988c",
      "metadata": {
        "id": "08c2988c"
      },
      "source": [
        "## 7) AutoML #2 — FLAML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73e8269a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "73e8269a",
        "outputId": "90cf0b51-7199-45f2-89aa-acf9c9bf3131"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[flaml.automl.logger: 10-04 23:18:32] {1752} INFO - task = classification\n",
            "[flaml.automl.logger: 10-04 23:18:32] {1763} INFO - Evaluation method: cv\n",
            "[flaml.automl.logger: 10-04 23:18:32] {1862} INFO - Minimizing error metric: 1-f1\n",
            "[flaml.automl.logger: 10-04 23:18:32] {1979} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'sgd', 'catboost', 'lrl1']\n",
            "[flaml.automl.logger: 10-04 23:18:32] {2282} INFO - iteration 0, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:18:32] {2417} INFO - Estimated sufficient time budget=1559s. Estimated necessary time budget=38s.\n",
            "[flaml.automl.logger: 10-04 23:18:32] {2466} INFO -  at 0.2s,\testimator lgbm's best error=0.2286,\tbest estimator lgbm's best error=0.2286\n",
            "[flaml.automl.logger: 10-04 23:18:32] {2282} INFO - iteration 1, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:18:32] {2466} INFO -  at 0.3s,\testimator lgbm's best error=0.2286,\tbest estimator lgbm's best error=0.2286\n",
            "[flaml.automl.logger: 10-04 23:18:32] {2282} INFO - iteration 2, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:18:32] {2466} INFO -  at 0.4s,\testimator lgbm's best error=0.2124,\tbest estimator lgbm's best error=0.2124\n",
            "[flaml.automl.logger: 10-04 23:18:32] {2282} INFO - iteration 3, current learner sgd\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:flaml.tune.searcher.blendsearch:No low-cost partial config given to the search algorithm. For cost-frugal search, consider providing low-cost values for cost-related hps via 'low_cost_partial_config'. More info can be found at https://microsoft.github.io/FLAML/docs/FAQ#about-low_cost_partial_config-in-tune\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[flaml.automl.logger: 10-04 23:18:32] {2466} INFO -  at 0.6s,\testimator sgd's best error=0.4231,\tbest estimator lgbm's best error=0.2124\n",
            "[flaml.automl.logger: 10-04 23:18:32] {2282} INFO - iteration 4, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:18:32] {2466} INFO -  at 0.7s,\testimator lgbm's best error=0.2045,\tbest estimator lgbm's best error=0.2045\n",
            "[flaml.automl.logger: 10-04 23:18:32] {2282} INFO - iteration 5, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:18:33] {2466} INFO -  at 0.8s,\testimator lgbm's best error=0.2045,\tbest estimator lgbm's best error=0.2045\n",
            "[flaml.automl.logger: 10-04 23:18:33] {2282} INFO - iteration 6, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:18:33] {2466} INFO -  at 1.1s,\testimator lgbm's best error=0.2045,\tbest estimator lgbm's best error=0.2045\n",
            "[flaml.automl.logger: 10-04 23:18:33] {2282} INFO - iteration 7, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:18:33] {2466} INFO -  at 1.2s,\testimator lgbm's best error=0.2045,\tbest estimator lgbm's best error=0.2045\n",
            "[flaml.automl.logger: 10-04 23:18:33] {2282} INFO - iteration 8, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:18:33] {2466} INFO -  at 1.4s,\testimator sgd's best error=0.4231,\tbest estimator lgbm's best error=0.2045\n",
            "[flaml.automl.logger: 10-04 23:18:33] {2282} INFO - iteration 9, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:18:33] {2466} INFO -  at 1.5s,\testimator sgd's best error=0.4231,\tbest estimator lgbm's best error=0.2045\n",
            "[flaml.automl.logger: 10-04 23:18:33] {2282} INFO - iteration 10, current learner xgboost\n",
            "[flaml.automl.logger: 10-04 23:18:33] {2466} INFO -  at 1.7s,\testimator xgboost's best error=0.2266,\tbest estimator lgbm's best error=0.2045\n",
            "[flaml.automl.logger: 10-04 23:18:33] {2282} INFO - iteration 11, current learner xgboost\n",
            "[flaml.automl.logger: 10-04 23:18:34] {2466} INFO -  at 1.8s,\testimator xgboost's best error=0.2226,\tbest estimator lgbm's best error=0.2045\n",
            "[flaml.automl.logger: 10-04 23:18:34] {2282} INFO - iteration 12, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:18:34] {2466} INFO -  at 2.0s,\testimator extra_tree's best error=0.3478,\tbest estimator lgbm's best error=0.2045\n",
            "[flaml.automl.logger: 10-04 23:18:34] {2282} INFO - iteration 13, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:18:34] {2466} INFO -  at 2.3s,\testimator extra_tree's best error=0.3478,\tbest estimator lgbm's best error=0.2045\n",
            "[flaml.automl.logger: 10-04 23:18:34] {2282} INFO - iteration 14, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:18:34] {2466} INFO -  at 2.5s,\testimator rf's best error=0.2211,\tbest estimator lgbm's best error=0.2045\n",
            "[flaml.automl.logger: 10-04 23:18:34] {2282} INFO - iteration 15, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:18:35] {2466} INFO -  at 2.9s,\testimator rf's best error=0.2211,\tbest estimator lgbm's best error=0.2045\n",
            "[flaml.automl.logger: 10-04 23:18:35] {2282} INFO - iteration 16, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:18:35] {2466} INFO -  at 3.2s,\testimator extra_tree's best error=0.2732,\tbest estimator lgbm's best error=0.2045\n",
            "[flaml.automl.logger: 10-04 23:18:35] {2282} INFO - iteration 17, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:18:36] {2466} INFO -  at 3.9s,\testimator rf's best error=0.2211,\tbest estimator lgbm's best error=0.2045\n",
            "[flaml.automl.logger: 10-04 23:18:36] {2282} INFO - iteration 18, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:18:36] {2466} INFO -  at 4.1s,\testimator sgd's best error=0.4231,\tbest estimator lgbm's best error=0.2045\n",
            "[flaml.automl.logger: 10-04 23:18:36] {2282} INFO - iteration 19, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:18:37] {2466} INFO -  at 5.1s,\testimator lgbm's best error=0.1951,\tbest estimator lgbm's best error=0.1951\n",
            "[flaml.automl.logger: 10-04 23:18:37] {2282} INFO - iteration 20, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:18:37] {2466} INFO -  at 5.3s,\testimator sgd's best error=0.4231,\tbest estimator lgbm's best error=0.1951\n",
            "[flaml.automl.logger: 10-04 23:18:37] {2282} INFO - iteration 21, current learner xgboost\n",
            "[flaml.automl.logger: 10-04 23:18:38] {2466} INFO -  at 6.0s,\testimator xgboost's best error=0.2101,\tbest estimator lgbm's best error=0.1951\n",
            "[flaml.automl.logger: 10-04 23:18:38] {2282} INFO - iteration 22, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:18:38] {2466} INFO -  at 6.4s,\testimator extra_tree's best error=0.2732,\tbest estimator lgbm's best error=0.1951\n",
            "[flaml.automl.logger: 10-04 23:18:38] {2282} INFO - iteration 23, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:18:38] {2466} INFO -  at 6.7s,\testimator lgbm's best error=0.1951,\tbest estimator lgbm's best error=0.1951\n",
            "[flaml.automl.logger: 10-04 23:18:38] {2282} INFO - iteration 24, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:18:39] {2466} INFO -  at 7.0s,\testimator rf's best error=0.2200,\tbest estimator lgbm's best error=0.1951\n",
            "[flaml.automl.logger: 10-04 23:18:39] {2282} INFO - iteration 25, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:18:39] {2466} INFO -  at 7.1s,\testimator sgd's best error=0.4231,\tbest estimator lgbm's best error=0.1951\n",
            "[flaml.automl.logger: 10-04 23:18:39] {2282} INFO - iteration 26, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:18:39] {2466} INFO -  at 7.2s,\testimator sgd's best error=0.4231,\tbest estimator lgbm's best error=0.1951\n",
            "[flaml.automl.logger: 10-04 23:18:39] {2282} INFO - iteration 27, current learner xgboost\n",
            "[flaml.automl.logger: 10-04 23:18:39] {2466} INFO -  at 7.3s,\testimator xgboost's best error=0.2101,\tbest estimator lgbm's best error=0.1951\n",
            "[flaml.automl.logger: 10-04 23:18:39] {2282} INFO - iteration 28, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:18:39] {2466} INFO -  at 7.5s,\testimator sgd's best error=0.4231,\tbest estimator lgbm's best error=0.1951\n",
            "[flaml.automl.logger: 10-04 23:18:39] {2282} INFO - iteration 29, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:18:39] {2466} INFO -  at 7.6s,\testimator sgd's best error=0.4050,\tbest estimator lgbm's best error=0.1951\n",
            "[flaml.automl.logger: 10-04 23:18:39] {2282} INFO - iteration 30, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:18:40] {2466} INFO -  at 7.8s,\testimator extra_tree's best error=0.2732,\tbest estimator lgbm's best error=0.1951\n",
            "[flaml.automl.logger: 10-04 23:18:40] {2282} INFO - iteration 31, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:18:40] {2466} INFO -  at 8.0s,\testimator lgbm's best error=0.1951,\tbest estimator lgbm's best error=0.1951\n",
            "[flaml.automl.logger: 10-04 23:18:40] {2282} INFO - iteration 32, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:18:40] {2466} INFO -  at 8.3s,\testimator lgbm's best error=0.1951,\tbest estimator lgbm's best error=0.1951\n",
            "[flaml.automl.logger: 10-04 23:18:40] {2282} INFO - iteration 33, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:18:40] {2466} INFO -  at 8.6s,\testimator lgbm's best error=0.1951,\tbest estimator lgbm's best error=0.1951\n",
            "[flaml.automl.logger: 10-04 23:18:40] {2282} INFO - iteration 34, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:18:41] {2466} INFO -  at 9.0s,\testimator extra_tree's best error=0.2732,\tbest estimator lgbm's best error=0.1951\n",
            "[flaml.automl.logger: 10-04 23:18:41] {2282} INFO - iteration 35, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:18:41] {2466} INFO -  at 9.1s,\testimator lgbm's best error=0.1951,\tbest estimator lgbm's best error=0.1951\n",
            "[flaml.automl.logger: 10-04 23:18:41] {2282} INFO - iteration 36, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:18:41] {2466} INFO -  at 9.4s,\testimator rf's best error=0.2197,\tbest estimator lgbm's best error=0.1951\n",
            "[flaml.automl.logger: 10-04 23:18:41] {2282} INFO - iteration 37, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:18:41] {2466} INFO -  at 9.6s,\testimator extra_tree's best error=0.2732,\tbest estimator lgbm's best error=0.1951\n",
            "[flaml.automl.logger: 10-04 23:18:41] {2282} INFO - iteration 38, current learner xgboost\n",
            "[flaml.automl.logger: 10-04 23:18:41] {2466} INFO -  at 9.7s,\testimator xgboost's best error=0.2078,\tbest estimator lgbm's best error=0.1951\n",
            "[flaml.automl.logger: 10-04 23:18:41] {2282} INFO - iteration 39, current learner xgboost\n",
            "[flaml.automl.logger: 10-04 23:18:42] {2466} INFO -  at 9.9s,\testimator xgboost's best error=0.2078,\tbest estimator lgbm's best error=0.1951\n",
            "[flaml.automl.logger: 10-04 23:18:42] {2282} INFO - iteration 40, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:18:42] {2466} INFO -  at 10.0s,\testimator lgbm's best error=0.1951,\tbest estimator lgbm's best error=0.1951\n",
            "[flaml.automl.logger: 10-04 23:18:42] {2282} INFO - iteration 41, current learner xgboost\n",
            "[flaml.automl.logger: 10-04 23:18:42] {2466} INFO -  at 10.2s,\testimator xgboost's best error=0.2000,\tbest estimator lgbm's best error=0.1951\n",
            "[flaml.automl.logger: 10-04 23:18:42] {2282} INFO - iteration 42, current learner xgboost\n",
            "[flaml.automl.logger: 10-04 23:18:43] {2466} INFO -  at 10.8s,\testimator xgboost's best error=0.1964,\tbest estimator lgbm's best error=0.1951\n",
            "[flaml.automl.logger: 10-04 23:18:43] {2282} INFO - iteration 43, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:18:43] {2466} INFO -  at 11.2s,\testimator lgbm's best error=0.1951,\tbest estimator lgbm's best error=0.1951\n",
            "[flaml.automl.logger: 10-04 23:18:43] {2282} INFO - iteration 44, current learner xgboost\n",
            "[flaml.automl.logger: 10-04 23:18:43] {2466} INFO -  at 11.4s,\testimator xgboost's best error=0.1964,\tbest estimator lgbm's best error=0.1951\n",
            "[flaml.automl.logger: 10-04 23:18:43] {2282} INFO - iteration 45, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:18:43] {2466} INFO -  at 11.5s,\testimator sgd's best error=0.4050,\tbest estimator lgbm's best error=0.1951\n",
            "[flaml.automl.logger: 10-04 23:18:43] {2282} INFO - iteration 46, current learner xgboost\n",
            "[flaml.automl.logger: 10-04 23:18:44] {2466} INFO -  at 11.8s,\testimator xgboost's best error=0.1964,\tbest estimator lgbm's best error=0.1951\n",
            "[flaml.automl.logger: 10-04 23:18:44] {2282} INFO - iteration 47, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:18:44] {2466} INFO -  at 12.1s,\testimator lgbm's best error=0.1951,\tbest estimator lgbm's best error=0.1951\n",
            "[flaml.automl.logger: 10-04 23:18:44] {2282} INFO - iteration 48, current learner xgboost\n",
            "[flaml.automl.logger: 10-04 23:18:44] {2466} INFO -  at 12.7s,\testimator xgboost's best error=0.1964,\tbest estimator lgbm's best error=0.1951\n",
            "[flaml.automl.logger: 10-04 23:18:44] {2282} INFO - iteration 49, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:18:45] {2466} INFO -  at 12.9s,\testimator lgbm's best error=0.1951,\tbest estimator lgbm's best error=0.1951\n",
            "[flaml.automl.logger: 10-04 23:18:45] {2282} INFO - iteration 50, current learner xgboost\n",
            "[flaml.automl.logger: 10-04 23:18:45] {2466} INFO -  at 13.1s,\testimator xgboost's best error=0.1964,\tbest estimator lgbm's best error=0.1951\n",
            "[flaml.automl.logger: 10-04 23:18:45] {2282} INFO - iteration 51, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:18:45] {2466} INFO -  at 13.4s,\testimator extra_tree's best error=0.2732,\tbest estimator lgbm's best error=0.1951\n",
            "[flaml.automl.logger: 10-04 23:18:45] {2282} INFO - iteration 52, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:18:45] {2466} INFO -  at 13.5s,\testimator lgbm's best error=0.1951,\tbest estimator lgbm's best error=0.1951\n",
            "[flaml.automl.logger: 10-04 23:18:45] {2282} INFO - iteration 53, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:18:45] {2466} INFO -  at 13.8s,\testimator lgbm's best error=0.1951,\tbest estimator lgbm's best error=0.1951\n",
            "[flaml.automl.logger: 10-04 23:18:45] {2282} INFO - iteration 54, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:18:46] {2466} INFO -  at 14.0s,\testimator lgbm's best error=0.1920,\tbest estimator lgbm's best error=0.1920\n",
            "[flaml.automl.logger: 10-04 23:18:46] {2282} INFO - iteration 55, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:18:49] {2466} INFO -  at 16.8s,\testimator catboost's best error=0.1929,\tbest estimator lgbm's best error=0.1920\n",
            "[flaml.automl.logger: 10-04 23:18:49] {2282} INFO - iteration 56, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:18:49] {2466} INFO -  at 17.3s,\testimator lgbm's best error=0.1920,\tbest estimator lgbm's best error=0.1920\n",
            "[flaml.automl.logger: 10-04 23:18:49] {2282} INFO - iteration 57, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:18:49] {2466} INFO -  at 17.5s,\testimator sgd's best error=0.4050,\tbest estimator lgbm's best error=0.1920\n",
            "[flaml.automl.logger: 10-04 23:18:49] {2282} INFO - iteration 58, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:18:51] {2466} INFO -  at 19.4s,\testimator lgbm's best error=0.1920,\tbest estimator lgbm's best error=0.1920\n",
            "[flaml.automl.logger: 10-04 23:18:51] {2282} INFO - iteration 59, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:18:52] {2466} INFO -  at 20.4s,\testimator lgbm's best error=0.1920,\tbest estimator lgbm's best error=0.1920\n",
            "[flaml.automl.logger: 10-04 23:18:52] {2282} INFO - iteration 60, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:18:53] {2466} INFO -  at 21.0s,\testimator extra_tree's best error=0.2732,\tbest estimator lgbm's best error=0.1920\n",
            "[flaml.automl.logger: 10-04 23:18:53] {2282} INFO - iteration 61, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:18:53] {2466} INFO -  at 21.2s,\testimator lgbm's best error=0.1920,\tbest estimator lgbm's best error=0.1920\n",
            "[flaml.automl.logger: 10-04 23:18:53] {2282} INFO - iteration 62, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:18:53] {2466} INFO -  at 21.6s,\testimator extra_tree's best error=0.2732,\tbest estimator lgbm's best error=0.1920\n",
            "[flaml.automl.logger: 10-04 23:18:53] {2282} INFO - iteration 63, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:18:54] {2466} INFO -  at 22.0s,\testimator lgbm's best error=0.1920,\tbest estimator lgbm's best error=0.1920\n",
            "[flaml.automl.logger: 10-04 23:18:54] {2282} INFO - iteration 64, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:18:54] {2466} INFO -  at 22.2s,\testimator extra_tree's best error=0.2617,\tbest estimator lgbm's best error=0.1920\n",
            "[flaml.automl.logger: 10-04 23:18:54] {2282} INFO - iteration 65, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:18:58] {2466} INFO -  at 25.9s,\testimator catboost's best error=0.1885,\tbest estimator catboost's best error=0.1885\n",
            "[flaml.automl.logger: 10-04 23:18:58] {2282} INFO - iteration 66, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:18:58] {2466} INFO -  at 26.2s,\testimator lgbm's best error=0.1920,\tbest estimator catboost's best error=0.1885\n",
            "[flaml.automl.logger: 10-04 23:18:58] {2282} INFO - iteration 67, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:18:58] {2466} INFO -  at 26.4s,\testimator extra_tree's best error=0.2332,\tbest estimator catboost's best error=0.1885\n",
            "[flaml.automl.logger: 10-04 23:18:58] {2282} INFO - iteration 68, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:18:58] {2466} INFO -  at 26.6s,\testimator extra_tree's best error=0.2332,\tbest estimator catboost's best error=0.1885\n",
            "[flaml.automl.logger: 10-04 23:18:58] {2282} INFO - iteration 69, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:18:59] {2466} INFO -  at 26.9s,\testimator extra_tree's best error=0.2059,\tbest estimator catboost's best error=0.1885\n",
            "[flaml.automl.logger: 10-04 23:18:59] {2282} INFO - iteration 70, current learner xgboost\n",
            "[flaml.automl.logger: 10-04 23:19:00] {2466} INFO -  at 27.9s,\testimator xgboost's best error=0.1946,\tbest estimator catboost's best error=0.1885\n",
            "[flaml.automl.logger: 10-04 23:19:00] {2282} INFO - iteration 71, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:19:00] {2466} INFO -  at 28.1s,\testimator extra_tree's best error=0.2059,\tbest estimator catboost's best error=0.1885\n",
            "[flaml.automl.logger: 10-04 23:19:00] {2282} INFO - iteration 72, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:19:00] {2466} INFO -  at 28.3s,\testimator extra_tree's best error=0.2059,\tbest estimator catboost's best error=0.1885\n",
            "[flaml.automl.logger: 10-04 23:19:00] {2282} INFO - iteration 73, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:19:00] {2466} INFO -  at 28.6s,\testimator extra_tree's best error=0.2059,\tbest estimator catboost's best error=0.1885\n",
            "[flaml.automl.logger: 10-04 23:19:00] {2282} INFO - iteration 74, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:19:08] {2466} INFO -  at 36.1s,\testimator catboost's best error=0.1885,\tbest estimator catboost's best error=0.1885\n",
            "[flaml.automl.logger: 10-04 23:19:08] {2282} INFO - iteration 75, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:19:08] {2466} INFO -  at 36.3s,\testimator extra_tree's best error=0.2059,\tbest estimator catboost's best error=0.1885\n",
            "[flaml.automl.logger: 10-04 23:19:08] {2282} INFO - iteration 76, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:19:11] {2466} INFO -  at 39.4s,\testimator catboost's best error=0.1885,\tbest estimator catboost's best error=0.1885\n",
            "[flaml.automl.logger: 10-04 23:19:11] {2282} INFO - iteration 77, current learner xgboost\n",
            "[flaml.automl.logger: 10-04 23:19:11] {2466} INFO -  at 39.7s,\testimator xgboost's best error=0.1946,\tbest estimator catboost's best error=0.1885\n",
            "[flaml.automl.logger: 10-04 23:19:11] {2282} INFO - iteration 78, current learner xgboost\n",
            "[flaml.automl.logger: 10-04 23:19:13] {2466} INFO -  at 41.6s,\testimator xgboost's best error=0.1923,\tbest estimator catboost's best error=0.1885\n",
            "[flaml.automl.logger: 10-04 23:19:13] {2282} INFO - iteration 79, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:19:14] {2466} INFO -  at 41.8s,\testimator extra_tree's best error=0.2059,\tbest estimator catboost's best error=0.1885\n",
            "[flaml.automl.logger: 10-04 23:19:14] {2282} INFO - iteration 80, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:19:14] {2466} INFO -  at 42.0s,\testimator extra_tree's best error=0.2001,\tbest estimator catboost's best error=0.1885\n",
            "[flaml.automl.logger: 10-04 23:19:14] {2282} INFO - iteration 81, current learner xgboost\n",
            "[flaml.automl.logger: 10-04 23:19:14] {2466} INFO -  at 42.7s,\testimator xgboost's best error=0.1923,\tbest estimator catboost's best error=0.1885\n",
            "[flaml.automl.logger: 10-04 23:19:14] {2282} INFO - iteration 82, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:19:26] {2466} INFO -  at 54.8s,\testimator catboost's best error=0.1885,\tbest estimator catboost's best error=0.1885\n",
            "[flaml.automl.logger: 10-04 23:19:26] {2282} INFO - iteration 83, current learner xgboost\n",
            "[flaml.automl.logger: 10-04 23:19:41] {2466} INFO -  at 69.2s,\testimator xgboost's best error=0.1900,\tbest estimator catboost's best error=0.1885\n",
            "[flaml.automl.logger: 10-04 23:19:41] {2282} INFO - iteration 84, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:19:41] {2466} INFO -  at 69.5s,\testimator extra_tree's best error=0.2001,\tbest estimator catboost's best error=0.1885\n",
            "[flaml.automl.logger: 10-04 23:19:41] {2282} INFO - iteration 85, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:19:42] {2466} INFO -  at 69.9s,\testimator extra_tree's best error=0.1993,\tbest estimator catboost's best error=0.1885\n",
            "[flaml.automl.logger: 10-04 23:19:42] {2282} INFO - iteration 86, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-04 23:19:42] {2466} INFO -  at 70.2s,\testimator xgb_limitdepth's best error=0.1974,\tbest estimator catboost's best error=0.1885\n",
            "[flaml.automl.logger: 10-04 23:19:42] {2282} INFO - iteration 87, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-04 23:19:42] {2466} INFO -  at 70.5s,\testimator xgb_limitdepth's best error=0.1962,\tbest estimator catboost's best error=0.1885\n",
            "[flaml.automl.logger: 10-04 23:19:42] {2282} INFO - iteration 88, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-04 23:19:42] {2466} INFO -  at 70.7s,\testimator xgb_limitdepth's best error=0.1962,\tbest estimator catboost's best error=0.1885\n",
            "[flaml.automl.logger: 10-04 23:19:42] {2282} INFO - iteration 89, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-04 23:19:43] {2466} INFO -  at 70.9s,\testimator xgb_limitdepth's best error=0.1962,\tbest estimator catboost's best error=0.1885\n",
            "[flaml.automl.logger: 10-04 23:19:43] {2282} INFO - iteration 90, current learner xgboost\n",
            "[flaml.automl.logger: 10-04 23:20:06] {2466} INFO -  at 94.5s,\testimator xgboost's best error=0.1890,\tbest estimator catboost's best error=0.1885\n",
            "[flaml.automl.logger: 10-04 23:20:06] {2282} INFO - iteration 91, current learner xgboost\n",
            "[flaml.automl.logger: 10-04 23:20:12] {2466} INFO -  at 99.9s,\testimator xgboost's best error=0.1890,\tbest estimator catboost's best error=0.1885\n",
            "[flaml.automl.logger: 10-04 23:20:12] {2282} INFO - iteration 92, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:20:16] {2466} INFO -  at 103.9s,\testimator catboost's best error=0.1876,\tbest estimator catboost's best error=0.1876\n",
            "[flaml.automl.logger: 10-04 23:20:16] {2282} INFO - iteration 93, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:20:16] {2466} INFO -  at 104.4s,\testimator extra_tree's best error=0.1993,\tbest estimator catboost's best error=0.1876\n",
            "[flaml.automl.logger: 10-04 23:20:16] {2282} INFO - iteration 94, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:20:23] {2466} INFO -  at 111.2s,\testimator catboost's best error=0.1876,\tbest estimator catboost's best error=0.1876\n",
            "[flaml.automl.logger: 10-04 23:20:23] {2282} INFO - iteration 95, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-04 23:20:24] {2466} INFO -  at 111.9s,\testimator xgb_limitdepth's best error=0.1962,\tbest estimator catboost's best error=0.1876\n",
            "[flaml.automl.logger: 10-04 23:20:24] {2282} INFO - iteration 96, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-04 23:20:24] {2466} INFO -  at 112.6s,\testimator xgb_limitdepth's best error=0.1962,\tbest estimator catboost's best error=0.1876\n",
            "[flaml.automl.logger: 10-04 23:20:24] {2282} INFO - iteration 97, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:20:25] {2466} INFO -  at 112.8s,\testimator lgbm's best error=0.1920,\tbest estimator catboost's best error=0.1876\n",
            "[flaml.automl.logger: 10-04 23:20:25] {2282} INFO - iteration 98, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:20:28] {2466} INFO -  at 116.3s,\testimator catboost's best error=0.1876,\tbest estimator catboost's best error=0.1876\n",
            "[flaml.automl.logger: 10-04 23:20:28] {2282} INFO - iteration 99, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:20:28] {2466} INFO -  at 116.6s,\testimator extra_tree's best error=0.1993,\tbest estimator catboost's best error=0.1876\n",
            "[flaml.automl.logger: 10-04 23:20:28] {2282} INFO - iteration 100, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-04 23:20:29] {2466} INFO -  at 117.3s,\testimator xgb_limitdepth's best error=0.1946,\tbest estimator catboost's best error=0.1876\n",
            "[flaml.automl.logger: 10-04 23:20:29] {2282} INFO - iteration 101, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:20:29] {2466} INFO -  at 117.7s,\testimator extra_tree's best error=0.1993,\tbest estimator catboost's best error=0.1876\n",
            "[flaml.automl.logger: 10-04 23:20:29] {2282} INFO - iteration 102, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:20:30] {2466} INFO -  at 118.1s,\testimator rf's best error=0.2197,\tbest estimator catboost's best error=0.1876\n",
            "[flaml.automl.logger: 10-04 23:20:30] {2282} INFO - iteration 103, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:20:36] {2466} INFO -  at 124.1s,\testimator catboost's best error=0.1876,\tbest estimator catboost's best error=0.1876\n",
            "[flaml.automl.logger: 10-04 23:20:36] {2282} INFO - iteration 104, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-04 23:20:37] {2466} INFO -  at 125.2s,\testimator xgb_limitdepth's best error=0.1946,\tbest estimator catboost's best error=0.1876\n",
            "[flaml.automl.logger: 10-04 23:20:37] {2282} INFO - iteration 105, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:20:37] {2466} INFO -  at 125.4s,\testimator lgbm's best error=0.1920,\tbest estimator catboost's best error=0.1876\n",
            "[flaml.automl.logger: 10-04 23:20:37] {2282} INFO - iteration 106, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-04 23:20:37] {2466} INFO -  at 125.8s,\testimator xgb_limitdepth's best error=0.1946,\tbest estimator catboost's best error=0.1876\n",
            "[flaml.automl.logger: 10-04 23:20:37] {2282} INFO - iteration 107, current learner xgboost\n",
            "[flaml.automl.logger: 10-04 23:21:07] {2466} INFO -  at 155.6s,\testimator xgboost's best error=0.1890,\tbest estimator catboost's best error=0.1876\n",
            "[flaml.automl.logger: 10-04 23:21:07] {2282} INFO - iteration 108, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-04 23:21:08] {2466} INFO -  at 155.9s,\testimator xgb_limitdepth's best error=0.1946,\tbest estimator catboost's best error=0.1876\n",
            "[flaml.automl.logger: 10-04 23:21:08] {2282} INFO - iteration 109, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:21:11] {2466} INFO -  at 159.6s,\testimator catboost's best error=0.1876,\tbest estimator catboost's best error=0.1876\n",
            "[flaml.automl.logger: 10-04 23:21:11] {2282} INFO - iteration 110, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:21:12] {2466} INFO -  at 159.9s,\testimator extra_tree's best error=0.1993,\tbest estimator catboost's best error=0.1876\n",
            "[flaml.automl.logger: 10-04 23:21:12] {2282} INFO - iteration 111, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:21:14] {2466} INFO -  at 162.1s,\testimator catboost's best error=0.1876,\tbest estimator catboost's best error=0.1876\n",
            "[flaml.automl.logger: 10-04 23:21:14] {2282} INFO - iteration 112, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:21:14] {2466} INFO -  at 162.1s,\testimator sgd's best error=0.4050,\tbest estimator catboost's best error=0.1876\n",
            "[flaml.automl.logger: 10-04 23:21:14] {2282} INFO - iteration 113, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:21:14] {2466} INFO -  at 162.5s,\testimator lgbm's best error=0.1920,\tbest estimator catboost's best error=0.1876\n",
            "[flaml.automl.logger: 10-04 23:21:14] {2282} INFO - iteration 114, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:21:17] {2466} INFO -  at 165.7s,\testimator catboost's best error=0.1876,\tbest estimator catboost's best error=0.1876\n",
            "[flaml.automl.logger: 10-04 23:21:17] {2282} INFO - iteration 115, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:21:18] {2466} INFO -  at 165.9s,\testimator sgd's best error=0.4050,\tbest estimator catboost's best error=0.1876\n",
            "[flaml.automl.logger: 10-04 23:21:18] {2282} INFO - iteration 116, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:21:24] {2466} INFO -  at 172.7s,\testimator catboost's best error=0.1867,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:21:24] {2282} INFO - iteration 117, current learner lrl1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:flaml.tune.searcher.blendsearch:No low-cost partial config given to the search algorithm. For cost-frugal search, consider providing low-cost values for cost-related hps via 'low_cost_partial_config'. More info can be found at https://microsoft.github.io/FLAML/docs/FAQ#about-low_cost_partial_config-in-tune\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[flaml.automl.logger: 10-04 23:21:25] {2466} INFO -  at 173.2s,\testimator lrl1's best error=0.4030,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:21:25] {2282} INFO - iteration 118, current learner lrl1\n",
            "[flaml.automl.logger: 10-04 23:21:25] {2466} INFO -  at 173.7s,\testimator lrl1's best error=0.4030,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:21:25] {2282} INFO - iteration 119, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:21:35] {2466} INFO -  at 183.6s,\testimator catboost's best error=0.1867,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:21:35] {2282} INFO - iteration 120, current learner lrl1\n",
            "[flaml.automl.logger: 10-04 23:21:36] {2466} INFO -  at 184.0s,\testimator lrl1's best error=0.4030,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:21:36] {2282} INFO - iteration 121, current learner lrl1\n",
            "[flaml.automl.logger: 10-04 23:21:36] {2466} INFO -  at 184.7s,\testimator lrl1's best error=0.4030,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:21:36] {2282} INFO - iteration 122, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:21:37] {2466} INFO -  at 184.9s,\testimator lgbm's best error=0.1920,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:21:37] {2282} INFO - iteration 123, current learner lrl1\n",
            "[flaml.automl.logger: 10-04 23:21:37] {2466} INFO -  at 185.4s,\testimator lrl1's best error=0.4030,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:21:37] {2282} INFO - iteration 124, current learner lrl1\n",
            "[flaml.automl.logger: 10-04 23:21:38] {2466} INFO -  at 185.9s,\testimator lrl1's best error=0.4030,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:21:38] {2282} INFO - iteration 125, current learner lrl1\n",
            "[flaml.automl.logger: 10-04 23:21:38] {2466} INFO -  at 186.3s,\testimator lrl1's best error=0.4030,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:21:38] {2282} INFO - iteration 126, current learner lrl1\n",
            "[flaml.automl.logger: 10-04 23:21:39] {2466} INFO -  at 186.9s,\testimator lrl1's best error=0.4030,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:21:39] {2282} INFO - iteration 127, current learner xgboost\n",
            "[flaml.automl.logger: 10-04 23:21:51] {2466} INFO -  at 199.6s,\testimator xgboost's best error=0.1890,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:21:51] {2282} INFO - iteration 128, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:21:52] {2466} INFO -  at 199.8s,\testimator lgbm's best error=0.1920,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:21:52] {2282} INFO - iteration 129, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:21:52] {2466} INFO -  at 200.1s,\testimator lgbm's best error=0.1920,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:21:52] {2282} INFO - iteration 130, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:21:52] {2466} INFO -  at 200.3s,\testimator lgbm's best error=0.1920,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:21:52] {2282} INFO - iteration 131, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:21:52] {2466} INFO -  at 200.5s,\testimator sgd's best error=0.4050,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:21:52] {2282} INFO - iteration 132, current learner lrl1\n",
            "[flaml.automl.logger: 10-04 23:21:53] {2466} INFO -  at 201.1s,\testimator lrl1's best error=0.4030,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:21:53] {2282} INFO - iteration 133, current learner lrl1\n",
            "[flaml.automl.logger: 10-04 23:21:53] {2466} INFO -  at 201.6s,\testimator lrl1's best error=0.4030,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:21:53] {2282} INFO - iteration 134, current learner lrl1\n",
            "[flaml.automl.logger: 10-04 23:21:54] {2466} INFO -  at 202.1s,\testimator lrl1's best error=0.4030,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:21:54] {2282} INFO - iteration 135, current learner lrl1\n",
            "[flaml.automl.logger: 10-04 23:21:54] {2466} INFO -  at 202.5s,\testimator lrl1's best error=0.4030,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:21:54] {2282} INFO - iteration 136, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:21:55] {2466} INFO -  at 202.8s,\testimator rf's best error=0.2197,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:21:55] {2282} INFO - iteration 137, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-04 23:21:56] {2466} INFO -  at 203.9s,\testimator xgb_limitdepth's best error=0.1928,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:21:56] {2282} INFO - iteration 138, current learner lrl1\n",
            "[flaml.automl.logger: 10-04 23:21:56] {2466} INFO -  at 204.4s,\testimator lrl1's best error=0.4030,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:21:56] {2282} INFO - iteration 139, current learner lrl1\n",
            "[flaml.automl.logger: 10-04 23:21:57] {2466} INFO -  at 204.8s,\testimator lrl1's best error=0.4027,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:21:57] {2282} INFO - iteration 140, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-04 23:21:57] {2466} INFO -  at 205.2s,\testimator xgb_limitdepth's best error=0.1928,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:21:57] {2282} INFO - iteration 141, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:22:01] {2466} INFO -  at 209.4s,\testimator lgbm's best error=0.1920,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:22:01] {2282} INFO - iteration 142, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:22:04] {2466} INFO -  at 212.2s,\testimator catboost's best error=0.1867,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:22:04] {2282} INFO - iteration 143, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:22:04] {2466} INFO -  at 212.6s,\testimator extra_tree's best error=0.1993,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:22:04] {2282} INFO - iteration 144, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:22:09] {2466} INFO -  at 217.8s,\testimator catboost's best error=0.1867,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:22:09] {2282} INFO - iteration 145, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-04 23:22:12] {2466} INFO -  at 219.9s,\testimator xgb_limitdepth's best error=0.1928,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:22:12] {2282} INFO - iteration 146, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:22:21] {2466} INFO -  at 229.0s,\testimator catboost's best error=0.1867,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:22:21] {2282} INFO - iteration 147, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:22:21] {2466} INFO -  at 229.1s,\testimator sgd's best error=0.4050,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:22:21] {2282} INFO - iteration 148, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-04 23:22:21] {2466} INFO -  at 229.4s,\testimator xgb_limitdepth's best error=0.1928,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:22:21] {2282} INFO - iteration 149, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:22:21] {2466} INFO -  at 229.7s,\testimator lgbm's best error=0.1920,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:22:21] {2282} INFO - iteration 150, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:22:22] {2466} INFO -  at 229.9s,\testimator lgbm's best error=0.1920,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:22:22] {2282} INFO - iteration 151, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:22:22] {2466} INFO -  at 230.3s,\testimator lgbm's best error=0.1920,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:22:22] {2282} INFO - iteration 152, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:22:22] {2466} INFO -  at 230.8s,\testimator lgbm's best error=0.1920,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:22:22] {2282} INFO - iteration 153, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:22:23] {2466} INFO -  at 231.0s,\testimator lgbm's best error=0.1920,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:22:23] {2282} INFO - iteration 154, current learner xgboost\n",
            "[flaml.automl.logger: 10-04 23:22:34] {2466} INFO -  at 241.8s,\testimator xgboost's best error=0.1890,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:22:34] {2282} INFO - iteration 155, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:22:34] {2466} INFO -  at 241.9s,\testimator sgd's best error=0.4050,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:22:34] {2282} INFO - iteration 156, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:22:34] {2466} INFO -  at 242.0s,\testimator sgd's best error=0.4050,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:22:34] {2282} INFO - iteration 157, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:22:34] {2466} INFO -  at 242.2s,\testimator lgbm's best error=0.1920,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:22:34] {2282} INFO - iteration 158, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:22:34] {2466} INFO -  at 242.5s,\testimator lgbm's best error=0.1920,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:22:34] {2282} INFO - iteration 159, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:22:39] {2466} INFO -  at 247.1s,\testimator catboost's best error=0.1867,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:22:39] {2282} INFO - iteration 160, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:22:39] {2466} INFO -  at 247.2s,\testimator sgd's best error=0.4050,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:22:39] {2282} INFO - iteration 161, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:22:39] {2466} INFO -  at 247.6s,\testimator rf's best error=0.2178,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:22:39] {2282} INFO - iteration 162, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:22:40] {2466} INFO -  at 248.0s,\testimator rf's best error=0.2178,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:22:40] {2282} INFO - iteration 163, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:22:40] {2466} INFO -  at 248.1s,\testimator sgd's best error=0.4050,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:22:40] {2282} INFO - iteration 164, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:22:40] {2466} INFO -  at 248.6s,\testimator rf's best error=0.2178,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:22:40] {2282} INFO - iteration 165, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-04 23:22:46] {2466} INFO -  at 254.1s,\testimator xgb_limitdepth's best error=0.1910,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:22:46] {2282} INFO - iteration 166, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:22:50] {2466} INFO -  at 258.1s,\testimator catboost's best error=0.1867,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:22:50] {2282} INFO - iteration 167, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:22:53] {2466} INFO -  at 261.0s,\testimator catboost's best error=0.1867,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:22:53] {2282} INFO - iteration 168, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:22:53] {2466} INFO -  at 261.2s,\testimator rf's best error=0.2173,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:22:53] {2282} INFO - iteration 169, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-04 23:22:55] {2466} INFO -  at 263.0s,\testimator xgb_limitdepth's best error=0.1910,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:22:55] {2282} INFO - iteration 170, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:22:55] {2466} INFO -  at 263.2s,\testimator sgd's best error=0.4050,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:22:55] {2282} INFO - iteration 171, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:23:02] {2466} INFO -  at 270.4s,\testimator catboost's best error=0.1867,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:23:02] {2282} INFO - iteration 172, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:23:02] {2466} INFO -  at 270.7s,\testimator lgbm's best error=0.1920,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:23:02] {2282} INFO - iteration 173, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:23:03] {2466} INFO -  at 270.9s,\testimator lgbm's best error=0.1920,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:23:03] {2282} INFO - iteration 174, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:23:04] {2466} INFO -  at 272.2s,\testimator lgbm's best error=0.1920,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:23:04] {2282} INFO - iteration 175, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-04 23:23:08] {2466} INFO -  at 276.2s,\testimator xgb_limitdepth's best error=0.1910,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:23:08] {2282} INFO - iteration 176, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:23:08] {2466} INFO -  at 276.3s,\testimator sgd's best error=0.4050,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:23:08] {2282} INFO - iteration 177, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-04 23:23:18] {2466} INFO -  at 286.8s,\testimator xgb_limitdepth's best error=0.1910,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:23:18] {2282} INFO - iteration 178, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:23:19] {2466} INFO -  at 287.0s,\testimator extra_tree's best error=0.1993,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:23:19] {2282} INFO - iteration 179, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:23:22] {2466} INFO -  at 290.7s,\testimator catboost's best error=0.1867,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:23:22] {2282} INFO - iteration 180, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:23:23] {2466} INFO -  at 290.8s,\testimator sgd's best error=0.4050,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:23:23] {2282} INFO - iteration 181, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:23:23] {2466} INFO -  at 291.5s,\testimator extra_tree's best error=0.1974,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:23:23] {2282} INFO - iteration 182, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:23:24] {2466} INFO -  at 292.6s,\testimator extra_tree's best error=0.1948,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:23:24] {2282} INFO - iteration 183, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:23:25] {2466} INFO -  at 293.1s,\testimator extra_tree's best error=0.1948,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:23:25] {2282} INFO - iteration 184, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:23:26] {2466} INFO -  at 294.5s,\testimator extra_tree's best error=0.1908,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:23:26] {2282} INFO - iteration 185, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:23:27] {2466} INFO -  at 295.3s,\testimator extra_tree's best error=0.1908,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:23:27] {2282} INFO - iteration 186, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:23:27] {2466} INFO -  at 295.5s,\testimator lgbm's best error=0.1920,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:23:27] {2282} INFO - iteration 187, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:23:28] {2466} INFO -  at 295.9s,\testimator extra_tree's best error=0.1908,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:23:28] {2282} INFO - iteration 188, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:23:29] {2466} INFO -  at 297.7s,\testimator extra_tree's best error=0.1908,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:23:29] {2282} INFO - iteration 189, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:23:30] {2466} INFO -  at 298.2s,\testimator extra_tree's best error=0.1908,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:23:30] {2282} INFO - iteration 190, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-04 23:23:31] {2466} INFO -  at 299.2s,\testimator xgb_limitdepth's best error=0.1910,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:23:31] {2282} INFO - iteration 191, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:23:31] {2466} INFO -  at 299.4s,\testimator lgbm's best error=0.1920,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:23:31] {2282} INFO - iteration 192, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:23:32] {2466} INFO -  at 300.2s,\testimator extra_tree's best error=0.1908,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:23:32] {2282} INFO - iteration 193, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:23:32] {2466} INFO -  at 300.4s,\testimator sgd's best error=0.4050,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:23:32] {2282} INFO - iteration 194, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:23:34] {2466} INFO -  at 301.9s,\testimator extra_tree's best error=0.1908,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:23:34] {2282} INFO - iteration 195, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:23:34] {2466} INFO -  at 302.3s,\testimator extra_tree's best error=0.1908,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:23:34] {2282} INFO - iteration 196, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:23:35] {2466} INFO -  at 303.0s,\testimator extra_tree's best error=0.1908,\tbest estimator catboost's best error=0.1867\n",
            "[flaml.automl.logger: 10-04 23:23:35] {2282} INFO - iteration 197, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:23:41] {2466} INFO -  at 309.2s,\testimator catboost's best error=0.1865,\tbest estimator catboost's best error=0.1865\n",
            "[flaml.automl.logger: 10-04 23:23:41] {2282} INFO - iteration 198, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:23:42] {2466} INFO -  at 310.0s,\testimator extra_tree's best error=0.1908,\tbest estimator catboost's best error=0.1865\n",
            "[flaml.automl.logger: 10-04 23:23:42] {2282} INFO - iteration 199, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:23:42] {2466} INFO -  at 310.3s,\testimator lgbm's best error=0.1920,\tbest estimator catboost's best error=0.1865\n",
            "[flaml.automl.logger: 10-04 23:23:42] {2282} INFO - iteration 200, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:23:42] {2466} INFO -  at 310.3s,\testimator sgd's best error=0.3615,\tbest estimator catboost's best error=0.1865\n",
            "[flaml.automl.logger: 10-04 23:23:42] {2282} INFO - iteration 201, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:23:42] {2466} INFO -  at 310.5s,\testimator sgd's best error=0.3615,\tbest estimator catboost's best error=0.1865\n",
            "[flaml.automl.logger: 10-04 23:23:42] {2282} INFO - iteration 202, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:23:46] {2466} INFO -  at 314.3s,\testimator catboost's best error=0.1865,\tbest estimator catboost's best error=0.1865\n",
            "[flaml.automl.logger: 10-04 23:23:46] {2282} INFO - iteration 203, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:23:51] {2466} INFO -  at 318.8s,\testimator catboost's best error=0.1865,\tbest estimator catboost's best error=0.1865\n",
            "[flaml.automl.logger: 10-04 23:23:51] {2282} INFO - iteration 204, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:23:51] {2466} INFO -  at 319.3s,\testimator lgbm's best error=0.1863,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:23:51] {2282} INFO - iteration 205, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:23:51] {2466} INFO -  at 319.5s,\testimator lgbm's best error=0.1863,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:23:51] {2282} INFO - iteration 206, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-04 23:23:58] {2466} INFO -  at 326.3s,\testimator xgb_limitdepth's best error=0.1898,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:23:58] {2282} INFO - iteration 207, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:23:58] {2466} INFO -  at 326.4s,\testimator sgd's best error=0.3615,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:23:58] {2282} INFO - iteration 208, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:24:02] {2466} INFO -  at 329.9s,\testimator catboost's best error=0.1865,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:24:02] {2282} INFO - iteration 209, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:24:03] {2466} INFO -  at 331.0s,\testimator extra_tree's best error=0.1908,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:24:03] {2282} INFO - iteration 210, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:24:03] {2466} INFO -  at 331.1s,\testimator sgd's best error=0.3615,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:24:03] {2282} INFO - iteration 211, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:24:03] {2466} INFO -  at 331.2s,\testimator sgd's best error=0.3615,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:24:03] {2282} INFO - iteration 212, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:24:03] {2466} INFO -  at 331.7s,\testimator extra_tree's best error=0.1908,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:24:03] {2282} INFO - iteration 213, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:24:05] {2466} INFO -  at 333.0s,\testimator extra_tree's best error=0.1908,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:24:05] {2282} INFO - iteration 214, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-04 23:24:09] {2466} INFO -  at 337.0s,\testimator xgb_limitdepth's best error=0.1898,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:24:09] {2282} INFO - iteration 215, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:24:10] {2466} INFO -  at 337.8s,\testimator extra_tree's best error=0.1908,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:24:10] {2282} INFO - iteration 216, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:24:10] {2466} INFO -  at 338.1s,\testimator sgd's best error=0.3615,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:24:10] {2282} INFO - iteration 217, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:24:10] {2466} INFO -  at 338.2s,\testimator sgd's best error=0.3615,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:24:10] {2282} INFO - iteration 218, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:24:10] {2466} INFO -  at 338.7s,\testimator rf's best error=0.2047,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:24:10] {2282} INFO - iteration 219, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:24:10] {2466} INFO -  at 338.8s,\testimator sgd's best error=0.3615,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:24:10] {2282} INFO - iteration 220, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:24:11] {2466} INFO -  at 339.0s,\testimator rf's best error=0.2047,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:24:11] {2282} INFO - iteration 221, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:24:11] {2466} INFO -  at 339.4s,\testimator rf's best error=0.2047,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:24:11] {2282} INFO - iteration 222, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:24:11] {2466} INFO -  at 339.7s,\testimator rf's best error=0.2047,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:24:11] {2282} INFO - iteration 223, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:24:12] {2466} INFO -  at 340.2s,\testimator rf's best error=0.2047,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:24:12] {2282} INFO - iteration 224, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:24:13] {2466} INFO -  at 341.3s,\testimator lgbm's best error=0.1863,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:24:13] {2282} INFO - iteration 225, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:24:13] {2466} INFO -  at 341.5s,\testimator sgd's best error=0.3615,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:24:13] {2282} INFO - iteration 226, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-04 23:24:18] {2466} INFO -  at 345.8s,\testimator xgb_limitdepth's best error=0.1898,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:24:18] {2282} INFO - iteration 227, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:24:18] {2466} INFO -  at 346.3s,\testimator lgbm's best error=0.1863,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:24:18] {2282} INFO - iteration 228, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:24:20] {2466} INFO -  at 348.6s,\testimator lgbm's best error=0.1863,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:24:20] {2282} INFO - iteration 229, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:24:21] {2466} INFO -  at 349.0s,\testimator rf's best error=0.2047,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:24:21] {2282} INFO - iteration 230, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:24:22] {2466} INFO -  at 350.2s,\testimator lgbm's best error=0.1863,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:24:22] {2282} INFO - iteration 231, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-04 23:24:29] {2466} INFO -  at 357.2s,\testimator xgb_limitdepth's best error=0.1898,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:24:29] {2282} INFO - iteration 232, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:24:29] {2466} INFO -  at 357.5s,\testimator rf's best error=0.2047,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:24:29] {2282} INFO - iteration 233, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:24:29] {2466} INFO -  at 357.6s,\testimator sgd's best error=0.3615,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:24:29] {2282} INFO - iteration 234, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:24:30] {2466} INFO -  at 357.9s,\testimator rf's best error=0.2047,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:24:30] {2282} INFO - iteration 235, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:24:30] {2466} INFO -  at 358.0s,\testimator sgd's best error=0.3566,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:24:30] {2282} INFO - iteration 236, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:24:30] {2466} INFO -  at 358.4s,\testimator extra_tree's best error=0.1908,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:24:30] {2282} INFO - iteration 237, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-04 23:24:34] {2466} INFO -  at 362.2s,\testimator xgb_limitdepth's best error=0.1898,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:24:34] {2282} INFO - iteration 238, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:24:34] {2466} INFO -  at 362.5s,\testimator rf's best error=0.2047,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:24:34] {2282} INFO - iteration 239, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:24:35] {2466} INFO -  at 363.0s,\testimator rf's best error=0.2002,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:24:35] {2282} INFO - iteration 240, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:24:38] {2466} INFO -  at 365.9s,\testimator extra_tree's best error=0.1900,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:24:38] {2282} INFO - iteration 241, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:24:40] {2466} INFO -  at 367.8s,\testimator lgbm's best error=0.1863,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:24:40] {2282} INFO - iteration 242, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:24:40] {2466} INFO -  at 368.5s,\testimator rf's best error=0.2002,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:24:40] {2282} INFO - iteration 243, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:24:41] {2466} INFO -  at 368.8s,\testimator rf's best error=0.2002,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:24:41] {2282} INFO - iteration 244, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:24:41] {2466} INFO -  at 369.3s,\testimator lgbm's best error=0.1863,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:24:41] {2282} INFO - iteration 245, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:24:41] {2466} INFO -  at 369.8s,\testimator rf's best error=0.2002,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:24:41] {2282} INFO - iteration 246, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:24:42] {2466} INFO -  at 370.0s,\testimator lgbm's best error=0.1863,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:24:42] {2282} INFO - iteration 247, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:24:43] {2466} INFO -  at 370.8s,\testimator extra_tree's best error=0.1900,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:24:43] {2282} INFO - iteration 248, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:24:44] {2466} INFO -  at 372.0s,\testimator lgbm's best error=0.1863,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:24:44] {2282} INFO - iteration 249, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:24:44] {2466} INFO -  at 372.2s,\testimator sgd's best error=0.3566,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:24:44] {2282} INFO - iteration 250, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:24:45] {2466} INFO -  at 372.9s,\testimator rf's best error=0.1967,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:24:45] {2282} INFO - iteration 251, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:24:45] {2466} INFO -  at 373.2s,\testimator lgbm's best error=0.1863,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:24:45] {2282} INFO - iteration 252, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:24:46] {2466} INFO -  at 373.8s,\testimator rf's best error=0.1967,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:24:46] {2282} INFO - iteration 253, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:24:47] {2466} INFO -  at 375.0s,\testimator rf's best error=0.1967,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:24:47] {2282} INFO - iteration 254, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:24:48] {2466} INFO -  at 375.9s,\testimator lgbm's best error=0.1863,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:24:48] {2282} INFO - iteration 255, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:24:49] {2466} INFO -  at 377.3s,\testimator lgbm's best error=0.1863,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:24:49] {2282} INFO - iteration 256, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:24:49] {2466} INFO -  at 377.7s,\testimator rf's best error=0.1967,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:24:49] {2282} INFO - iteration 257, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:24:50] {2466} INFO -  at 377.9s,\testimator sgd's best error=0.3566,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:24:50] {2282} INFO - iteration 258, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:24:52] {2466} INFO -  at 379.8s,\testimator lgbm's best error=0.1863,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:24:52] {2282} INFO - iteration 259, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:24:57] {2466} INFO -  at 385.5s,\testimator catboost's best error=0.1865,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:24:57] {2282} INFO - iteration 260, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:24:58] {2466} INFO -  at 386.6s,\testimator lgbm's best error=0.1863,\tbest estimator lgbm's best error=0.1863\n",
            "[flaml.automl.logger: 10-04 23:24:58] {2282} INFO - iteration 261, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:25:03] {2466} INFO -  at 391.4s,\testimator catboost's best error=0.1846,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:25:03] {2282} INFO - iteration 262, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:25:08] {2466} INFO -  at 396.7s,\testimator extra_tree's best error=0.1900,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:25:08] {2282} INFO - iteration 263, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:25:12] {2466} INFO -  at 400.7s,\testimator catboost's best error=0.1846,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:25:12] {2282} INFO - iteration 264, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:25:14] {2466} INFO -  at 401.9s,\testimator rf's best error=0.1967,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:25:14] {2282} INFO - iteration 265, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:25:14] {2466} INFO -  at 402.1s,\testimator sgd's best error=0.3566,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:25:14] {2282} INFO - iteration 266, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:25:14] {2466} INFO -  at 402.5s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:25:14] {2282} INFO - iteration 267, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:25:16] {2466} INFO -  at 404.7s,\testimator extra_tree's best error=0.1900,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:25:16] {2282} INFO - iteration 268, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:25:24] {2466} INFO -  at 412.4s,\testimator catboost's best error=0.1846,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:25:24] {2282} INFO - iteration 269, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:25:28] {2466} INFO -  at 416.2s,\testimator catboost's best error=0.1846,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:25:28] {2282} INFO - iteration 270, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:25:32] {2466} INFO -  at 420.4s,\testimator catboost's best error=0.1846,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:25:32] {2282} INFO - iteration 271, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:25:40] {2466} INFO -  at 428.5s,\testimator catboost's best error=0.1846,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:25:40] {2282} INFO - iteration 272, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:25:45] {2466} INFO -  at 433.5s,\testimator catboost's best error=0.1846,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:25:45] {2282} INFO - iteration 273, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:25:46] {2466} INFO -  at 433.9s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:25:46] {2282} INFO - iteration 274, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-04 23:25:48] {2466} INFO -  at 436.5s,\testimator xgb_limitdepth's best error=0.1898,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:25:48] {2282} INFO - iteration 275, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:25:51] {2466} INFO -  at 439.7s,\testimator rf's best error=0.1967,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:25:51] {2282} INFO - iteration 276, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:25:53] {2466} INFO -  at 440.9s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:25:53] {2282} INFO - iteration 277, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:25:53] {2466} INFO -  at 441.1s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:25:53] {2282} INFO - iteration 278, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:25:54] {2466} INFO -  at 441.9s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:25:54] {2282} INFO - iteration 279, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:25:55] {2466} INFO -  at 442.9s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:25:55] {2282} INFO - iteration 280, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-04 23:25:55] {2466} INFO -  at 443.7s,\testimator xgb_limitdepth's best error=0.1898,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:25:55] {2282} INFO - iteration 281, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:25:56] {2466} INFO -  at 444.0s,\testimator rf's best error=0.1967,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:25:56] {2282} INFO - iteration 282, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:26:00] {2466} INFO -  at 447.9s,\testimator catboost's best error=0.1846,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:26:00] {2282} INFO - iteration 283, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:26:00] {2466} INFO -  at 448.0s,\testimator sgd's best error=0.3566,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:26:00] {2282} INFO - iteration 284, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:26:00] {2466} INFO -  at 448.3s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:26:00] {2282} INFO - iteration 285, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:26:02] {2466} INFO -  at 449.9s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:26:02] {2282} INFO - iteration 286, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:26:02] {2466} INFO -  at 450.2s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:26:02] {2282} INFO - iteration 287, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:26:08] {2466} INFO -  at 456.7s,\testimator catboost's best error=0.1846,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:26:08] {2282} INFO - iteration 288, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:26:13] {2466} INFO -  at 461.7s,\testimator catboost's best error=0.1846,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:26:13] {2282} INFO - iteration 289, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:26:21] {2466} INFO -  at 469.7s,\testimator catboost's best error=0.1846,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:26:21] {2282} INFO - iteration 290, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:26:23] {2466} INFO -  at 471.0s,\testimator extra_tree's best error=0.1900,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:26:23] {2282} INFO - iteration 291, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:26:23] {2466} INFO -  at 471.6s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:26:23] {2282} INFO - iteration 292, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:26:24] {2466} INFO -  at 471.9s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:26:24] {2282} INFO - iteration 293, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:26:29] {2466} INFO -  at 477.5s,\testimator catboost's best error=0.1846,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:26:29] {2282} INFO - iteration 294, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:26:30] {2466} INFO -  at 478.8s,\testimator rf's best error=0.1947,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:26:30] {2282} INFO - iteration 295, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:26:31] {2466} INFO -  at 478.9s,\testimator sgd's best error=0.3566,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:26:31] {2282} INFO - iteration 296, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:26:31] {2466} INFO -  at 479.6s,\testimator rf's best error=0.1947,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:26:31] {2282} INFO - iteration 297, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:26:32] {2466} INFO -  at 480.1s,\testimator sgd's best error=0.3566,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:26:32] {2282} INFO - iteration 298, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:26:32] {2466} INFO -  at 480.7s,\testimator rf's best error=0.1947,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:26:32] {2282} INFO - iteration 299, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:26:33] {2466} INFO -  at 481.0s,\testimator sgd's best error=0.3566,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:26:33] {2282} INFO - iteration 300, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:26:37] {2466} INFO -  at 485.5s,\testimator rf's best error=0.1927,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:26:37] {2282} INFO - iteration 301, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:26:39] {2466} INFO -  at 487.3s,\testimator rf's best error=0.1927,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:26:39] {2282} INFO - iteration 302, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:26:39] {2466} INFO -  at 487.7s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:26:39] {2282} INFO - iteration 303, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:26:40] {2466} INFO -  at 488.3s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:26:40] {2282} INFO - iteration 304, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:26:40] {2466} INFO -  at 488.6s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:26:40] {2282} INFO - iteration 305, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:26:42] {2466} INFO -  at 490.1s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:26:42] {2282} INFO - iteration 306, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:26:46] {2466} INFO -  at 493.8s,\testimator catboost's best error=0.1846,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:26:46] {2282} INFO - iteration 307, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:26:50] {2466} INFO -  at 498.0s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:26:50] {2282} INFO - iteration 308, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:26:54] {2466} INFO -  at 502.5s,\testimator catboost's best error=0.1846,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:26:54] {2282} INFO - iteration 309, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:26:58] {2466} INFO -  at 506.1s,\testimator catboost's best error=0.1846,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:26:58] {2282} INFO - iteration 310, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:27:00] {2466} INFO -  at 508.3s,\testimator extra_tree's best error=0.1900,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:27:00] {2282} INFO - iteration 311, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:27:07] {2466} INFO -  at 515.0s,\testimator rf's best error=0.1908,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:27:07] {2282} INFO - iteration 312, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:27:07] {2466} INFO -  at 515.4s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:27:07] {2282} INFO - iteration 313, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:27:23] {2466} INFO -  at 530.8s,\testimator rf's best error=0.1871,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:27:23] {2282} INFO - iteration 314, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:27:28] {2466} INFO -  at 536.7s,\testimator rf's best error=0.1871,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:27:28] {2282} INFO - iteration 315, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:27:29] {2466} INFO -  at 537.3s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:27:29] {2282} INFO - iteration 316, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:27:44] {2466} INFO -  at 552.5s,\testimator rf's best error=0.1871,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:27:44] {2282} INFO - iteration 317, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:27:50] {2466} INFO -  at 557.9s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:27:50] {2282} INFO - iteration 318, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:28:03] {2466} INFO -  at 571.5s,\testimator catboost's best error=0.1846,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:28:03] {2282} INFO - iteration 319, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:28:08] {2466} INFO -  at 576.0s,\testimator catboost's best error=0.1846,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:28:08] {2282} INFO - iteration 320, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:28:08] {2466} INFO -  at 576.4s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:28:08] {2282} INFO - iteration 321, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:28:09] {2466} INFO -  at 577.1s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:28:09] {2282} INFO - iteration 322, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:28:09] {2466} INFO -  at 577.6s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:28:09] {2282} INFO - iteration 323, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:28:26] {2466} INFO -  at 594.0s,\testimator rf's best error=0.1871,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:28:26] {2282} INFO - iteration 324, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-04 23:28:42] {2466} INFO -  at 610.3s,\testimator xgb_limitdepth's best error=0.1898,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:28:42] {2282} INFO - iteration 325, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:28:42] {2466} INFO -  at 610.7s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:28:42] {2282} INFO - iteration 326, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:28:43] {2466} INFO -  at 611.3s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:28:43] {2282} INFO - iteration 327, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:28:50] {2466} INFO -  at 618.0s,\testimator catboost's best error=0.1846,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:28:50] {2282} INFO - iteration 328, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:28:50] {2466} INFO -  at 618.7s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:28:50] {2282} INFO - iteration 329, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:29:09] {2466} INFO -  at 637.7s,\testimator rf's best error=0.1871,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:29:09] {2282} INFO - iteration 330, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:29:10] {2466} INFO -  at 638.7s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:29:10] {2282} INFO - iteration 331, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:29:11] {2466} INFO -  at 639.0s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:29:11] {2282} INFO - iteration 332, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:29:20] {2466} INFO -  at 648.6s,\testimator rf's best error=0.1871,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:29:20] {2282} INFO - iteration 333, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:29:41] {2466} INFO -  at 668.8s,\testimator rf's best error=0.1871,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:29:41] {2282} INFO - iteration 334, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:29:41] {2466} INFO -  at 669.3s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:29:41] {2282} INFO - iteration 335, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:29:43] {2466} INFO -  at 671.4s,\testimator extra_tree's best error=0.1900,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:29:43] {2282} INFO - iteration 336, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:29:53] {2466} INFO -  at 681.4s,\testimator rf's best error=0.1871,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:29:53] {2282} INFO - iteration 337, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:29:54] {2466} INFO -  at 682.3s,\testimator extra_tree's best error=0.1900,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:29:54] {2282} INFO - iteration 338, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:29:55] {2466} INFO -  at 682.8s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:29:55] {2282} INFO - iteration 339, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:29:55] {2466} INFO -  at 682.9s,\testimator sgd's best error=0.3566,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:29:55] {2282} INFO - iteration 340, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:29:55] {2466} INFO -  at 683.3s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:29:55] {2282} INFO - iteration 341, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:30:03] {2466} INFO -  at 691.1s,\testimator rf's best error=0.1871,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:30:03] {2282} INFO - iteration 342, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:30:03] {2466} INFO -  at 691.4s,\testimator sgd's best error=0.3566,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:30:03] {2282} INFO - iteration 343, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:30:04] {2466} INFO -  at 692.2s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:30:04] {2282} INFO - iteration 344, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:30:05] {2466} INFO -  at 693.3s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:30:05] {2282} INFO - iteration 345, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:30:13] {2466} INFO -  at 701.8s,\testimator catboost's best error=0.1846,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:30:13] {2282} INFO - iteration 346, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:30:20] {2466} INFO -  at 708.7s,\testimator catboost's best error=0.1846,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:30:20] {2282} INFO - iteration 347, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:30:51] {2466} INFO -  at 739.2s,\testimator rf's best error=0.1871,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:30:51] {2282} INFO - iteration 348, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:30:56] {2466} INFO -  at 744.0s,\testimator catboost's best error=0.1846,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:30:56] {2282} INFO - iteration 349, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:31:03] {2466} INFO -  at 751.2s,\testimator catboost's best error=0.1846,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:31:03] {2282} INFO - iteration 350, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:31:03] {2466} INFO -  at 751.4s,\testimator sgd's best error=0.3566,\tbest estimator catboost's best error=0.1846\n",
            "[flaml.automl.logger: 10-04 23:31:03] {2282} INFO - iteration 351, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:31:08] {2466} INFO -  at 756.7s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:31:08] {2282} INFO - iteration 352, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:31:09] {2466} INFO -  at 756.9s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:31:09] {2282} INFO - iteration 353, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:31:12] {2466} INFO -  at 760.2s,\testimator extra_tree's best error=0.1900,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:31:12] {2282} INFO - iteration 354, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:31:12] {2466} INFO -  at 760.3s,\testimator sgd's best error=0.3566,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:31:12] {2282} INFO - iteration 355, current learner xgboost\n",
            "[flaml.automl.logger: 10-04 23:31:47] {2466} INFO -  at 795.7s,\testimator xgboost's best error=0.1890,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:31:47] {2282} INFO - iteration 356, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:31:48] {2466} INFO -  at 795.9s,\testimator sgd's best error=0.3566,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:31:48] {2282} INFO - iteration 357, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:31:48] {2466} INFO -  at 796.5s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:31:48] {2282} INFO - iteration 358, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:31:48] {2466} INFO -  at 796.7s,\testimator sgd's best error=0.3566,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:31:48] {2282} INFO - iteration 359, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:31:49] {2466} INFO -  at 796.8s,\testimator sgd's best error=0.3566,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:31:49] {2282} INFO - iteration 360, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:31:49] {2466} INFO -  at 797.2s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:31:49] {2282} INFO - iteration 361, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:31:49] {2466} INFO -  at 797.5s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:31:49] {2282} INFO - iteration 362, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:31:50] {2466} INFO -  at 798.1s,\testimator extra_tree's best error=0.1900,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:31:50] {2282} INFO - iteration 363, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:31:51] {2466} INFO -  at 799.1s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:31:51] {2282} INFO - iteration 364, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:31:51] {2466} INFO -  at 799.3s,\testimator sgd's best error=0.3566,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:31:51] {2282} INFO - iteration 365, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:31:51] {2466} INFO -  at 799.6s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:31:51] {2282} INFO - iteration 366, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:31:51] {2466} INFO -  at 799.7s,\testimator sgd's best error=0.3566,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:31:51] {2282} INFO - iteration 367, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:31:59] {2466} INFO -  at 807.5s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:31:59] {2282} INFO - iteration 368, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:32:00] {2466} INFO -  at 808.0s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:32:00] {2282} INFO - iteration 369, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:32:02] {2466} INFO -  at 809.8s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:32:02] {2282} INFO - iteration 370, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:32:05] {2466} INFO -  at 813.6s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:32:05] {2282} INFO - iteration 371, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:32:16] {2466} INFO -  at 824.4s,\testimator rf's best error=0.1871,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:32:16] {2282} INFO - iteration 372, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:32:18] {2466} INFO -  at 826.5s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:32:18] {2282} INFO - iteration 373, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:32:23] {2466} INFO -  at 831.2s,\testimator extra_tree's best error=0.1900,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:32:23] {2282} INFO - iteration 374, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:32:28] {2466} INFO -  at 836.5s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:32:28] {2282} INFO - iteration 375, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:32:55] {2466} INFO -  at 863.1s,\testimator rf's best error=0.1871,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:32:55] {2282} INFO - iteration 376, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:33:14] {2466} INFO -  at 882.7s,\testimator rf's best error=0.1871,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:33:14] {2282} INFO - iteration 377, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:33:15] {2466} INFO -  at 882.9s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:33:15] {2282} INFO - iteration 378, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:33:15] {2466} INFO -  at 883.2s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:33:15] {2282} INFO - iteration 379, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:33:16] {2466} INFO -  at 884.1s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:33:16] {2282} INFO - iteration 380, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:33:17] {2466} INFO -  at 885.0s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:33:17] {2282} INFO - iteration 381, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:33:17] {2466} INFO -  at 885.1s,\testimator sgd's best error=0.3566,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:33:17] {2282} INFO - iteration 382, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:33:17] {2466} INFO -  at 885.5s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:33:17] {2282} INFO - iteration 383, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:33:18] {2466} INFO -  at 885.9s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:33:18] {2282} INFO - iteration 384, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:33:20] {2466} INFO -  at 888.5s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:33:20] {2282} INFO - iteration 385, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:33:20] {2466} INFO -  at 888.7s,\testimator sgd's best error=0.3566,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:33:20] {2282} INFO - iteration 386, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:33:20] {2466} INFO -  at 888.8s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:33:20] {2282} INFO - iteration 387, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:33:21] {2466} INFO -  at 889.4s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:33:21] {2282} INFO - iteration 388, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:33:22] {2466} INFO -  at 890.2s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:33:22] {2282} INFO - iteration 389, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:33:23] {2466} INFO -  at 891.2s,\testimator extra_tree's best error=0.1900,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:33:23] {2282} INFO - iteration 390, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:33:26] {2466} INFO -  at 894.3s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:33:26] {2282} INFO - iteration 391, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:33:29] {2466} INFO -  at 896.9s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:33:29] {2282} INFO - iteration 392, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:33:29] {2466} INFO -  at 897.1s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:33:29] {2282} INFO - iteration 393, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:33:30] {2466} INFO -  at 898.0s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:33:30] {2282} INFO - iteration 394, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:33:30] {2466} INFO -  at 898.2s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:33:30] {2282} INFO - iteration 395, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:33:32] {2466} INFO -  at 900.0s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:33:32] {2282} INFO - iteration 396, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:33:32] {2466} INFO -  at 900.3s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:33:32] {2282} INFO - iteration 397, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:33:42] {2466} INFO -  at 910.1s,\testimator rf's best error=0.1871,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:33:42] {2282} INFO - iteration 398, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:33:44] {2466} INFO -  at 912.0s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:33:44] {2282} INFO - iteration 399, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:33:48] {2466} INFO -  at 915.9s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:33:48] {2282} INFO - iteration 400, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:33:48] {2466} INFO -  at 916.1s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:33:48] {2282} INFO - iteration 401, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:33:49] {2466} INFO -  at 917.1s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:33:49] {2282} INFO - iteration 402, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-04 23:33:51] {2466} INFO -  at 919.1s,\testimator xgb_limitdepth's best error=0.1898,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:33:51] {2282} INFO - iteration 403, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:33:53] {2466} INFO -  at 921.1s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:33:53] {2282} INFO - iteration 404, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:33:55] {2466} INFO -  at 923.2s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:33:55] {2282} INFO - iteration 405, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:33:55] {2466} INFO -  at 923.4s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:33:55] {2282} INFO - iteration 406, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:34:12] {2466} INFO -  at 940.6s,\testimator rf's best error=0.1871,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:34:12] {2282} INFO - iteration 407, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:34:15] {2466} INFO -  at 943.4s,\testimator extra_tree's best error=0.1900,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:34:15] {2282} INFO - iteration 408, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:34:18] {2466} INFO -  at 946.1s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:34:18] {2282} INFO - iteration 409, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:34:20] {2466} INFO -  at 947.9s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:34:20] {2282} INFO - iteration 410, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:34:20] {2466} INFO -  at 948.8s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:34:20] {2282} INFO - iteration 411, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:34:21] {2466} INFO -  at 948.9s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:34:21] {2282} INFO - iteration 412, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:34:35] {2466} INFO -  at 963.5s,\testimator rf's best error=0.1871,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:34:35] {2282} INFO - iteration 413, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:34:37] {2466} INFO -  at 965.5s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:34:37] {2282} INFO - iteration 414, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:34:37] {2466} INFO -  at 965.7s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:34:37] {2282} INFO - iteration 415, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:34:38] {2466} INFO -  at 966.4s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:34:38] {2282} INFO - iteration 416, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:34:39] {2466} INFO -  at 966.9s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:34:39] {2282} INFO - iteration 417, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:34:41] {2466} INFO -  at 969.5s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:34:41] {2282} INFO - iteration 418, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:34:43] {2466} INFO -  at 971.2s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:34:43] {2282} INFO - iteration 419, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:34:43] {2466} INFO -  at 971.4s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:34:43] {2282} INFO - iteration 420, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:34:45] {2466} INFO -  at 973.7s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:34:45] {2282} INFO - iteration 421, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:34:46] {2466} INFO -  at 973.8s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:34:46] {2282} INFO - iteration 422, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:34:47] {2466} INFO -  at 975.6s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:34:47] {2282} INFO - iteration 423, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:34:48] {2466} INFO -  at 976.2s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:34:48] {2282} INFO - iteration 424, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:34:51] {2466} INFO -  at 978.8s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:34:51] {2282} INFO - iteration 425, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:34:51] {2466} INFO -  at 979.7s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:34:51] {2282} INFO - iteration 426, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:34:54] {2466} INFO -  at 982.0s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:34:54] {2282} INFO - iteration 427, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:34:54] {2466} INFO -  at 982.2s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:34:54] {2282} INFO - iteration 428, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:34:57] {2466} INFO -  at 984.8s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:34:57] {2282} INFO - iteration 429, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:34:58] {2466} INFO -  at 985.9s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:34:58] {2282} INFO - iteration 430, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:34:58] {2466} INFO -  at 986.3s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:34:58] {2282} INFO - iteration 431, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:34:59] {2466} INFO -  at 987.4s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:34:59] {2282} INFO - iteration 432, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:35:06] {2466} INFO -  at 994.3s,\testimator rf's best error=0.1871,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:35:06] {2282} INFO - iteration 433, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:35:08] {2466} INFO -  at 996.0s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:35:08] {2282} INFO - iteration 434, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:35:08] {2466} INFO -  at 996.5s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:35:08] {2282} INFO - iteration 435, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:35:13] {2466} INFO -  at 1001.1s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:35:13] {2282} INFO - iteration 436, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:35:13] {2466} INFO -  at 1001.5s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:35:13] {2282} INFO - iteration 437, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:35:15] {2466} INFO -  at 1003.7s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:35:15] {2282} INFO - iteration 438, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:35:36] {2466} INFO -  at 1024.6s,\testimator rf's best error=0.1871,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:35:36] {2282} INFO - iteration 439, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:35:42] {2466} INFO -  at 1030.6s,\testimator rf's best error=0.1871,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:35:42] {2282} INFO - iteration 440, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:36:28] {2466} INFO -  at 1076.1s,\testimator rf's best error=0.1871,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:36:28] {2282} INFO - iteration 441, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:36:38] {2466} INFO -  at 1086.1s,\testimator rf's best error=0.1871,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:36:38] {2282} INFO - iteration 442, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:36:41] {2466} INFO -  at 1089.0s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:36:41] {2282} INFO - iteration 443, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:36:41] {2466} INFO -  at 1089.4s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:36:41] {2282} INFO - iteration 444, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:36:43] {2466} INFO -  at 1091.3s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:36:43] {2282} INFO - iteration 445, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:36:45] {2466} INFO -  at 1093.0s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:36:45] {2282} INFO - iteration 446, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:36:47] {2466} INFO -  at 1095.5s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:36:47] {2282} INFO - iteration 447, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:36:47] {2466} INFO -  at 1095.6s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:36:47] {2282} INFO - iteration 448, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:36:47] {2466} INFO -  at 1095.8s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:36:47] {2282} INFO - iteration 449, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:36:49] {2466} INFO -  at 1096.9s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:36:49] {2282} INFO - iteration 450, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:36:53] {2466} INFO -  at 1101.0s,\testimator extra_tree's best error=0.1900,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:36:53] {2282} INFO - iteration 451, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:36:53] {2466} INFO -  at 1101.5s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:36:53] {2282} INFO - iteration 452, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:36:57] {2466} INFO -  at 1104.9s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:36:57] {2282} INFO - iteration 453, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:36:59] {2466} INFO -  at 1107.4s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:36:59] {2282} INFO - iteration 454, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:37:01] {2466} INFO -  at 1109.4s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:37:01] {2282} INFO - iteration 455, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:37:04] {2466} INFO -  at 1111.8s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:37:04] {2282} INFO - iteration 456, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:37:04] {2466} INFO -  at 1112.2s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:37:04] {2282} INFO - iteration 457, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:37:05] {2466} INFO -  at 1113.0s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:37:05] {2282} INFO - iteration 458, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:37:07] {2466} INFO -  at 1115.4s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:37:07] {2282} INFO - iteration 459, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:37:07] {2466} INFO -  at 1115.6s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:37:07] {2282} INFO - iteration 460, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:37:10] {2466} INFO -  at 1118.6s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:37:10] {2282} INFO - iteration 461, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:37:13] {2466} INFO -  at 1120.9s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:37:13] {2282} INFO - iteration 462, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:37:13] {2466} INFO -  at 1121.1s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:37:13] {2282} INFO - iteration 463, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:37:15] {2466} INFO -  at 1123.6s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:37:15] {2282} INFO - iteration 464, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:37:17] {2466} INFO -  at 1125.7s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:37:17] {2282} INFO - iteration 465, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:37:18] {2466} INFO -  at 1126.7s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:37:18] {2282} INFO - iteration 466, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:37:19] {2466} INFO -  at 1127.1s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:37:19] {2282} INFO - iteration 467, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:37:22] {2466} INFO -  at 1130.6s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:37:22] {2282} INFO - iteration 468, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:37:24] {2466} INFO -  at 1131.8s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:37:24] {2282} INFO - iteration 469, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:37:26] {2466} INFO -  at 1134.4s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:37:26] {2282} INFO - iteration 470, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:37:26] {2466} INFO -  at 1134.7s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:37:26] {2282} INFO - iteration 471, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:37:27] {2466} INFO -  at 1135.5s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:37:27] {2282} INFO - iteration 472, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:37:30] {2466} INFO -  at 1138.1s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:37:30] {2282} INFO - iteration 473, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:37:30] {2466} INFO -  at 1138.6s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:37:30] {2282} INFO - iteration 474, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:37:41] {2466} INFO -  at 1149.4s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:37:41] {2282} INFO - iteration 475, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:37:42] {2466} INFO -  at 1150.6s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:37:42] {2282} INFO - iteration 476, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-04 23:37:45] {2466} INFO -  at 1153.6s,\testimator xgb_limitdepth's best error=0.1898,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:37:45] {2282} INFO - iteration 477, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:37:46] {2466} INFO -  at 1153.9s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:37:46] {2282} INFO - iteration 478, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:37:55] {2466} INFO -  at 1163.4s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:37:55] {2282} INFO - iteration 479, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:37:56] {2466} INFO -  at 1164.1s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:37:56] {2282} INFO - iteration 480, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:38:15] {2466} INFO -  at 1183.6s,\testimator rf's best error=0.1871,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:38:15] {2282} INFO - iteration 481, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:38:16] {2466} INFO -  at 1184.4s,\testimator extra_tree's best error=0.1900,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:38:16] {2282} INFO - iteration 482, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:38:27] {2466} INFO -  at 1195.2s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:38:27] {2282} INFO - iteration 483, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:38:28] {2466} INFO -  at 1195.8s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:38:28] {2282} INFO - iteration 484, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:38:42] {2466} INFO -  at 1210.8s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:38:42] {2282} INFO - iteration 485, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:39:06] {2466} INFO -  at 1234.3s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:39:06] {2282} INFO - iteration 486, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:39:06] {2466} INFO -  at 1234.7s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:39:06] {2282} INFO - iteration 487, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:39:07] {2466} INFO -  at 1235.7s,\testimator extra_tree's best error=0.1900,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:39:07] {2282} INFO - iteration 488, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:39:09] {2466} INFO -  at 1237.6s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:39:09] {2282} INFO - iteration 489, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:39:37] {2466} INFO -  at 1265.0s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:39:37] {2282} INFO - iteration 490, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:39:39] {2466} INFO -  at 1267.4s,\testimator extra_tree's best error=0.1900,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:39:39] {2282} INFO - iteration 491, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:39:39] {2466} INFO -  at 1267.5s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:39:39] {2282} INFO - iteration 492, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:40:04] {2466} INFO -  at 1292.2s,\testimator rf's best error=0.1871,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:40:04] {2282} INFO - iteration 493, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:40:04] {2466} INFO -  at 1292.3s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:40:04] {2282} INFO - iteration 494, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:40:04] {2466} INFO -  at 1292.6s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:40:04] {2282} INFO - iteration 495, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:40:05] {2466} INFO -  at 1293.3s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:40:05] {2282} INFO - iteration 496, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-04 23:40:13] {2466} INFO -  at 1301.5s,\testimator xgb_limitdepth's best error=0.1898,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:40:13] {2282} INFO - iteration 497, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:40:18] {2466} INFO -  at 1305.9s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:40:18] {2282} INFO - iteration 498, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:40:19] {2466} INFO -  at 1307.3s,\testimator extra_tree's best error=0.1900,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:40:19] {2282} INFO - iteration 499, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:40:30] {2466} INFO -  at 1318.1s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:40:30] {2282} INFO - iteration 500, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:40:39] {2466} INFO -  at 1327.0s,\testimator rf's best error=0.1871,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:40:39] {2282} INFO - iteration 501, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:40:39] {2466} INFO -  at 1327.3s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:40:39] {2282} INFO - iteration 502, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:40:40] {2466} INFO -  at 1328.0s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:40:40] {2282} INFO - iteration 503, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:40:52] {2466} INFO -  at 1340.5s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:40:52] {2282} INFO - iteration 504, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:41:21] {2466} INFO -  at 1369.3s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:41:21] {2282} INFO - iteration 505, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:41:38] {2466} INFO -  at 1386.5s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:41:38] {2282} INFO - iteration 506, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:42:00] {2466} INFO -  at 1408.3s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:42:00] {2282} INFO - iteration 507, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:42:01] {2466} INFO -  at 1408.8s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:42:01] {2282} INFO - iteration 508, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:42:01] {2466} INFO -  at 1409.5s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:42:01] {2282} INFO - iteration 509, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:42:02] {2466} INFO -  at 1409.9s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:42:02] {2282} INFO - iteration 510, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:42:02] {2466} INFO -  at 1410.4s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:42:02] {2282} INFO - iteration 511, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:42:03] {2466} INFO -  at 1411.1s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:42:03] {2282} INFO - iteration 512, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-04 23:42:04] {2466} INFO -  at 1411.9s,\testimator xgb_limitdepth's best error=0.1898,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:42:04] {2282} INFO - iteration 513, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:42:04] {2466} INFO -  at 1412.2s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:42:04] {2282} INFO - iteration 514, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:42:04] {2466} INFO -  at 1412.3s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:42:04] {2282} INFO - iteration 515, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:42:05] {2466} INFO -  at 1413.3s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:42:05] {2282} INFO - iteration 516, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:42:05] {2466} INFO -  at 1413.5s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:42:05] {2282} INFO - iteration 517, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:42:06] {2466} INFO -  at 1414.0s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:42:06] {2282} INFO - iteration 518, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:42:07] {2466} INFO -  at 1415.7s,\testimator extra_tree's best error=0.1900,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:42:07] {2282} INFO - iteration 519, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:42:08] {2466} INFO -  at 1416.2s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:42:08] {2282} INFO - iteration 520, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:42:08] {2466} INFO -  at 1416.5s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:42:08] {2282} INFO - iteration 521, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:42:11] {2466} INFO -  at 1418.9s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:42:11] {2282} INFO - iteration 522, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:42:11] {2466} INFO -  at 1419.0s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:42:11] {2282} INFO - iteration 523, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:42:21] {2466} INFO -  at 1429.2s,\testimator rf's best error=0.1871,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:42:21] {2282} INFO - iteration 524, current learner xgboost\n",
            "[flaml.automl.logger: 10-04 23:42:50] {2466} INFO -  at 1458.0s,\testimator xgboost's best error=0.1890,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:42:50] {2282} INFO - iteration 525, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:42:50] {2466} INFO -  at 1458.3s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:42:50] {2282} INFO - iteration 526, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:42:55] {2466} INFO -  at 1463.5s,\testimator extra_tree's best error=0.1900,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:42:55] {2282} INFO - iteration 527, current learner lrl1\n",
            "[flaml.automl.logger: 10-04 23:42:56] {2466} INFO -  at 1464.1s,\testimator lrl1's best error=0.4027,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:42:56] {2282} INFO - iteration 528, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:43:17] {2466} INFO -  at 1485.1s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:43:17] {2282} INFO - iteration 529, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:43:18] {2466} INFO -  at 1485.8s,\testimator extra_tree's best error=0.1900,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:43:18] {2282} INFO - iteration 530, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:43:41] {2466} INFO -  at 1509.5s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:43:41] {2282} INFO - iteration 531, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:43:57] {2466} INFO -  at 1525.7s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:43:57] {2282} INFO - iteration 532, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:43:59] {2466} INFO -  at 1527.5s,\testimator extra_tree's best error=0.1900,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:43:59] {2282} INFO - iteration 533, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:44:00] {2466} INFO -  at 1528.2s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:44:00] {2282} INFO - iteration 534, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:44:00] {2466} INFO -  at 1528.7s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:44:00] {2282} INFO - iteration 535, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:44:01] {2466} INFO -  at 1529.2s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:44:01] {2282} INFO - iteration 536, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:44:21] {2466} INFO -  at 1548.8s,\testimator rf's best error=0.1871,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:44:21] {2282} INFO - iteration 537, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:44:23] {2466} INFO -  at 1551.0s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:44:23] {2282} INFO - iteration 538, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:44:57] {2466} INFO -  at 1585.1s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:44:57] {2282} INFO - iteration 539, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:44:58] {2466} INFO -  at 1585.9s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:44:58] {2282} INFO - iteration 540, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:45:28] {2466} INFO -  at 1616.1s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:45:28] {2282} INFO - iteration 541, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:45:28] {2466} INFO -  at 1616.3s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:45:28] {2282} INFO - iteration 542, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:45:28] {2466} INFO -  at 1616.5s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:45:28] {2282} INFO - iteration 543, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-04 23:45:30] {2466} INFO -  at 1618.6s,\testimator xgb_limitdepth's best error=0.1898,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:45:30] {2282} INFO - iteration 544, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-04 23:45:36] {2466} INFO -  at 1624.7s,\testimator xgb_limitdepth's best error=0.1898,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:45:36] {2282} INFO - iteration 545, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:45:49] {2466} INFO -  at 1637.6s,\testimator rf's best error=0.1871,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:45:49] {2282} INFO - iteration 546, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:45:50] {2466} INFO -  at 1638.1s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:45:50] {2282} INFO - iteration 547, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:45:50] {2466} INFO -  at 1638.8s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:45:50] {2282} INFO - iteration 548, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:46:08] {2466} INFO -  at 1656.0s,\testimator rf's best error=0.1871,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:46:08] {2282} INFO - iteration 549, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:46:08] {2466} INFO -  at 1656.2s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:46:08] {2282} INFO - iteration 550, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:46:47] {2466} INFO -  at 1695.7s,\testimator rf's best error=0.1871,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:46:47] {2282} INFO - iteration 551, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:46:48] {2466} INFO -  at 1696.8s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:46:48] {2282} INFO - iteration 552, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:46:49] {2466} INFO -  at 1697.0s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:46:49] {2282} INFO - iteration 553, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:46:49] {2466} INFO -  at 1697.3s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:46:49] {2282} INFO - iteration 554, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:46:49] {2466} INFO -  at 1697.4s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:46:49] {2282} INFO - iteration 555, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:46:50] {2466} INFO -  at 1698.3s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:46:50] {2282} INFO - iteration 556, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:47:11] {2466} INFO -  at 1719.3s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:47:11] {2282} INFO - iteration 557, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:47:12] {2466} INFO -  at 1720.4s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:47:12] {2282} INFO - iteration 558, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:47:16] {2466} INFO -  at 1723.8s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:47:16] {2282} INFO - iteration 559, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:47:20] {2466} INFO -  at 1727.9s,\testimator rf's best error=0.1871,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:47:20] {2282} INFO - iteration 560, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:47:20] {2466} INFO -  at 1728.0s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:47:20] {2282} INFO - iteration 561, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:47:32] {2466} INFO -  at 1740.7s,\testimator rf's best error=0.1871,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:47:32] {2282} INFO - iteration 562, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:47:33] {2466} INFO -  at 1741.3s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:47:33] {2282} INFO - iteration 563, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:47:35] {2466} INFO -  at 1743.1s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:47:35] {2282} INFO - iteration 564, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:47:51] {2466} INFO -  at 1759.1s,\testimator rf's best error=0.1871,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:47:51] {2282} INFO - iteration 565, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-04 23:48:01] {2466} INFO -  at 1768.9s,\testimator xgb_limitdepth's best error=0.1898,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:48:01] {2282} INFO - iteration 566, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:48:01] {2466} INFO -  at 1769.0s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:48:01] {2282} INFO - iteration 567, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:48:01] {2466} INFO -  at 1769.2s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:48:01] {2282} INFO - iteration 568, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:48:02] {2466} INFO -  at 1770.3s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:48:02] {2282} INFO - iteration 569, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:48:15] {2466} INFO -  at 1782.9s,\testimator rf's best error=0.1871,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:48:15] {2282} INFO - iteration 570, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:48:15] {2466} INFO -  at 1782.9s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:48:15] {2282} INFO - iteration 571, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:48:15] {2466} INFO -  at 1783.4s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:48:15] {2282} INFO - iteration 572, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-04 23:48:17] {2466} INFO -  at 1784.8s,\testimator xgb_limitdepth's best error=0.1898,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:48:17] {2282} INFO - iteration 573, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-04 23:48:20] {2466} INFO -  at 1788.7s,\testimator xgb_limitdepth's best error=0.1898,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:48:20] {2282} INFO - iteration 574, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:48:21] {2466} INFO -  at 1789.5s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:48:21] {2282} INFO - iteration 575, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:49:00] {2466} INFO -  at 1828.6s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:49:00] {2282} INFO - iteration 576, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-04 23:49:02] {2466} INFO -  at 1830.0s,\testimator xgb_limitdepth's best error=0.1898,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:49:02] {2282} INFO - iteration 577, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:49:03] {2466} INFO -  at 1830.9s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:49:03] {2282} INFO - iteration 578, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:49:21] {2466} INFO -  at 1849.2s,\testimator rf's best error=0.1871,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:49:21] {2282} INFO - iteration 579, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:49:21] {2466} INFO -  at 1849.4s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:49:21] {2282} INFO - iteration 580, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:49:21] {2466} INFO -  at 1849.6s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:49:21] {2282} INFO - iteration 581, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-04 23:49:40] {2466} INFO -  at 1868.3s,\testimator xgb_limitdepth's best error=0.1898,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:49:40] {2282} INFO - iteration 582, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-04 23:49:41] {2466} INFO -  at 1869.4s,\testimator xgb_limitdepth's best error=0.1898,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:49:41] {2282} INFO - iteration 583, current learner xgboost\n",
            "[flaml.automl.logger: 10-04 23:49:54] {2466} INFO -  at 1882.7s,\testimator xgboost's best error=0.1890,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:49:54] {2282} INFO - iteration 584, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:49:55] {2466} INFO -  at 1883.1s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:49:55] {2282} INFO - iteration 585, current learner xgboost\n",
            "[flaml.automl.logger: 10-04 23:49:58] {2466} INFO -  at 1886.7s,\testimator xgboost's best error=0.1890,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:49:58] {2282} INFO - iteration 586, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-04 23:50:06] {2466} INFO -  at 1894.0s,\testimator xgb_limitdepth's best error=0.1898,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:50:06] {2282} INFO - iteration 587, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:50:06] {2466} INFO -  at 1894.2s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:50:06] {2282} INFO - iteration 588, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:50:24] {2466} INFO -  at 1911.8s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:50:24] {2282} INFO - iteration 589, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:50:25] {2466} INFO -  at 1913.6s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:50:25] {2282} INFO - iteration 590, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:50:25] {2466} INFO -  at 1913.7s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:50:25] {2282} INFO - iteration 591, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:50:26] {2466} INFO -  at 1914.1s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:50:26] {2282} INFO - iteration 592, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:50:26] {2466} INFO -  at 1914.2s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:50:26] {2282} INFO - iteration 593, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:50:27] {2466} INFO -  at 1914.9s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:50:27] {2282} INFO - iteration 594, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:50:27] {2466} INFO -  at 1915.1s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:50:27] {2282} INFO - iteration 595, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:50:27] {2466} INFO -  at 1915.3s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:50:27] {2282} INFO - iteration 596, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:50:28] {2466} INFO -  at 1916.2s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:50:28] {2282} INFO - iteration 597, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:50:28] {2466} INFO -  at 1916.3s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:50:28] {2282} INFO - iteration 598, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:50:28] {2466} INFO -  at 1916.5s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:50:28] {2282} INFO - iteration 599, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:50:28] {2466} INFO -  at 1916.6s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:50:28] {2282} INFO - iteration 600, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:50:28] {2466} INFO -  at 1916.8s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:50:28] {2282} INFO - iteration 601, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:50:33] {2466} INFO -  at 1921.2s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:50:33] {2282} INFO - iteration 602, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:50:33] {2466} INFO -  at 1921.5s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:50:33] {2282} INFO - iteration 603, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:50:34] {2466} INFO -  at 1922.5s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:50:34] {2282} INFO - iteration 604, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:50:35] {2466} INFO -  at 1923.1s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:50:35] {2282} INFO - iteration 605, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:50:35] {2466} INFO -  at 1923.5s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:50:35] {2282} INFO - iteration 606, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:50:36] {2466} INFO -  at 1923.8s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:50:36] {2282} INFO - iteration 607, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:50:37] {2466} INFO -  at 1924.8s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:50:37] {2282} INFO - iteration 608, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-04 23:50:38] {2466} INFO -  at 1926.7s,\testimator xgb_limitdepth's best error=0.1898,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:50:38] {2282} INFO - iteration 609, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:50:39] {2466} INFO -  at 1926.9s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:50:39] {2282} INFO - iteration 610, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:50:39] {2466} INFO -  at 1927.4s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:50:39] {2282} INFO - iteration 611, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:50:40] {2466} INFO -  at 1927.9s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:50:40] {2282} INFO - iteration 612, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:50:40] {2466} INFO -  at 1928.3s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:50:40] {2282} INFO - iteration 613, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:51:15] {2466} INFO -  at 1963.3s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:51:15] {2282} INFO - iteration 614, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:51:15] {2466} INFO -  at 1963.4s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:51:15] {2282} INFO - iteration 615, current learner xgboost\n",
            "[flaml.automl.logger: 10-04 23:52:34] {2466} INFO -  at 2042.1s,\testimator xgboost's best error=0.1890,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:52:34] {2282} INFO - iteration 616, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:52:35] {2466} INFO -  at 2043.0s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:52:35] {2282} INFO - iteration 617, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:52:35] {2466} INFO -  at 2043.1s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:52:35] {2282} INFO - iteration 618, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:52:35] {2466} INFO -  at 2043.3s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:52:35] {2282} INFO - iteration 619, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:52:59] {2466} INFO -  at 2066.9s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:52:59] {2282} INFO - iteration 620, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-04 23:53:03] {2466} INFO -  at 2070.9s,\testimator xgb_limitdepth's best error=0.1898,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:53:03] {2282} INFO - iteration 621, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:53:13] {2466} INFO -  at 2081.1s,\testimator rf's best error=0.1871,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:53:13] {2282} INFO - iteration 622, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:53:14] {2466} INFO -  at 2082.2s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:53:14] {2282} INFO - iteration 623, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:53:46] {2466} INFO -  at 2114.7s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:53:46] {2282} INFO - iteration 624, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:53:47] {2466} INFO -  at 2115.1s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:53:47] {2282} INFO - iteration 625, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:53:48] {2466} INFO -  at 2115.9s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:53:48] {2282} INFO - iteration 626, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:53:48] {2466} INFO -  at 2116.3s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:53:48] {2282} INFO - iteration 627, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:53:48] {2466} INFO -  at 2116.7s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:53:48] {2282} INFO - iteration 628, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:53:49] {2466} INFO -  at 2117.6s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:53:49] {2282} INFO - iteration 629, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:53:49] {2466} INFO -  at 2117.7s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:53:49] {2282} INFO - iteration 630, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:53:50] {2466} INFO -  at 2118.2s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:53:50] {2282} INFO - iteration 631, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:53:52] {2466} INFO -  at 2120.4s,\testimator extra_tree's best error=0.1900,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:53:52] {2282} INFO - iteration 632, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:53:52] {2466} INFO -  at 2120.7s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:53:52] {2282} INFO - iteration 633, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:53:53] {2466} INFO -  at 2121.3s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:53:53] {2282} INFO - iteration 634, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:53:55] {2466} INFO -  at 2123.1s,\testimator extra_tree's best error=0.1900,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:53:55] {2282} INFO - iteration 635, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:53:55] {2466} INFO -  at 2123.2s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:53:55] {2282} INFO - iteration 636, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:53:56] {2466} INFO -  at 2124.7s,\testimator extra_tree's best error=0.1900,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:53:56] {2282} INFO - iteration 637, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:53:57] {2466} INFO -  at 2125.6s,\testimator extra_tree's best error=0.1900,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:53:57] {2282} INFO - iteration 638, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:53:59] {2466} INFO -  at 2127.0s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:53:59] {2282} INFO - iteration 639, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:53:59] {2466} INFO -  at 2127.2s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:53:59] {2282} INFO - iteration 640, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:54:37] {2466} INFO -  at 2165.5s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:54:37] {2282} INFO - iteration 641, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:54:38] {2466} INFO -  at 2166.2s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:54:38] {2282} INFO - iteration 642, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:54:38] {2466} INFO -  at 2166.3s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:54:38] {2282} INFO - iteration 643, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:54:38] {2466} INFO -  at 2166.8s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:54:38] {2282} INFO - iteration 644, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:54:39] {2466} INFO -  at 2166.9s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:54:39] {2282} INFO - iteration 645, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:54:39] {2466} INFO -  at 2167.2s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:54:39] {2282} INFO - iteration 646, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:54:40] {2466} INFO -  at 2168.4s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:54:40] {2282} INFO - iteration 647, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:54:41] {2466} INFO -  at 2168.9s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:54:41] {2282} INFO - iteration 648, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:54:41] {2466} INFO -  at 2169.6s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:54:41] {2282} INFO - iteration 649, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:55:07] {2466} INFO -  at 2195.7s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:55:07] {2282} INFO - iteration 650, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:55:08] {2466} INFO -  at 2196.1s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:55:08] {2282} INFO - iteration 651, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:55:34] {2466} INFO -  at 2221.8s,\testimator rf's best error=0.1871,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:55:34] {2282} INFO - iteration 652, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:56:10] {2466} INFO -  at 2258.2s,\testimator rf's best error=0.1871,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:56:10] {2282} INFO - iteration 653, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:56:11] {2466} INFO -  at 2259.4s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:56:11] {2282} INFO - iteration 654, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:56:12] {2466} INFO -  at 2260.0s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:56:12] {2282} INFO - iteration 655, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:56:12] {2466} INFO -  at 2260.5s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:56:12] {2282} INFO - iteration 656, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:56:19] {2466} INFO -  at 2266.9s,\testimator rf's best error=0.1871,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:56:19] {2282} INFO - iteration 657, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:56:20] {2466} INFO -  at 2268.7s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:56:20] {2282} INFO - iteration 658, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:56:21] {2466} INFO -  at 2268.9s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:56:21] {2282} INFO - iteration 659, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:56:21] {2466} INFO -  at 2269.4s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:56:21] {2282} INFO - iteration 660, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:56:21] {2466} INFO -  at 2269.6s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:56:21] {2282} INFO - iteration 661, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:56:22] {2466} INFO -  at 2270.1s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:56:22] {2282} INFO - iteration 662, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:56:55] {2466} INFO -  at 2303.3s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:56:55] {2282} INFO - iteration 663, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:56:56] {2466} INFO -  at 2303.9s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:56:56] {2282} INFO - iteration 664, current learner xgboost\n",
            "[flaml.automl.logger: 10-04 23:57:16] {2466} INFO -  at 2324.6s,\testimator xgboost's best error=0.1877,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:57:16] {2282} INFO - iteration 665, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:57:17] {2466} INFO -  at 2325.1s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:57:17] {2282} INFO - iteration 666, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:57:17] {2466} INFO -  at 2325.4s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:57:17] {2282} INFO - iteration 667, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:57:18] {2466} INFO -  at 2325.8s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:57:18] {2282} INFO - iteration 668, current learner rf\n",
            "[flaml.automl.logger: 10-04 23:57:33] {2466} INFO -  at 2341.6s,\testimator rf's best error=0.1871,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:57:33] {2282} INFO - iteration 669, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:57:33] {2466} INFO -  at 2341.7s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:57:33] {2282} INFO - iteration 670, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:57:34] {2466} INFO -  at 2342.3s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:57:34] {2282} INFO - iteration 671, current learner xgboost\n",
            "[flaml.automl.logger: 10-04 23:57:56] {2466} INFO -  at 2364.5s,\testimator xgboost's best error=0.1877,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:57:56] {2282} INFO - iteration 672, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:57:57] {2466} INFO -  at 2365.4s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:57:57] {2282} INFO - iteration 673, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:57:57] {2466} INFO -  at 2365.6s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:57:57] {2282} INFO - iteration 674, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-04 23:58:00] {2466} INFO -  at 2367.8s,\testimator xgb_limitdepth's best error=0.1875,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:58:00] {2282} INFO - iteration 675, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:58:00] {2466} INFO -  at 2368.8s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:58:00] {2282} INFO - iteration 676, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:58:01] {2466} INFO -  at 2368.9s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:58:01] {2282} INFO - iteration 677, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:58:01] {2466} INFO -  at 2369.1s,\testimator lgbm's best error=0.1863,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:58:01] {2282} INFO - iteration 678, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:58:01] {2466} INFO -  at 2369.3s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:58:01] {2282} INFO - iteration 679, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:58:04] {2466} INFO -  at 2372.2s,\testimator extra_tree's best error=0.1900,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:58:04] {2282} INFO - iteration 680, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:58:05] {2466} INFO -  at 2373.3s,\testimator lgbm's best error=0.1858,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:58:05] {2282} INFO - iteration 681, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:58:05] {2466} INFO -  at 2373.4s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:58:05] {2282} INFO - iteration 682, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:58:05] {2466} INFO -  at 2373.6s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:58:05] {2282} INFO - iteration 683, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:58:32] {2466} INFO -  at 2400.3s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:58:32] {2282} INFO - iteration 684, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:58:36] {2466} INFO -  at 2404.2s,\testimator extra_tree's best error=0.1890,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:58:36] {2282} INFO - iteration 685, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:58:41] {2466} INFO -  at 2409.6s,\testimator lgbm's best error=0.1858,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:58:41] {2282} INFO - iteration 686, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:59:17] {2466} INFO -  at 2445.5s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:59:17] {2282} INFO - iteration 687, current learner catboost\n",
            "[flaml.automl.logger: 10-04 23:59:44] {2466} INFO -  at 2471.9s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:59:44] {2282} INFO - iteration 688, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:59:44] {2466} INFO -  at 2472.0s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:59:44] {2282} INFO - iteration 689, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-04 23:59:46] {2466} INFO -  at 2473.8s,\testimator xgb_limitdepth's best error=0.1875,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:59:46] {2282} INFO - iteration 690, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:59:46] {2466} INFO -  at 2473.9s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:59:46] {2282} INFO - iteration 691, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:59:46] {2466} INFO -  at 2474.0s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:59:46] {2282} INFO - iteration 692, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:59:47] {2466} INFO -  at 2475.3s,\testimator extra_tree's best error=0.1890,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:59:47] {2282} INFO - iteration 693, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:59:47] {2466} INFO -  at 2475.4s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:59:47] {2282} INFO - iteration 694, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:59:47] {2466} INFO -  at 2475.6s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:59:47] {2282} INFO - iteration 695, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-04 23:59:53] {2466} INFO -  at 2481.0s,\testimator xgb_limitdepth's best error=0.1875,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:59:53] {2282} INFO - iteration 696, current learner extra_tree\n",
            "[flaml.automl.logger: 10-04 23:59:57] {2466} INFO -  at 2485.4s,\testimator extra_tree's best error=0.1890,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:59:57] {2282} INFO - iteration 697, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:59:57] {2466} INFO -  at 2485.5s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:59:57] {2282} INFO - iteration 698, current learner lgbm\n",
            "[flaml.automl.logger: 10-04 23:59:58] {2466} INFO -  at 2486.1s,\testimator lgbm's best error=0.1858,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:59:58] {2282} INFO - iteration 699, current learner sgd\n",
            "[flaml.automl.logger: 10-04 23:59:58] {2466} INFO -  at 2486.2s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-04 23:59:58] {2282} INFO - iteration 700, current learner catboost\n",
            "[flaml.automl.logger: 10-05 00:00:37] {2466} INFO -  at 2525.0s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:00:37] {2282} INFO - iteration 701, current learner xgboost\n",
            "[flaml.automl.logger: 10-05 00:01:18] {2466} INFO -  at 2566.7s,\testimator xgboost's best error=0.1877,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:01:18] {2282} INFO - iteration 702, current learner rf\n",
            "[flaml.automl.logger: 10-05 00:01:32] {2466} INFO -  at 2580.6s,\testimator rf's best error=0.1871,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:01:32] {2282} INFO - iteration 703, current learner xgboost\n",
            "[flaml.automl.logger: 10-05 00:01:36] {2466} INFO -  at 2584.5s,\testimator xgboost's best error=0.1877,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:01:36] {2282} INFO - iteration 704, current learner extra_tree\n",
            "[flaml.automl.logger: 10-05 00:01:39] {2466} INFO -  at 2587.6s,\testimator extra_tree's best error=0.1890,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:01:39] {2282} INFO - iteration 705, current learner catboost\n",
            "[flaml.automl.logger: 10-05 00:02:07] {2466} INFO -  at 2615.7s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:02:07] {2282} INFO - iteration 706, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-05 00:02:10] {2466} INFO -  at 2617.9s,\testimator xgb_limitdepth's best error=0.1875,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:02:10] {2282} INFO - iteration 707, current learner extra_tree\n",
            "[flaml.automl.logger: 10-05 00:02:14] {2466} INFO -  at 2622.1s,\testimator extra_tree's best error=0.1890,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:02:14] {2282} INFO - iteration 708, current learner rf\n",
            "[flaml.automl.logger: 10-05 00:02:22] {2466} INFO -  at 2630.4s,\testimator rf's best error=0.1871,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:02:22] {2282} INFO - iteration 709, current learner extra_tree\n",
            "[flaml.automl.logger: 10-05 00:02:30] {2466} INFO -  at 2637.8s,\testimator extra_tree's best error=0.1890,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:02:30] {2282} INFO - iteration 710, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-05 00:02:31] {2466} INFO -  at 2639.6s,\testimator xgb_limitdepth's best error=0.1875,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:02:31] {2282} INFO - iteration 711, current learner extra_tree\n",
            "[flaml.automl.logger: 10-05 00:02:41] {2466} INFO -  at 2649.6s,\testimator extra_tree's best error=0.1890,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:02:41] {2282} INFO - iteration 712, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-05 00:02:44] {2466} INFO -  at 2652.5s,\testimator xgb_limitdepth's best error=0.1875,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:02:44] {2282} INFO - iteration 713, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-05 00:02:46] {2466} INFO -  at 2654.0s,\testimator xgb_limitdepth's best error=0.1875,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:02:46] {2282} INFO - iteration 714, current learner sgd\n",
            "[flaml.automl.logger: 10-05 00:02:46] {2466} INFO -  at 2654.1s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:02:46] {2282} INFO - iteration 715, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-05 00:02:47] {2466} INFO -  at 2654.9s,\testimator xgb_limitdepth's best error=0.1875,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:02:47] {2282} INFO - iteration 716, current learner extra_tree\n",
            "[flaml.automl.logger: 10-05 00:02:48] {2466} INFO -  at 2656.6s,\testimator extra_tree's best error=0.1889,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:02:48] {2282} INFO - iteration 717, current learner sgd\n",
            "[flaml.automl.logger: 10-05 00:02:48] {2466} INFO -  at 2656.7s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:02:48] {2282} INFO - iteration 718, current learner xgboost\n",
            "[flaml.automl.logger: 10-05 00:03:01] {2466} INFO -  at 2669.1s,\testimator xgboost's best error=0.1877,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:03:01] {2282} INFO - iteration 719, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-05 00:03:05] {2466} INFO -  at 2672.9s,\testimator xgb_limitdepth's best error=0.1875,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:03:05] {2282} INFO - iteration 720, current learner extra_tree\n",
            "[flaml.automl.logger: 10-05 00:03:07] {2466} INFO -  at 2675.1s,\testimator extra_tree's best error=0.1889,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:03:07] {2282} INFO - iteration 721, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-05 00:03:11] {2466} INFO -  at 2679.1s,\testimator xgb_limitdepth's best error=0.1875,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:03:11] {2282} INFO - iteration 722, current learner catboost\n",
            "[flaml.automl.logger: 10-05 00:03:42] {2466} INFO -  at 2710.4s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:03:42] {2282} INFO - iteration 723, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-05 00:03:44] {2466} INFO -  at 2712.5s,\testimator xgb_limitdepth's best error=0.1875,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:03:44] {2282} INFO - iteration 724, current learner sgd\n",
            "[flaml.automl.logger: 10-05 00:03:44] {2466} INFO -  at 2712.6s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:03:44] {2282} INFO - iteration 725, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-05 00:03:46] {2466} INFO -  at 2714.4s,\testimator xgb_limitdepth's best error=0.1875,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:03:46] {2282} INFO - iteration 726, current learner sgd\n",
            "[flaml.automl.logger: 10-05 00:03:46] {2466} INFO -  at 2714.5s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:03:46] {2282} INFO - iteration 727, current learner rf\n",
            "[flaml.automl.logger: 10-05 00:04:04] {2466} INFO -  at 2732.6s,\testimator rf's best error=0.1871,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:04:04] {2282} INFO - iteration 728, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-05 00:04:10] {2466} INFO -  at 2738.0s,\testimator xgb_limitdepth's best error=0.1875,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:04:10] {2282} INFO - iteration 729, current learner catboost\n",
            "[flaml.automl.logger: 10-05 00:04:33] {2466} INFO -  at 2761.3s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:04:33] {2282} INFO - iteration 730, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-05 00:04:37] {2466} INFO -  at 2764.9s,\testimator xgb_limitdepth's best error=0.1875,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:04:37] {2282} INFO - iteration 731, current learner sgd\n",
            "[flaml.automl.logger: 10-05 00:04:37] {2466} INFO -  at 2765.0s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:04:37] {2282} INFO - iteration 732, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-05 00:04:42] {2466} INFO -  at 2770.0s,\testimator xgb_limitdepth's best error=0.1875,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:04:42] {2282} INFO - iteration 733, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-05 00:04:53] {2466} INFO -  at 2781.2s,\testimator xgb_limitdepth's best error=0.1875,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:04:53] {2282} INFO - iteration 734, current learner catboost\n",
            "[flaml.automl.logger: 10-05 00:05:40] {2466} INFO -  at 2828.4s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:05:40] {2282} INFO - iteration 735, current learner lgbm\n",
            "[flaml.automl.logger: 10-05 00:05:41] {2466} INFO -  at 2829.5s,\testimator lgbm's best error=0.1858,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:05:41] {2282} INFO - iteration 736, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-05 00:05:42] {2466} INFO -  at 2830.4s,\testimator xgb_limitdepth's best error=0.1875,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:05:42] {2282} INFO - iteration 737, current learner catboost\n",
            "[flaml.automl.logger: 10-05 00:06:09] {2466} INFO -  at 2857.6s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:06:09] {2282} INFO - iteration 738, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-05 00:06:11] {2466} INFO -  at 2859.7s,\testimator xgb_limitdepth's best error=0.1875,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:06:11] {2282} INFO - iteration 739, current learner rf\n",
            "[flaml.automl.logger: 10-05 00:06:39] {2466} INFO -  at 2886.9s,\testimator rf's best error=0.1871,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:06:39] {2282} INFO - iteration 740, current learner catboost\n",
            "[flaml.automl.logger: 10-05 00:07:07] {2466} INFO -  at 2915.4s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:07:07] {2282} INFO - iteration 741, current learner xgboost\n",
            "[flaml.automl.logger: 10-05 00:07:25] {2466} INFO -  at 2933.2s,\testimator xgboost's best error=0.1877,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:07:25] {2282} INFO - iteration 742, current learner sgd\n",
            "[flaml.automl.logger: 10-05 00:07:25] {2466} INFO -  at 2933.4s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:07:25] {2282} INFO - iteration 743, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-05 00:07:30] {2466} INFO -  at 2938.6s,\testimator xgb_limitdepth's best error=0.1875,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:07:30] {2282} INFO - iteration 744, current learner catboost\n",
            "[flaml.automl.logger: 10-05 00:08:04] {2466} INFO -  at 2972.1s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:08:04] {2282} INFO - iteration 745, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-05 00:08:05] {2466} INFO -  at 2972.9s,\testimator xgb_limitdepth's best error=0.1875,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:08:05] {2282} INFO - iteration 746, current learner sgd\n",
            "[flaml.automl.logger: 10-05 00:08:05] {2466} INFO -  at 2973.0s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:08:05] {2282} INFO - iteration 747, current learner lgbm\n",
            "[flaml.automl.logger: 10-05 00:08:06] {2466} INFO -  at 2974.1s,\testimator lgbm's best error=0.1858,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:08:06] {2282} INFO - iteration 748, current learner lrl1\n",
            "[flaml.automl.logger: 10-05 00:08:06] {2466} INFO -  at 2974.6s,\testimator lrl1's best error=0.4027,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:08:06] {2282} INFO - iteration 749, current learner lgbm\n",
            "[flaml.automl.logger: 10-05 00:08:09] {2466} INFO -  at 2976.8s,\testimator lgbm's best error=0.1858,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:08:09] {2282} INFO - iteration 750, current learner extra_tree\n",
            "[flaml.automl.logger: 10-05 00:08:11] {2466} INFO -  at 2979.1s,\testimator extra_tree's best error=0.1889,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:08:11] {2282} INFO - iteration 751, current learner catboost\n",
            "[flaml.automl.logger: 10-05 00:08:55] {2466} INFO -  at 3023.7s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:08:55] {2282} INFO - iteration 752, current learner lgbm\n",
            "[flaml.automl.logger: 10-05 00:08:56] {2466} INFO -  at 3024.6s,\testimator lgbm's best error=0.1858,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:08:56] {2282} INFO - iteration 753, current learner sgd\n",
            "[flaml.automl.logger: 10-05 00:08:56] {2466} INFO -  at 3024.7s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:08:56] {2282} INFO - iteration 754, current learner catboost\n",
            "[flaml.automl.logger: 10-05 00:09:16] {2466} INFO -  at 3044.3s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:09:16] {2282} INFO - iteration 755, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-05 00:09:27] {2466} INFO -  at 3055.4s,\testimator xgb_limitdepth's best error=0.1875,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:09:27] {2282} INFO - iteration 756, current learner xgboost\n",
            "[flaml.automl.logger: 10-05 00:10:02] {2466} INFO -  at 3090.4s,\testimator xgboost's best error=0.1877,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:10:02] {2282} INFO - iteration 757, current learner sgd\n",
            "[flaml.automl.logger: 10-05 00:10:02] {2466} INFO -  at 3090.5s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:10:02] {2282} INFO - iteration 758, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-05 00:10:08] {2466} INFO -  at 3096.1s,\testimator xgb_limitdepth's best error=0.1875,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:10:08] {2282} INFO - iteration 759, current learner rf\n",
            "[flaml.automl.logger: 10-05 00:10:14] {2466} INFO -  at 3102.3s,\testimator rf's best error=0.1871,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:10:14] {2282} INFO - iteration 760, current learner catboost\n",
            "[flaml.automl.logger: 10-05 00:10:45] {2466} INFO -  at 3132.8s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:10:45] {2282} INFO - iteration 761, current learner catboost\n",
            "[flaml.automl.logger: 10-05 00:11:23] {2466} INFO -  at 3170.9s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:11:23] {2282} INFO - iteration 762, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-05 00:11:24] {2466} INFO -  at 3172.5s,\testimator xgb_limitdepth's best error=0.1875,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:11:24] {2282} INFO - iteration 763, current learner catboost\n",
            "[flaml.automl.logger: 10-05 00:11:54] {2466} INFO -  at 3202.6s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:11:54] {2282} INFO - iteration 764, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-05 00:11:55] {2466} INFO -  at 3203.6s,\testimator xgb_limitdepth's best error=0.1875,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:11:55] {2282} INFO - iteration 765, current learner sgd\n",
            "[flaml.automl.logger: 10-05 00:11:56] {2466} INFO -  at 3204.0s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:11:56] {2282} INFO - iteration 766, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-05 00:12:02] {2466} INFO -  at 3210.1s,\testimator xgb_limitdepth's best error=0.1875,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:12:02] {2282} INFO - iteration 767, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-05 00:12:04] {2466} INFO -  at 3211.9s,\testimator xgb_limitdepth's best error=0.1875,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:12:04] {2282} INFO - iteration 768, current learner rf\n",
            "[flaml.automl.logger: 10-05 00:12:26] {2466} INFO -  at 3234.3s,\testimator rf's best error=0.1871,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:12:26] {2282} INFO - iteration 769, current learner catboost\n",
            "[flaml.automl.logger: 10-05 00:12:52] {2466} INFO -  at 3260.0s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:12:52] {2282} INFO - iteration 770, current learner xgboost\n",
            "[flaml.automl.logger: 10-05 00:12:59] {2466} INFO -  at 3266.9s,\testimator xgboost's best error=0.1877,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:12:59] {2282} INFO - iteration 771, current learner lgbm\n",
            "[flaml.automl.logger: 10-05 00:13:01] {2466} INFO -  at 3269.2s,\testimator lgbm's best error=0.1858,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:13:01] {2282} INFO - iteration 772, current learner rf\n",
            "[flaml.automl.logger: 10-05 00:13:12] {2466} INFO -  at 3280.3s,\testimator rf's best error=0.1871,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:13:12] {2282} INFO - iteration 773, current learner lgbm\n",
            "[flaml.automl.logger: 10-05 00:13:13] {2466} INFO -  at 3281.0s,\testimator lgbm's best error=0.1858,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:13:13] {2282} INFO - iteration 774, current learner sgd\n",
            "[flaml.automl.logger: 10-05 00:13:13] {2466} INFO -  at 3281.1s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:13:13] {2282} INFO - iteration 775, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-05 00:13:15] {2466} INFO -  at 3283.5s,\testimator xgb_limitdepth's best error=0.1875,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:13:15] {2282} INFO - iteration 776, current learner sgd\n",
            "[flaml.automl.logger: 10-05 00:13:15] {2466} INFO -  at 3283.6s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:13:15] {2282} INFO - iteration 777, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-05 00:13:18] {2466} INFO -  at 3286.6s,\testimator xgb_limitdepth's best error=0.1875,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:13:18] {2282} INFO - iteration 778, current learner sgd\n",
            "[flaml.automl.logger: 10-05 00:13:18] {2466} INFO -  at 3286.7s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:13:18] {2282} INFO - iteration 779, current learner sgd\n",
            "[flaml.automl.logger: 10-05 00:13:19] {2466} INFO -  at 3286.8s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:13:19] {2282} INFO - iteration 780, current learner sgd\n",
            "[flaml.automl.logger: 10-05 00:13:19] {2466} INFO -  at 3287.0s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:13:19] {2282} INFO - iteration 781, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-05 00:13:20] {2466} INFO -  at 3288.2s,\testimator xgb_limitdepth's best error=0.1875,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:13:20] {2282} INFO - iteration 782, current learner sgd\n",
            "[flaml.automl.logger: 10-05 00:13:20] {2466} INFO -  at 3288.3s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:13:20] {2282} INFO - iteration 783, current learner rf\n",
            "[flaml.automl.logger: 10-05 00:13:35] {2466} INFO -  at 3303.3s,\testimator rf's best error=0.1871,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:13:35] {2282} INFO - iteration 784, current learner xgboost\n",
            "[flaml.automl.logger: 10-05 00:13:54] {2466} INFO -  at 3322.6s,\testimator xgboost's best error=0.1877,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:13:54] {2282} INFO - iteration 785, current learner rf\n",
            "[flaml.automl.logger: 10-05 00:14:09] {2466} INFO -  at 3337.5s,\testimator rf's best error=0.1871,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:14:09] {2282} INFO - iteration 786, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-05 00:14:17] {2466} INFO -  at 3345.3s,\testimator xgb_limitdepth's best error=0.1875,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:14:17] {2282} INFO - iteration 787, current learner rf\n",
            "[flaml.automl.logger: 10-05 00:14:55] {2466} INFO -  at 3383.1s,\testimator rf's best error=0.1871,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:14:55] {2282} INFO - iteration 788, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-05 00:14:56] {2466} INFO -  at 3384.0s,\testimator xgb_limitdepth's best error=0.1875,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:14:56] {2282} INFO - iteration 789, current learner catboost\n",
            "[flaml.automl.logger: 10-05 00:15:17] {2466} INFO -  at 3405.5s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:15:17] {2282} INFO - iteration 790, current learner xgboost\n",
            "[flaml.automl.logger: 10-05 00:15:24] {2466} INFO -  at 3412.6s,\testimator xgboost's best error=0.1877,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:15:24] {2282} INFO - iteration 791, current learner catboost\n",
            "[flaml.automl.logger: 10-05 00:16:02] {2466} INFO -  at 3450.7s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:16:02] {2282} INFO - iteration 792, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-05 00:16:03] {2466} INFO -  at 3451.7s,\testimator xgb_limitdepth's best error=0.1875,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:16:03] {2282} INFO - iteration 793, current learner extra_tree\n",
            "[flaml.automl.logger: 10-05 00:16:05] {2466} INFO -  at 3453.2s,\testimator extra_tree's best error=0.1889,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:16:05] {2282} INFO - iteration 794, current learner catboost\n",
            "[flaml.automl.logger: 10-05 00:16:39] {2466} INFO -  at 3487.1s,\testimator catboost's best error=0.1840,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:16:39] {2282} INFO - iteration 795, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-05 00:16:45] {2466} INFO -  at 3493.8s,\testimator xgb_limitdepth's best error=0.1875,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:16:45] {2282} INFO - iteration 796, current learner rf\n",
            "[flaml.automl.logger: 10-05 00:16:51] {2466} INFO -  at 3498.9s,\testimator rf's best error=0.1871,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:16:51] {2282} INFO - iteration 797, current learner sgd\n",
            "[flaml.automl.logger: 10-05 00:16:51] {2466} INFO -  at 3499.0s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:16:51] {2282} INFO - iteration 798, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-05 00:16:54] {2466} INFO -  at 3502.1s,\testimator xgb_limitdepth's best error=0.1875,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:16:54] {2282} INFO - iteration 799, current learner extra_tree\n",
            "[flaml.automl.logger: 10-05 00:16:57] {2466} INFO -  at 3505.2s,\testimator extra_tree's best error=0.1889,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:16:57] {2282} INFO - iteration 800, current learner xgboost\n",
            "[flaml.automl.logger: 10-05 00:17:53] {2466} INFO -  at 3561.4s,\testimator xgboost's best error=0.1877,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:17:53] {2282} INFO - iteration 801, current learner sgd\n",
            "[flaml.automl.logger: 10-05 00:17:53] {2466} INFO -  at 3561.6s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:17:53] {2282} INFO - iteration 802, current learner xgboost\n",
            "[flaml.automl.logger: 10-05 00:17:56] {2466} INFO -  at 3564.2s,\testimator xgboost's best error=0.1877,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:17:56] {2282} INFO - iteration 803, current learner sgd\n",
            "[flaml.automl.logger: 10-05 00:17:56] {2466} INFO -  at 3564.3s,\testimator sgd's best error=0.3514,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:17:56] {2282} INFO - iteration 804, current learner xgboost\n",
            "[flaml.automl.logger: 10-05 00:18:28] {2466} INFO -  at 3595.9s,\testimator xgboost's best error=0.1877,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:18:28] {2282} INFO - iteration 805, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-05 00:18:29] {2466} INFO -  at 3597.7s,\testimator xgb_limitdepth's best error=0.1875,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:18:29] {2282} INFO - iteration 806, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-05 00:18:32] {2466} INFO -  at 3600.1s,\testimator xgb_limitdepth's best error=0.1875,\tbest estimator catboost's best error=0.1840\n",
            "[flaml.automl.logger: 10-05 00:18:34] {2724} INFO - retrain catboost for 1.9s\n",
            "[flaml.automl.logger: 10-05 00:18:34] {2727} INFO - retrained model: <catboost.core.CatBoostClassifier object at 0x786cbe023290>\n",
            "[flaml.automl.logger: 10-05 00:18:34] {2009} INFO - fit succeeded\n",
            "[flaml.automl.logger: 10-05 00:18:34] {2010} INFO - Time taken to find the best model: 756.7135815620422\n",
            "FLAML best estimator: catboost\n",
            "FLAML best config: {'early_stopping_rounds': 15, 'learning_rate': 0.06070164529361272, 'n_estimators': 8192}\n",
            "FLAML best loss: 0.18396130967945282\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"    final_reports(y_test_f, fl_proba, THR, title_prefix=\\\"[FLAML] \\\")\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"threshold\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.15138251770487454,\n        \"min\": 0.05,\n        \"max\": 0.49999999999999994,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.44999999999999996,\n          0.1,\n          0.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 29,\n        \"min\": 604,\n        \"max\": 687,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          621,\n          685,\n          661\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 46,\n        \"min\": 74,\n        \"max\": 218,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          85,\n          181,\n          110\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FN\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 29,\n        \"min\": 5,\n        \"max\": 88,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          71,\n          7,\n          31\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TN\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 46,\n        \"min\": 82,\n        \"max\": 226,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          215,\n          119,\n          190\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FN_rate(%)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.192716523754034,\n        \"min\": 0.7225433526011561,\n        \"max\": 12.716763005780347,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          10.260115606936417,\n          1.0115606936416186,\n          4.479768786127168\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0432756230163896,\n        \"min\": 0.7591160220994475,\n        \"max\": 0.8908554572271387,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.8796033994334278,\n          0.7909930715935335,\n          0.8573281452658884\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.041927165237540344,\n        \"min\": 0.8728323699421965,\n        \"max\": 0.9927745664739884,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.8973988439306358,\n          0.9898843930635838,\n          0.9552023121387283\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.014054911974960635,\n        \"min\": 0.8603631809643081,\n        \"max\": 0.9050505050505051,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.8884120171673819,\n          0.8793324775353016,\n          0.9036226930963773\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Specificity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1561974850021205,\n        \"min\": 0.2733333333333333,\n        \"max\": 0.7533333333333333,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.7166666666666667,\n          0.39666666666666667,\n          0.6333333333333333\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.026633599533641646,\n        \"min\": 0.7752016129032258,\n        \"max\": 0.8588709677419355,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.842741935483871,\n          0.8104838709677419,\n          0.8588709677419355\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-d6a1a377-4684-42cc-8aa2-0f6d59e7c458\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>threshold</th>\n",
              "      <th>TP</th>\n",
              "      <th>FP</th>\n",
              "      <th>FN</th>\n",
              "      <th>TN</th>\n",
              "      <th>FN_rate(%)</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.05</td>\n",
              "      <td>687</td>\n",
              "      <td>218</td>\n",
              "      <td>5</td>\n",
              "      <td>82</td>\n",
              "      <td>0.722543</td>\n",
              "      <td>0.759116</td>\n",
              "      <td>0.992775</td>\n",
              "      <td>0.860363</td>\n",
              "      <td>0.273333</td>\n",
              "      <td>0.775202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.10</td>\n",
              "      <td>685</td>\n",
              "      <td>181</td>\n",
              "      <td>7</td>\n",
              "      <td>119</td>\n",
              "      <td>1.011561</td>\n",
              "      <td>0.790993</td>\n",
              "      <td>0.989884</td>\n",
              "      <td>0.879332</td>\n",
              "      <td>0.396667</td>\n",
              "      <td>0.810484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.15</td>\n",
              "      <td>682</td>\n",
              "      <td>158</td>\n",
              "      <td>10</td>\n",
              "      <td>142</td>\n",
              "      <td>1.445087</td>\n",
              "      <td>0.811905</td>\n",
              "      <td>0.985549</td>\n",
              "      <td>0.890339</td>\n",
              "      <td>0.473333</td>\n",
              "      <td>0.830645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.20</td>\n",
              "      <td>679</td>\n",
              "      <td>142</td>\n",
              "      <td>13</td>\n",
              "      <td>158</td>\n",
              "      <td>1.878613</td>\n",
              "      <td>0.827040</td>\n",
              "      <td>0.981214</td>\n",
              "      <td>0.897555</td>\n",
              "      <td>0.526667</td>\n",
              "      <td>0.843750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.25</td>\n",
              "      <td>672</td>\n",
              "      <td>121</td>\n",
              "      <td>20</td>\n",
              "      <td>179</td>\n",
              "      <td>2.890173</td>\n",
              "      <td>0.847415</td>\n",
              "      <td>0.971098</td>\n",
              "      <td>0.905051</td>\n",
              "      <td>0.596667</td>\n",
              "      <td>0.857863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.30</td>\n",
              "      <td>661</td>\n",
              "      <td>110</td>\n",
              "      <td>31</td>\n",
              "      <td>190</td>\n",
              "      <td>4.479769</td>\n",
              "      <td>0.857328</td>\n",
              "      <td>0.955202</td>\n",
              "      <td>0.903623</td>\n",
              "      <td>0.633333</td>\n",
              "      <td>0.857863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.35</td>\n",
              "      <td>648</td>\n",
              "      <td>96</td>\n",
              "      <td>44</td>\n",
              "      <td>204</td>\n",
              "      <td>6.358382</td>\n",
              "      <td>0.870968</td>\n",
              "      <td>0.936416</td>\n",
              "      <td>0.902507</td>\n",
              "      <td>0.680000</td>\n",
              "      <td>0.858871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.40</td>\n",
              "      <td>638</td>\n",
              "      <td>88</td>\n",
              "      <td>54</td>\n",
              "      <td>212</td>\n",
              "      <td>7.803468</td>\n",
              "      <td>0.878788</td>\n",
              "      <td>0.921965</td>\n",
              "      <td>0.899859</td>\n",
              "      <td>0.706667</td>\n",
              "      <td>0.856855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.45</td>\n",
              "      <td>621</td>\n",
              "      <td>85</td>\n",
              "      <td>71</td>\n",
              "      <td>215</td>\n",
              "      <td>10.260116</td>\n",
              "      <td>0.879603</td>\n",
              "      <td>0.897399</td>\n",
              "      <td>0.888412</td>\n",
              "      <td>0.716667</td>\n",
              "      <td>0.842742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.50</td>\n",
              "      <td>604</td>\n",
              "      <td>74</td>\n",
              "      <td>88</td>\n",
              "      <td>226</td>\n",
              "      <td>12.716763</td>\n",
              "      <td>0.890855</td>\n",
              "      <td>0.872832</td>\n",
              "      <td>0.881752</td>\n",
              "      <td>0.753333</td>\n",
              "      <td>0.836694</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d6a1a377-4684-42cc-8aa2-0f6d59e7c458')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d6a1a377-4684-42cc-8aa2-0f6d59e7c458 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d6a1a377-4684-42cc-8aa2-0f6d59e7c458');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ba503a94-7b8b-45e2-9737-b75e2e5343a5\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ba503a94-7b8b-45e2-9737-b75e2e5343a5')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ba503a94-7b8b-45e2-9737-b75e2e5343a5 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   threshold   TP   FP  FN   TN  FN_rate(%)  Precision    Recall        F1  \\\n",
              "0       0.05  687  218   5   82    0.722543   0.759116  0.992775  0.860363   \n",
              "1       0.10  685  181   7  119    1.011561   0.790993  0.989884  0.879332   \n",
              "2       0.15  682  158  10  142    1.445087   0.811905  0.985549  0.890339   \n",
              "3       0.20  679  142  13  158    1.878613   0.827040  0.981214  0.897555   \n",
              "4       0.25  672  121  20  179    2.890173   0.847415  0.971098  0.905051   \n",
              "5       0.30  661  110  31  190    4.479769   0.857328  0.955202  0.903623   \n",
              "6       0.35  648   96  44  204    6.358382   0.870968  0.936416  0.902507   \n",
              "7       0.40  638   88  54  212    7.803468   0.878788  0.921965  0.899859   \n",
              "8       0.45  621   85  71  215   10.260116   0.879603  0.897399  0.888412   \n",
              "9       0.50  604   74  88  226   12.716763   0.890855  0.872832  0.881752   \n",
              "\n",
              "   Specificity  Accuracy  \n",
              "0     0.273333  0.775202  \n",
              "1     0.396667  0.810484  \n",
              "2     0.473333  0.830645  \n",
              "3     0.526667  0.843750  \n",
              "4     0.596667  0.857863  \n",
              "5     0.633333  0.857863  \n",
              "6     0.680000  0.858871  \n",
              "7     0.706667  0.856855  \n",
              "8     0.716667  0.842742  \n",
              "9     0.753333  0.836694  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Limiar FLAML: {'thr_f1': 0.25, 'thr_rec': 0.01, 'thr90': 0.44}\n",
            "[FLAML] TP=672 | FP=121 | FN=20 | TN=179\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.899     0.597     0.717       300\n",
            "           1      0.847     0.971     0.905       692\n",
            "\n",
            "    accuracy                          0.858       992\n",
            "   macro avg      0.873     0.784     0.811       992\n",
            "weighted avg      0.863     0.858     0.848       992\n",
            "\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'list' object has no attribute 'shape'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-873954915.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mTHR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthr_f1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthr_f1\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mfinal_reports\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfl_proba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTHR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"[FLAML] \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-468002529.py\u001b[0m in \u001b[0;36mfinal_reports\u001b[0;34m(y_true, proba, thr, title_prefix)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{title_prefix}TP={tp} | FP={fp} | FN={fn} | TN={tn}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdigits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mConfusionMatrixDisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{title_prefix}Matriz de Confusão (thr={thr:.2f})\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_plot/confusion_matrix.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, include_values, cmap, xticks_rotation, values_format, ax, colorbar, im_kw, text_kw)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0mn_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mdefault_im_kw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"nearest\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "if not _FLAML_OK:\n",
        "    print(\"FLAML indisponível.\")\n",
        "else:\n",
        "    # FLAML requer X, y separadas\n",
        "    X_train_f = train_df.drop(columns=[TARGET] + (['sample_weight'] if 'sample_weight' in train_df.columns else []))\n",
        "    y_train_f = train_df[TARGET].values\n",
        "    X_test_f  = test_df.drop(columns=[TARGET])\n",
        "    y_test_f  = test_df[TARGET].values\n",
        "\n",
        "    automl = AutoML()\n",
        "    flaml_settings = {\n",
        "        \"time_budget\": 3600,\n",
        "        \"metric\": EVAL_METRIC,          # 'f1' ou 'recall'\n",
        "        \"task\": \"classification\",\n",
        "        \"log_file_name\": \"flaml.log\",\n",
        "        \"seed\": RANDOM_STATE,\n",
        "    }\n",
        "    if 'sample_weight' in train_df.columns:\n",
        "        flaml_settings[\"sample_weight\"] = train_df['sample_weight'].values\n",
        "\n",
        "    automl.fit(X_train=X_train_f, y_train=y_train_f, **flaml_settings)\n",
        "    print(\"FLAML best estimator:\", automl.best_estimator)\n",
        "    print(\"FLAML best config:\", automl.best_config)\n",
        "    print(\"FLAML best loss:\", automl.best_loss)\n",
        "\n",
        "    fl_proba = automl.predict_proba(X_test_f)[:,1]\n",
        "    # Varredura + relatórios\n",
        "    fl_thr_tbl = sweep_thresholds(y_test_f, fl_proba, np.linspace(0.05, 0.95, 19))\n",
        "    display(fl_thr_tbl.head(10))\n",
        "\n",
        "    thr_f1  = best_threshold(y_test_f, fl_proba, optimize='f1')\n",
        "    thr_rec = best_threshold(y_test_f, fl_proba, optimize='recall')\n",
        "    thr90   = best_threshold(y_test_f, fl_proba, min_recall=0.90)\n",
        "    print(\"Limiar FLAML:\", {\"thr_f1\":thr_f1, \"thr_rec\":thr_rec, \"thr90\":thr90})\n",
        "\n",
        "    THR = thr_f1 if thr_f1 is not None else 0.5\n",
        "    final_reports(y_test_f, fl_proba, THR, title_prefix=\"[FLAML] \")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13c5cedf",
      "metadata": {
        "id": "13c5cedf"
      },
      "source": [
        "## 8) AutoML #3 — PyCaret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a26c3432",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a26c3432",
        "outputId": "5027e4dd-bdb7-4ece-fb01-4c9a38ace27d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyCaret indisponível.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "if not _PYCARET_OK:\n",
        "    print(\"PyCaret indisponível.\")\n",
        "else:\n",
        "    # PyCaret opera em DataFrame completo (features + target)\n",
        "    train_py = train_df.copy()\n",
        "    test_py  = test_df.copy()\n",
        "\n",
        "    # Setup\n",
        "    clf1 = pc_setup(\n",
        "        data=train_py, target=TARGET, session_id=RANDOM_STATE,\n",
        "        silent=True, verbose=False,\n",
        "        fix_imbalance=(IMBALANCE_STRATEGY=='smote'),  # ativa SMOTE interno se quiser\n",
        "        use_gpu=False,  # cpu-only por padrão\n",
        "        fold=5,\n",
        "        imputation_type='simple'\n",
        "    )\n",
        "\n",
        "    # Compara modelos padrão do PyCaret e escolhe o top por F1 (ou mude para 'Recall')\n",
        "    best = compare_models(sort=EVAL_METRIC)  # 'F1' mapeia para f1; para recall use sort='Recall'\n",
        "    best = finalize_model(best)\n",
        "\n",
        "    # Probabilidade no test\n",
        "    preds = predict_model(best, data=test_py)\n",
        "    # A coluna 'Score' (se probabilística) pode variar; garantimos a prob positiva:\n",
        "    if 'Score' in preds.columns:\n",
        "        py_proba = preds['Score'].values\n",
        "    else:\n",
        "        # fallback: gera proba manual se possível\n",
        "        try:\n",
        "            py_proba = best.predict_proba(test_py.drop(columns=[TARGET]))[:,1]\n",
        "        except Exception:\n",
        "            # se modelo não tiver predict_proba, usa 0/1\n",
        "            py_proba = preds['Label'].values.astype(float)\n",
        "\n",
        "    y_true_py = test_py[TARGET].values\n",
        "\n",
        "    py_thr_tbl = sweep_thresholds(y_true_py, py_proba, np.linspace(0.05, 0.95, 19))\n",
        "    display(py_thr_tbl.head(10))\n",
        "\n",
        "    thr_f1  = best_threshold(y_true_py, py_proba, optimize='f1')\n",
        "    thr_rec = best_threshold(y_true_py, py_proba, optimize='recall')\n",
        "    thr90   = best_threshold(y_true_py, py_proba, min_recall=0.90)\n",
        "    print(\"Limiar PyCaret:\", {\"thr_f1\":thr_f1, \"thr_rec\":thr_rec, \"thr90\":thr90})\n",
        "\n",
        "    THR = thr_f1 if thr_f1 is not None else 0.5\n",
        "    final_reports(y_true_py, py_proba, THR, title_prefix=\"[PyCaret] \")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "072b2519",
      "metadata": {
        "id": "072b2519"
      },
      "source": [
        "## 9) Generic table export (adjust if you want to save per framework)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a57af047",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a57af047",
        "outputId": "84b17c6b-0768-48e3-845e-76d47d50e099"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Tabela de limiares exportada para report_thresholds.csv\n",
            "✅ FNs exportados para report_false_negatives.csv\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Exemplo: exportar a tabela de limiares do último framework rodado (ajuste conforme desejar)\n",
        "try:\n",
        "    thr_table_to_save = py_thr_tbl if 'py_thr_tbl' in globals() else (fl_thr_tbl if 'fl_thr_tbl' in globals() else ag_thr_tbl)\n",
        "    thr_table_to_save.to_csv('report_thresholds.csv', index=False)\n",
        "    print(\"✅ Tabela de limiares exportada para report_thresholds.csv\")\n",
        "except Exception as e:\n",
        "    print(\"⚠️ Não foi possível exportar a tabela de limiares:\", e)\n",
        "\n",
        "# Exemplo: exportar FNs do último framework (ajuste)\n",
        "try:\n",
        "    THR = thr_f1 if 'thr_f1' in globals() and thr_f1 is not None else 0.5\n",
        "    # Selecionar y_true/proba da última execução disponível\n",
        "    if 'y_true_py' in globals() and 'py_proba' in globals():\n",
        "        y_true_exp, proba_exp, df_base = y_true_py, py_proba, test_df\n",
        "    elif 'y_test_f' in globals() and 'fl_proba' in globals():\n",
        "        y_true_exp, proba_exp, df_base = y_test_f, fl_proba, test_df\n",
        "    else:\n",
        "        y_true_exp, proba_exp, df_base = y_true, ag_proba, test_df\n",
        "\n",
        "    y_pred_exp = (proba_exp >= THR).astype(int)\n",
        "    fn_mask = (df_base[TARGET].values == 1) & (y_pred_exp == 0)\n",
        "    false_negatives = df_base.loc[fn_mask].copy()\n",
        "    false_negatives.to_csv('report_false_negatives.csv', index=False)\n",
        "    print(\"✅ FNs exportados para report_false_negatives.csv\")\n",
        "except Exception as e:\n",
        "    print(\"⚠️ Não foi possível exportar FNs:\", e)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
